<!DOCTYPE html>
                <html>
                <head>
                    <title>Neural Network Embeddings Explained</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://williamkoehrsen.medium.com/?source=post_page-----4d028e6f0526--------------------------------">Author : Will Koehrsen</a> </h5></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*pVTvM5NyFRUoVZ1n7zLgkQ.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">(<a href="https://www.pexels.com/photo/milky-way-illustration-1169754/" target="_self">Source</a>)</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Neural Network Embeddings Explained</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5 text-muted">How deep learning can represent War and Peace as a vector</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Applications of neural networks have expanded significantly in recent years from image segmentation to natural language processing to time-series forecasting. One notably successful use of deep learning is embedding, a method used to represent discrete variables as continuous vectors. This technique has found practical applications with word embeddings for <a href="https://arxiv.org/abs/1705.03127" target="_self">machine translation</a> and <a href="https://arxiv.org/abs/1604.06737" target="_self">entity embeddings for categorical variables</a>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this article, I’ll explain what neural network embeddings are, why we want to use them, and how they are learned. We’ll go through these concepts in the context of a<a href="https://github.com/WillKoehrsen/wikipedia-data-science/blob/master/notebooks/Book%20Recommendation%20System.ipynb" target="_self"> real problem I’m working on</a>: representing all the books on Wikipedia as vectors to create a book recommendation system.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*zAdi7DntawgPsQekPkFxPA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*zAdi7DntawgPsQekPkFxPA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*zAdi7DntawgPsQekPkFxPA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*zAdi7DntawgPsQekPkFxPA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*zAdi7DntawgPsQekPkFxPA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*zAdi7DntawgPsQekPkFxPA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zAdi7DntawgPsQekPkFxPA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*zAdi7DntawgPsQekPkFxPA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*zAdi7DntawgPsQekPkFxPA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*zAdi7DntawgPsQekPkFxPA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*zAdi7DntawgPsQekPkFxPA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*zAdi7DntawgPsQekPkFxPA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*zAdi7DntawgPsQekPkFxPA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*zAdi7DntawgPsQekPkFxPA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*zAdi7DntawgPsQekPkFxPA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Neural Network Embedding of all books on Wikipedia. (<a href="https://github.com/WillKoehrsen/wikipedia-data-science/blob/master/notebooks/Book%20Recommendation%20System.ipynb" target="_self">From Jupyter Notebook on GitHub</a>).</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Embeddings</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><em>An embedding is a mapping of a discrete — categorical — variable to a vector of continuous numbers.</em> <a href="https://www.tensorflow.org/guide/embedding" target="_self">In the context of neural networks, embeddings</a> are <em>low-dimensional,</em> <em>learned</em> continuous vector representations of discrete variables. Neural network embeddings are useful because they can <em>reduce the dimensionality</em> of categorical variables and <em>meaningfully represent</em> categories in the transformed space.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Neural network embeddings have 3 primary purposes:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">Finding nearest neighbors in the embedding space. These can be used to make recommendations based on user interests or cluster categories.</li><li class="ff3" style="font-size:22px;">As input to a machine learning model for a supervised task.</li><li class="ff3" style="font-size:22px;">For visualization of concepts and relations between categories.</li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This means in terms of the book project, using neural network embeddings, we can take all 37,000 book articles on Wikipedia and represent each one using only 50 numbers in a vector. Moreover, because embeddings are learned, books that are more similar in the context of our learning problem are closer to one another in the embedding space.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Neural network embeddings overcome the two limitations of a common method for representing categorical variables: one-hot encoding.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Limitations of One Hot Encoding</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The operation of one-hot encoding categorical variables is actually a simple embedding where each category is mapped to a different vector. This process takes discrete entities and maps each observation to a vector of 0s and a single 1 signaling the specific category.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The one-hot encoding technique has two main drawbacks:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">For high-cardinality variables — those with many unique categories — the dimensionality of the transformed vector becomes unmanageable.</li><li class="ff3" style="font-size:22px;">The mapping is completely uninformed: “similar” categories are not placed closer to each other in embedding space.</li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The first problem is well-understood: for each additional category — referred to as an entity — we have to add another number to the one-hot encoded vector. If we have 37,000 books on Wikipedia, then representing these requires a 37,000-dimensional vector for each book, which makes training any machine learning model on this representation infeasible.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The second problem is equally limiting: one-hot encoding <em>does not place similar entities closer to one another in vector space</em>. If we measure similarity between vectors using the cosine distance, then after one-hot encoding, the similarity is 0 for every comparison between entities.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This means that entities such as <em>War and Peace</em> and <em>Anna Karenina </em>(both classic books by Leo Tolstoy) are no closer to one another than <em>War and Peace</em> is to <em>The Hitchhiker’s Guide to the Galaxy </em>if we use one-hot encoding.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><strong># One Hot Encoding Categoricals</strong></span><span><strong>books = ["War and Peace", "Anna Karenina", <br/>          "The Hitchhiker's Guide to the Galaxy"]</strong></span><span><strong>books_encoded = [[1, 0, 0],<br/>                 [0, 1, 0],<br/>                 [0, 0, 1]]</strong></span><span><strong>Similarity (dot product) between First and Second = 0<br/>Similarity (dot product) between Second and Third = 0<br/>Similarity (dot product) between First and Third = 0</strong></span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Considering these two problems, the ideal solution for representing categorical variables would require <em>fewer</em> numbers than the number of unique categories and would place similar categories <em>closer</em> to one another.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><strong># Idealized Representation of Embedding</strong></span><span><strong>books = ["War and Peace", "Anna Karenina", <br/>          "The Hitchhiker's Guide to the Galaxy"]</strong></span><span><strong>books_encoded_ideal = [[0.53,  0.85],<br/>                       [0.60,  0.80],<br/>                       [-0.78, -0.62]]</strong></span><span><strong>Similarity (dot product) between First and Second = 0.99<br/>Similarity (dot product) between Second and Third = -0.94<br/>Similarity (dot product) between First and Third = -0.97</strong></span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To construct a better representation of categorical entities, we can use an embedding neural network and a supervised task to <em>learn embeddings</em>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Learning Embeddings</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The main issue with one-hot encoding is that the transformation does not rely on any supervision. We can greatly improve embeddings by learning them using a neural network on a supervised task. The <a href="https://stats.stackexchange.com/questions/182775/what-is-an-embedding-layer-in-a-neural-network" target="_self">embeddings form the parameters </a>— weights — of the network which are adjusted to minimize loss on the task. The resulting embedded vectors are representations of categories where similar categories — relative to the task — are closer to one another.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For example, if we have a vocabulary of 50,000 words used in a collection of movie reviews, we could learn 100-dimensional embeddings for each word using an embedding neural network trained to predict the sentimentality of the reviews. (For exactly this application see <a href="https://colab.research.google.com/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=embeddings-colab&hl=en" target="_self">this Google Colab Notebook</a>). Words in the vocabulary that are associated with positive reviews such as “brilliant” or “excellent” will come out closer in the embedding space because the network has learned these are both associated with positive reviews.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*DuaSQL7EiPa-IreCXf2r5w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*DuaSQL7EiPa-IreCXf2r5w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*DuaSQL7EiPa-IreCXf2r5w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*DuaSQL7EiPa-IreCXf2r5w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*DuaSQL7EiPa-IreCXf2r5w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*DuaSQL7EiPa-IreCXf2r5w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DuaSQL7EiPa-IreCXf2r5w.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*DuaSQL7EiPa-IreCXf2r5w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*DuaSQL7EiPa-IreCXf2r5w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*DuaSQL7EiPa-IreCXf2r5w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*DuaSQL7EiPa-IreCXf2r5w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*DuaSQL7EiPa-IreCXf2r5w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*DuaSQL7EiPa-IreCXf2r5w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*DuaSQL7EiPa-IreCXf2r5w.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*DuaSQL7EiPa-IreCXf2r5w.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Movie Sentiment Word Embeddings (<a href="https://colab.research.google.com/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=embeddings-colab&hl=en" target="_self">source</a>)</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the book example given above, our supervised task could be “identify whether or not a book was written by Leo Tolstoy” and the resulting embeddings would place books written by Tolstoy closer to each other. <mark>Figuring out how to create the supervised task to produce relevant representations is the toughest part of making embeddings.</mark></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Implementation</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the Wikipedia book project (<a href="https://github.com/WillKoehrsen/wikipedia-data-science/blob/master/notebooks/Book%20Recommendation%20System.ipynb" target="_self">complete notebook here</a>), the supervised learning task is set as predicting whether a given link to a Wikipedia page appears in the article for a book. We feed in pairs of (book title, link) training examples with a mix of positive — true — and negative — false — pairs. This set-up is based on the assumption that books which link to similar Wikipedia pages are similar to one another. The resulting embeddings should therefore place alike books closer together in vector space.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The network I used has two parallel embedding layers that map the book and wikilink to separate 50-dimensional vectors and a dot product layer that combines the embeddings into a single number for a prediction. The embeddings are the parameters, or weights, of the network that are adjusted during training to minimize the loss on the supervised task.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In Keras code, this looks like the following (don’t worry if you don’t completely understand the code, just skip to the images):</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre> # Both inputs are 1-dimensional
book = Input(name = 'book', shape = [1])
link = Input(name = 'link', shape = [1])

# Embedding the book (shape will be (None, 1, 50))
book_embedding = Embedding(name = 'book_embedding',
                           input_dim = len(book_index),
                           output_dim = embedding_size)(book)

# Embedding the link (shape will be (None, 1, 50))
link_embedding = Embedding(name = 'link_embedding',
                           input_dim = len(link_index),
                           output_dim = embedding_size)(link)

# Merge the layers with a dot product along the second axis (shape will be (None, 1, 1))
merged = Dot(name = 'dot_product', normalize = True, axes = 2)([book_embedding, link_embedding])

# Reshape to be a single number (shape will be (None, 1))
merged = Reshape(target_shape = [1])(merged)

# Output neuron
out = Dense(1, activation = 'sigmoid')(merged)
model = Model(inputs = [book, link], outputs = out)

# Minimize binary cross entropy
model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])</pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Although in a supervised machine learning task the goal is usually to train a model to make predictions on new data, in this embedding model, the predictions can be just a means to an end. What we want is the embedding weights, the representation of the books and links as continuous vectors.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The embeddings by themselves are not that interesting: they are simply vectors of numbers:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*9Gq6-KxBafIu8yGGokuwXA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*9Gq6-KxBafIu8yGGokuwXA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*9Gq6-KxBafIu8yGGokuwXA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*9Gq6-KxBafIu8yGGokuwXA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*9Gq6-KxBafIu8yGGokuwXA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*9Gq6-KxBafIu8yGGokuwXA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Gq6-KxBafIu8yGGokuwXA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*9Gq6-KxBafIu8yGGokuwXA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*9Gq6-KxBafIu8yGGokuwXA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*9Gq6-KxBafIu8yGGokuwXA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*9Gq6-KxBafIu8yGGokuwXA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*9Gq6-KxBafIu8yGGokuwXA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*9Gq6-KxBafIu8yGGokuwXA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*9Gq6-KxBafIu8yGGokuwXA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*9Gq6-KxBafIu8yGGokuwXA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Example Embeddings from Book Recommendation Embedding Model</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">However, the embeddings can be used for the 3 purposes listed previously, and for this project, we are primarily interested in recommending books based on the nearest neighbors. To compute similarity, we take a query book and find the dot product between its vector and those of all the other books. (If our embeddings are normalized, this dot product is the <a href="http://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/" target="_self">cosine distance</a> between vectors that ranges from -1, most dissimilar, to +1, most similar. We could also use the Euclidean distance to measure similarity).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is the output of the book embedding model I built:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><strong>Books closest to War and Peace.</strong></span><span><strong>Book: War and Peace              Similarity: 1.0<br/>Book: Anna Karenina              Similarity: 0.79<br/>Book: The Master and Margarita   Similarity: 0.77<br/>Book: Doctor Zhivago (novel)     Similarity: 0.76<br/>Book: Dead Souls                 Similarity: 0.75</strong></span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">(The cosine similarity between a vector and itself must be 1.0). After some dimensionality reduction (see below), we can make figures like the following:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*g2pnJdS3ydf3zemOMQffiQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*g2pnJdS3ydf3zemOMQffiQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*g2pnJdS3ydf3zemOMQffiQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*g2pnJdS3ydf3zemOMQffiQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*g2pnJdS3ydf3zemOMQffiQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*g2pnJdS3ydf3zemOMQffiQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g2pnJdS3ydf3zemOMQffiQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*g2pnJdS3ydf3zemOMQffiQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*g2pnJdS3ydf3zemOMQffiQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*g2pnJdS3ydf3zemOMQffiQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*g2pnJdS3ydf3zemOMQffiQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*g2pnJdS3ydf3zemOMQffiQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*g2pnJdS3ydf3zemOMQffiQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*g2pnJdS3ydf3zemOMQffiQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*g2pnJdS3ydf3zemOMQffiQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Embedding Books with Closest Neighbors</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We can clearly see the value of learning embeddings! We now have a 50-number representation of every single book on Wikipedia, with similar books closer to one another.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Embedding Visualizations</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">One of the coolest parts about embeddings are that they can be used to visualize concepts such as <em>novel </em>or <em>non-fiction </em>relative to one another. This requires a further dimension reduction technique to get the dimensions to 2 or 3. The most popular technique for reduction is itself an embedding method: t-Distributed Stochastic Neighbor Embedding (TSNE).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We can take the original 37,000 dimensions of all the books on Wikipedia, map them to 50 dimensions using neural network embeddings, and then map them to 2 dimensions using TSNE. The result is below:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:95%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 698px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*RmG8qwjGGbp_CAXA8eDISQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*RmG8qwjGGbp_CAXA8eDISQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*RmG8qwjGGbp_CAXA8eDISQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*RmG8qwjGGbp_CAXA8eDISQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*RmG8qwjGGbp_CAXA8eDISQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*RmG8qwjGGbp_CAXA8eDISQ.png 1100w, https://miro.medium.com/v2/resize:fit:1396/format:webp/1*RmG8qwjGGbp_CAXA8eDISQ.png 1396w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 698px" srcset="https://miro.medium.com/v2/resize:fit:640/1*RmG8qwjGGbp_CAXA8eDISQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*RmG8qwjGGbp_CAXA8eDISQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*RmG8qwjGGbp_CAXA8eDISQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*RmG8qwjGGbp_CAXA8eDISQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*RmG8qwjGGbp_CAXA8eDISQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*RmG8qwjGGbp_CAXA8eDISQ.png 1100w, https://miro.medium.com/v2/resize:fit:1396/1*RmG8qwjGGbp_CAXA8eDISQ.png 1396w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/698/1*RmG8qwjGGbp_CAXA8eDISQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Embedding of all 37,000 books on Wikipedia</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">(TSNE is a manifold learning technique which means that it tries to map high-dimensional data to a lower-dimensional manifold, creating an embedding that attempts to maintain local structure within the data. It’s almost exclusively used for visualization because the output is stochastic and it does not support transforming new data. An up and coming alternative is <a href="https://github.com/lmcinnes/umap" target="_self">Uniform Manifold Approximation and Projection, UMAP,</a> which is much faster and does support transform new data into the embedding space).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">By itself this isn’t very useful, but it can be insightful once we start coloring it based on different book characteristics.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*jYu2qwF4w3h7Xa93B05Ocw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*jYu2qwF4w3h7Xa93B05Ocw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*jYu2qwF4w3h7Xa93B05Ocw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*jYu2qwF4w3h7Xa93B05Ocw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*jYu2qwF4w3h7Xa93B05Ocw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*jYu2qwF4w3h7Xa93B05Ocw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jYu2qwF4w3h7Xa93B05Ocw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*jYu2qwF4w3h7Xa93B05Ocw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*jYu2qwF4w3h7Xa93B05Ocw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*jYu2qwF4w3h7Xa93B05Ocw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*jYu2qwF4w3h7Xa93B05Ocw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*jYu2qwF4w3h7Xa93B05Ocw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*jYu2qwF4w3h7Xa93B05Ocw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*jYu2qwF4w3h7Xa93B05Ocw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*jYu2qwF4w3h7Xa93B05Ocw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Embeddings Colored by Genre</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We can clearly see groupings of books belonging to the same genre. It’s not perfect, but it’s still impressive that we can represent all books on Wikipedia using just 2 numbers that still capture the variability between genres.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The book example (full article coming soon) shows the value of neural network embeddings: we have a vector representation of categorical objects that is both low-dimensional and places similar entities closer to one another in the embedded space.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Bonus: Interactive Visualizations</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The problem with static graphs is that we can’t really explore the data and investigate groupings or relationships between variables. To solve this problem, TensorFlow developed <a href="https://projector.tensorflow.org" target="_self">projector</a>, an online application that lets us visualize and interact with embeddings. I’ll release an article on how to use this tool shortly, but for now, here’s the results:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*zhlXuzV2kI2V2qJ5M3uPPg.gif 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*zhlXuzV2kI2V2qJ5M3uPPg.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Interactive Exploration of Book Embeddings using projector</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Conclusions</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Neural network embeddings are <em>learned low-dimensional representations of discrete data as continuous vectors. </em>These embeddings overcome the limitations of traditional encoding methods and can be used for purposes such as <em>finding nearest neighbors, input into another model</em>, and <em>visualizations</em>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Although many deep learning concepts are talked about in academic terms, neural network embeddings are both intuitive and relatively simple to implement. I firmly believe that anyone can <a href="http://fast.ai" target="_self">learn deep learning</a> and use libraries such as Keras to <a href="http://shop.oreilly.com/product/0636920097471.do" target="_self">build deep learning solutions</a>. Embeddings are an effective tool for handling discrete variables and present a useful application of deep learning.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Resources</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><a href="https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture" target="_self">Google-Produced tutorial on embeddings</a></li><li class="ff3" style="font-size:22px;"><a href="https://www.tensorflow.org/guide/embedding" target="_self">TensorFlow Guide to Embeddings</a></li><li class="ff3" style="font-size:22px;"><a href="https://github.com/WillKoehrsen/wikipedia-data-science/blob/master/notebooks/Book%20Recommendation%20System.ipynb" target="_self">Book Recommendation System Using Embeddings</a></li><li class="ff3" style="font-size:22px;"><a href="https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/" target="_self">Tutorial on Word Embeddings in Keras</a></li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As always, I welcome feedback and constructive criticism. I can be reached on Twitter <a href="http://twitter.com/@koehrsen_will" target="_self">@koehrsen_will</a> or on my personal website at <a href="https://willk.online" target="_self">willk.online</a>.</p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>