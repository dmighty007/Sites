<!DOCTYPE html>
                <html>
                <head>
                    <title>What Can You Do With GNNs</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://towardsdatascience.com/what-can-you-do-with-gnns-5dbec638b525"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://anuradhawick.medium.com/?source=post_page-----5dbec638b525--------------------------------">Author : Anuradha Wickramarachchi</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>What Can You Do With GNNs</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5 text-muted">Manipulation, Utility and Advantages of Graph Neural Networks</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Graph neural networks (GNN) are gaining popularity due to the ubiquitous nature of the Graph Data structure. Graphs enable us to model many different problems in science in fields such as (but not limited to) biology, sociology, ecology, vision, education, economics, etc. Moreover, graph representations enable us to handle unstructured data in massive scales.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this article, I will show how one might use a simple GNN in tasks such as classification, clustering and visualization. I will be using a GCN (Graph Convolution Network) for the running example. This should provide one with great intuition to extend the ideology to their own domain.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*YECeOxlko9KoOJNw8RNm3A.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*YECeOxlko9KoOJNw8RNm3A.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*YECeOxlko9KoOJNw8RNm3A.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*YECeOxlko9KoOJNw8RNm3A.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*YECeOxlko9KoOJNw8RNm3A.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*YECeOxlko9KoOJNw8RNm3A.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YECeOxlko9KoOJNw8RNm3A.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*YECeOxlko9KoOJNw8RNm3A.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*YECeOxlko9KoOJNw8RNm3A.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*YECeOxlko9KoOJNw8RNm3A.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*YECeOxlko9KoOJNw8RNm3A.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*YECeOxlko9KoOJNw8RNm3A.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*YECeOxlko9KoOJNw8RNm3A.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*YECeOxlko9KoOJNw8RNm3A.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*YECeOxlko9KoOJNw8RNm3A.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Photo by <a href="https://unsplash.com/@alinnnaaaa?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText" target="_self">Alina Grubnyak</a> on <a href="https://unsplash.com/s/photos/network?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText" target="_self">Unsplash</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Formal Representation of a GNN</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Any GNN can be represented as a layer containing two mathematical operators, <strong>aggregation function</strong> and <strong>combination function</strong>. This is best understood using the <strong>MPNN</strong> (message passing neural network) framework.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*hj_tH5CCOhayQQt-YhGu5A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*hj_tH5CCOhayQQt-YhGu5A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*hj_tH5CCOhayQQt-YhGu5A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*hj_tH5CCOhayQQt-YhGu5A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*hj_tH5CCOhayQQt-YhGu5A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*hj_tH5CCOhayQQt-YhGu5A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hj_tH5CCOhayQQt-YhGu5A.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*hj_tH5CCOhayQQt-YhGu5A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*hj_tH5CCOhayQQt-YhGu5A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*hj_tH5CCOhayQQt-YhGu5A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*hj_tH5CCOhayQQt-YhGu5A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*hj_tH5CCOhayQQt-YhGu5A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*hj_tH5CCOhayQQt-YhGu5A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*hj_tH5CCOhayQQt-YhGu5A.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*hj_tH5CCOhayQQt-YhGu5A.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure: <strong>Graph</strong> by Author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Aggregation</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If we consider an example graph as above, the aggregator function specializes in combining the neighbourhood information. More formally, aggregation can be represented as;</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*vz2VdLma2-J7EzgpHUpSTg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*vz2VdLma2-J7EzgpHUpSTg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*vz2VdLma2-J7EzgpHUpSTg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*vz2VdLma2-J7EzgpHUpSTg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*vz2VdLma2-J7EzgpHUpSTg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*vz2VdLma2-J7EzgpHUpSTg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vz2VdLma2-J7EzgpHUpSTg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*vz2VdLma2-J7EzgpHUpSTg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*vz2VdLma2-J7EzgpHUpSTg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*vz2VdLma2-J7EzgpHUpSTg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*vz2VdLma2-J7EzgpHUpSTg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*vz2VdLma2-J7EzgpHUpSTg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*vz2VdLma2-J7EzgpHUpSTg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*vz2VdLma2-J7EzgpHUpSTg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*vz2VdLma2-J7EzgpHUpSTg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Equation by Author Reference(<a href="https://arxiv.org/pdf/1810.00826.pdf" target="_self">https://arxiv.org/pdf/1810.00826.pdf</a>)</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In simple terms, the neighborhood aggregation of node <strong>v</strong> in <strong>k</strong>-th GNN layer is expressed using activation of neighboring node <strong>u</strong>, <strong>hᵤ </strong>of layer <strong>k-1.</strong> Neighbors of <strong>v </strong>are expressed as <strong>N(v)</strong>. In the first layer <strong>k-1=0</strong>, which fallback to the node features. In first layer we simply aggregate neighbors’ initial features. In case of GCN the aggregtor is simply the degree normalized means (each message is normalized by sequare root of product of degrees of <strong>v</strong> and <strong>u</strong>). One can think of various aggregators such as max, mean, min, etc as long as the operation is order invariant (result not altered by shuffling).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Combination</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Combination of neighbor information with the node itself is formally represented in the below equation.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*VBBkjKKPFvX2_HR4iiXqWw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*VBBkjKKPFvX2_HR4iiXqWw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*VBBkjKKPFvX2_HR4iiXqWw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*VBBkjKKPFvX2_HR4iiXqWw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*VBBkjKKPFvX2_HR4iiXqWw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*VBBkjKKPFvX2_HR4iiXqWw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VBBkjKKPFvX2_HR4iiXqWw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*VBBkjKKPFvX2_HR4iiXqWw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*VBBkjKKPFvX2_HR4iiXqWw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*VBBkjKKPFvX2_HR4iiXqWw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*VBBkjKKPFvX2_HR4iiXqWw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*VBBkjKKPFvX2_HR4iiXqWw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*VBBkjKKPFvX2_HR4iiXqWw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*VBBkjKKPFvX2_HR4iiXqWw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*VBBkjKKPFvX2_HR4iiXqWw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Equation by Author Reference(<a href="https://arxiv.org/pdf/1810.00826.pdf" target="_self">https://arxiv.org/pdf/1810.00826.pdf</a>)</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here different operations such as concatenation, summing up or element wise pooling operations can be used. Different GNN architectures rely on different functions. GCN uses the average, which we will discuss next.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the above <strong>Graph </strong>figure, we can aggregate features of node 1 to 6 by <code>X1/(sqrt(7×2))</code> X1 is features of node 1 and 7, 2 are degrees of node 6 and 1 respectively. For each node, we can do this. Intuitively, we can think of this as each node passing its message to others by averaging it over its out-degree, and them receiving others’ messages by averaging over their in-degrees. Hence the name <strong>MPNN</strong>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For a graph <strong>G(V, E)</strong> with adjacency matrix <strong>A</strong> and degree matrix <strong>D </strong>having features <strong>X</strong>, this can be easily achieved by <strong>D^(-1/2)XAD^(-1/2)</strong>. Usually, Adjacency matrix is added with <strong>I </strong>(identity matrix) to incorporate node’s own features. In such cases <strong>A</strong> is denoted as <strong>Â </strong>(A-hat) and <strong>D</strong> is replaced with <strong>D-hat</strong> where <strong>D-hat</strong> corresponds to <strong>A-hat</strong>. At this point, we have performed both aggregation and combination in few matrix operations. The resulting matrix is fed to a trainable differentiable function <strong>ɸ </strong>which is usually an MLP (Multi-layer perceptron) i.e. a neural network.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Stacking up layers</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We discussed what happens in a <strong>GNN layer</strong>, now imaging we stack up few such layers. This means we make more multiplications on the adjacency matrix. If you’re familiar with random-walks, <strong>D^(-1)A </strong>is called the transition matrix. Which is used in power iterations till convergence to find random walk probabilities from a given node to another. Intuitively, more layers of GNN we add, more hops the aggregation expands. Or in other words, after one Layer, we have node’s and its neighbors’ information. When we do it once more, neighbors (who have their neighbors) are aggregated again. Hence 2 hops, and so on.</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">Example Time!</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">PyTorch Geometric Framework</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">GNNs can be easily implemented using the pytorch geometric library. There you can find many implementations of GNNs and a messaging passing class to play around with your own custom implementations. Check it out in the following link.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://pytorch-geometric.readthedocs.io/en/latest"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">PyTorch Geometric Documentation - pytorch_geometric 1.7.2 documentation</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">It consists of various methods for deep learning on graphs and other irregular structures, also known as geometric deep…</h3><p>pytorch-geometric.readthedocs.io</p></a></div></div></div></div></section><br><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Cora Dataset</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We will use the popular Cora dataset which consists of scientific publications under 7 classes. It is connected via citations which represents the edges between nodes, which are research papers.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*l9fPSNCW8wPCi8HkQTwCNA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*l9fPSNCW8wPCi8HkQTwCNA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*l9fPSNCW8wPCi8HkQTwCNA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*l9fPSNCW8wPCi8HkQTwCNA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*l9fPSNCW8wPCi8HkQTwCNA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*l9fPSNCW8wPCi8HkQTwCNA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l9fPSNCW8wPCi8HkQTwCNA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*l9fPSNCW8wPCi8HkQTwCNA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*l9fPSNCW8wPCi8HkQTwCNA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*l9fPSNCW8wPCi8HkQTwCNA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*l9fPSNCW8wPCi8HkQTwCNA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*l9fPSNCW8wPCi8HkQTwCNA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*l9fPSNCW8wPCi8HkQTwCNA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*l9fPSNCW8wPCi8HkQTwCNA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*l9fPSNCW8wPCi8HkQTwCNA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image by Author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The visualization of graph using networkx yields the above image. We can see few colors have flocked together, but we are from any kind of satisfaction. So let’s reduce dimension on features and explore a bit more.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">UMAP on Features</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">One easy way to interpret data is seeing what is there and how they are placed. <a href="http://umap-learn.readthedocs.io" target="_self">UMAP</a> is a very helpful manifold learning tool which enables us to do this. Let’s visualize.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*C25521rkToKFOWLlVPeeTA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*C25521rkToKFOWLlVPeeTA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*C25521rkToKFOWLlVPeeTA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*C25521rkToKFOWLlVPeeTA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*C25521rkToKFOWLlVPeeTA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*C25521rkToKFOWLlVPeeTA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C25521rkToKFOWLlVPeeTA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*C25521rkToKFOWLlVPeeTA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*C25521rkToKFOWLlVPeeTA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*C25521rkToKFOWLlVPeeTA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*C25521rkToKFOWLlVPeeTA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*C25521rkToKFOWLlVPeeTA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*C25521rkToKFOWLlVPeeTA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*C25521rkToKFOWLlVPeeTA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*C25521rkToKFOWLlVPeeTA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image by Author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We can see some localization of classes but it is not perfect. Simplified code for the above operation is as follows (Complete code at end of article);</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span># essential imports that will be needed throughout the blog<br/>import torch<br/>import torch.nn.functional as F<br/>from torch_geometric.datasets import Planetoid<br/>from torch_geometric.nn import GCNConv<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import umap<br/>import networkx as nx<br/>import numpy as np</span><span>dataset = 'Cora'<br/>path = "./"<br/>dataset = Planetoid(path, dataset, transform=T.NormalizeFeatures())<br/>data = dataset[0]</span><span>embd = umap.UMAP().fit_transform(data.x.numpy())<br/>plt.figure(figsize=(10, 10))<br/>sns.scatterplot(x=embd.T[0], y=embd.T[1], hue=data.y.numpy(), palette=palette)<br/>plt.legend(bbox_to_anchor=(1,1), loc='upper left')</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We are definitely not happy with what we see, so let’s try a GCN and see the visualization. My network is as follows (which I modified from <a href="https://github.com/rusty1s/pytorch_geometric/blob/master/examples/gcn.py" target="_self">pytorch geometric github examples</a>);</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>class Net(torch.nn.Module):<br/>    def __init__(self):<br/>        super(Net, self).__init__()<br/>        self.conv1 = GCNConv(dataset.num_features, 16, cached=True)<br/>        self.conv2 = GCNConv(16, 16, cached=True)<br/>        <br/>        self.fc1 = torch.nn.Linear(16, dataset.num_classes)</span><span>    def forward(self):<br/>        x, edge_index, edge_weight = data.x, data.edge_index,<br/>                                          data.edge_attr<br/>        x = self.conv1(x, edge_index, edge_weight)<br/>        x = F.relu(x)<br/>        x = F.dropout(x, training=self.training)<br/>        x = self.conv2(x, edge_index, edge_weight)<br/>        x = F.relu(x)<br/>        x = F.dropout(x, training=self.training)<br/>        x = self.fc1(x)<br/>        <br/>        return F.log_softmax(x, dim=1)<br/>  </span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We can train this using the following code;</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')<br/>model, data = Net().to(device), data.to(device)<br/>optimizer = torch.optim.Adam([<br/>    dict(params=model.conv1.parameters(), weight_decay=5e-4),<br/>    dict(params=model.fc1.parameters(), weight_decay=5e-4),<br/>    dict(params=model.conv2.parameters(), weight_decay=0)<br/>], lr=0.01)</span><span>def train():<br/>    model.train()<br/>    optimizer.zero_grad()<br/>    F.nll_loss(model()[data.train_mask],<br/>                   data.y[data.train_mask]).backward()<br/>    optimizer.step()</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Note that L2 regularizer is missing in Conv layer 2, this is something authors of GCN has decided empirically (<a href="https://github.com/tkipf/gcn/issues/108" target="_self">https://github.com/tkipf/gcn/issues/108</a>).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">When visualized, the output looks like below;</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*IvylYUwdbxQAkNyBdtt2ig.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*IvylYUwdbxQAkNyBdtt2ig.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*IvylYUwdbxQAkNyBdtt2ig.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*IvylYUwdbxQAkNyBdtt2ig.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*IvylYUwdbxQAkNyBdtt2ig.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*IvylYUwdbxQAkNyBdtt2ig.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IvylYUwdbxQAkNyBdtt2ig.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*IvylYUwdbxQAkNyBdtt2ig.png 640w, https://miro.medium.com/v2/resize:fit:720/1*IvylYUwdbxQAkNyBdtt2ig.png 720w, https://miro.medium.com/v2/resize:fit:750/1*IvylYUwdbxQAkNyBdtt2ig.png 750w, https://miro.medium.com/v2/resize:fit:786/1*IvylYUwdbxQAkNyBdtt2ig.png 786w, https://miro.medium.com/v2/resize:fit:828/1*IvylYUwdbxQAkNyBdtt2ig.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*IvylYUwdbxQAkNyBdtt2ig.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*IvylYUwdbxQAkNyBdtt2ig.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*IvylYUwdbxQAkNyBdtt2ig.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image by Author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We can see that there is a very clear separation of different classes. Here, the training finished with <strong>0.7800</strong> test accuracy. Can we manipulate this a bit more? Let’s see.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Embedding losses</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Neural networks can be though of as continuous differentiable functions. Classification essentially learns decision boundaries for predictions. Read more about decision boundaies here;</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://medium.com/logistic-regression-and-decision-boundary-eab6e00c1e8"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">Logistic Regression and Decision Boundary</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">Understanding logistic regression and its utility in classification</h3><p>towardsdatascience.com</p></a></div></div></div></div></section><br><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In summary, if we force network to have better boundaries, we can have better visualizations. This means, we should be able to see the classes separately. This is particularly useful if we visualize of cluster data. One simple thing we can do is;</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">Ask GNN to embed similar classes closer</li><li class="ff3" style="font-size:22px;">Ask GNN to embed different classes further</li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Note that embeddings are the final layer output or the classification output of the network. We can use dot-product as a measure of distance in this case. We prepare our data point pairs as follows for this loss;</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>y_neg_pairs = []<br/>y_pos_pairs = []</span><span>data_idx = np.arange(len(data.x))<br/>for idx1, y1 in enumerate(data.y[data.train_mask].cpu().numpy()):<br/>    for idx2, y2 in enumerate(data.y[data.train_mask].cpu().numpy()):<br/>        if idx1 &gt; idx2 and y1!=y2:<br/>            y_neg_pairs.append([idx1, idx2])<br/>        if idx1 &gt; idx2 and y1==y2:<br/>            y_pos_pairs.append([idx1, idx2])</span><span>y_neg_pairs = np.array(y_neg_pairs)<br/>y_pos_pairs = np.array(y_pos_pairs)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Our modified loss function is as follows;</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>model_out = model()[data.train_mask]<br/>    y_true = data.y[data.train_mask]<br/>    nllloss = F.nll_loss(model_out, y_true)</span><span>    #Negative loss<br/>    disloss_neg = F.logsigmoid(-1 * (model_out[y_neg_pairs.T[0]]*model_out[y_neg_pairs.T[1]])).sum(-1).mean()<br/>    <br/>    #Positive loss<br/>    disloss_pos = F.logsigmoid((model_out[y_pos_pairs.T[0]]*model_out[y_pos_pairs.T[1]])).sum(-1).mean()<br/>    <br/>    loss = 10 * nllloss - disloss_neg - disloss_pos</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Note that we manipulate polarity of dot-product and pass it through logsigmoid to obtain the dot-product based loss. If you are interested this can be studied under GraphSAGE paper (<a href="https://arxiv.org/abs/1706.02216" target="_self">https://arxiv.org/abs/1706.02216</a>).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now our training finishes with a loss <strong>0.7720</strong>, which is slightly worse than before. Let’s visualize and see the output of the GNN with UMAP.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*CrE_StjMN9cldTL26zZRjA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*CrE_StjMN9cldTL26zZRjA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*CrE_StjMN9cldTL26zZRjA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*CrE_StjMN9cldTL26zZRjA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*CrE_StjMN9cldTL26zZRjA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*CrE_StjMN9cldTL26zZRjA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CrE_StjMN9cldTL26zZRjA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*CrE_StjMN9cldTL26zZRjA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*CrE_StjMN9cldTL26zZRjA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*CrE_StjMN9cldTL26zZRjA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*CrE_StjMN9cldTL26zZRjA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*CrE_StjMN9cldTL26zZRjA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*CrE_StjMN9cldTL26zZRjA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*CrE_StjMN9cldTL26zZRjA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*CrE_StjMN9cldTL26zZRjA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image by Author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We can see clusters are now better and noise is slightly lesser. Despite our lesser accuracy we have a better separation of clusters. Actually the lesser test loss is due to the indefinite nature of the clusters. We can see some points are confidently located in wrong colored clusters. This is essentially due to the nature of data.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Extending the Idea to Unsupervised Clustering</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">How do we extend this idea when we do not have labels, but only features and the graph. This has been discussed in GraphSAGE. The simple idea is to embed closer nodes closer and vice versa using graph topology. In place of our positive and negative pairs, we can have directly connected pairs and random pairs as positive and negative pairs respectively. This has shown good results in various domains, which is a topic for another day! 😊</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">I hope you enjoyed this article and I believe this will be useful for your research too!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As every other article, this comes with the <a href="https://gist.github.com/anuradhawick/bd2eb3f4e5f9c8030f8125d97dc686ac" target="_self">notebook</a>!</p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>