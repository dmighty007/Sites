<!DOCTYPE html>
                <html>
                <head>
                    <title>RNN or Recurrent Neural Network for Noobs</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/hackernoon/rnn-or-recurrent-neural-network-for-noobs-a9afbb00e860"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@debarko?source=post_page-----a9afbb00e860--------------------------------">Author : Debarko De ü¶Å</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>RNN or Recurrent Neural Network for Noobs</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">What is a Recurrent Neural Network or RNN, how it works, where it can be used? This article tries to answer the above questions. It also shows a demo implementation of a RNN used for a specific purpose, but you would be able to generalise it for your needs.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:89%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 651px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*6xj691fPWf3S-mWUCbxSJg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*6xj691fPWf3S-mWUCbxSJg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*6xj691fPWf3S-mWUCbxSJg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*6xj691fPWf3S-mWUCbxSJg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*6xj691fPWf3S-mWUCbxSJg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*6xj691fPWf3S-mWUCbxSJg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1302/format:webp/1*6xj691fPWf3S-mWUCbxSJg.jpeg 1302w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 651px" srcset="https://miro.medium.com/v2/resize:fit:640/1*6xj691fPWf3S-mWUCbxSJg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*6xj691fPWf3S-mWUCbxSJg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*6xj691fPWf3S-mWUCbxSJg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*6xj691fPWf3S-mWUCbxSJg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*6xj691fPWf3S-mWUCbxSJg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*6xj691fPWf3S-mWUCbxSJg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1302/1*6xj691fPWf3S-mWUCbxSJg.jpeg 1302w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/651/1*6xj691fPWf3S-mWUCbxSJg.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Recurrent Neural Network Architecture</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Knowhow. Python, CNN knowledge is required. CNN is required to compare why and where RNN performs better than CNN? No need to understand the math. If you want to check then go back to my earlier article to check what is a CNN.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We will begin with the word use of the word ‚ÄúRecurrent‚Äù. Why is it called Recurrent? In english the word recurrent means:</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">occurring often or repeatedly</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the case of this type of Neural Network it‚Äôs called Recurrent since it does the same operation over and over on sets of sequential input. We will discuss about the meaning of the <em>operation</em> later in the article.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Why do we need RNN?</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You might be wondering by now, we have vanilla networks like Convolutional ones which perform very well. Why do we need another type of a network? There is a very specific use case where RNNs are required. In order to explain RNNs you need to first understand something called a sequence. Let's talk about <strong>sequences </strong>first.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><mark>Sequence is a stream of data (finite or infinite) which are interdependent. Examples would be time series data, informative pieces of strings, conversations etc. In a conversation a sentence means something but the entire flow of the conversation mostly means something completely different. Also in a time series data like stock market data, a single tick data means the current price, but a full days data will show movement and allow us to take decision whether to buy or sell.</mark></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">CNNs generally don‚Äôt perform well when the input data is interdependent in a sequential pattern. CNNs don‚Äôt have any sort of correlation between previous input to the next input. So all the outputs are self dependent. CNN takes in an input and outputs based on the trained model. If you run 100 different inputs none of them would be biased by the previous output. But imagine a scenario like sentence generation or text translation. All the words generated are dependent on the words generated before (in certain cases, it‚Äôs dependent on words coming after as well, but we will discuss that later). So you need to have some bias based on your previous output. This is where RNNs shine. RNNs have in them a sense some memory about what happened earlier in the sequence of data. This helps the system to gain context. Theoretically RNNs have infinite memory, meaning they have the capability to look back indefinitely. By look back I mean all previous inputs. But practically they can only look back a last few steps. <em>(we will discuss this later)</em></p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">Just to draw a correlation with humans in general, we also don‚Äôt take in place decisions. We also base our decisions on previous knowledge on the subject. (**over simplified, hard to say I understand even 0.1% of human brains**)</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Where to use a RNN?</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">RNNs can be used in a lot of different places. Following are a few examples where a lot of RNNs are used.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">1. Language Modelling and Generating Text</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Given a sequence of word, here we try to predict the likelihood of the next word. This is useful for translation since the most likely sentence would be the one that is correct.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">2. Machine Translation</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Translating text from one language to other uses one or the other form of RNN. All practical day systems use some advanced version of a RNN.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">3. Speech Recognition</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Predicting phonetic segments based on input sound waves, thus formulating a word.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">4. Generating Image Descriptions</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A very big use case is to understand what is happening inside an image, thus we have a good description. This works in a combination of CNN and RNN. CNN does the segmentation and RNN then used the segmented data to recreate the description. It‚Äôs rudimentary but the possibilities are limitless.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">5. Video Tagging</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This can be used for video search where we do image description of a video frame by frame.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Lets Dig Deep!</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We will be following the below mentioned sequence of topics to finish the document. Each section builds on top of another so don‚Äôt read this as a reference.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">Feed-forward Networks</li><li class="ff3" style="font-size:22px;">Recurrent Networks</li><li class="ff3" style="font-size:22px;">Recurrent Neuron</li><li class="ff3" style="font-size:22px;">Backpropagation Through Time (BPTT)</li><li class="ff3" style="font-size:22px;">RNN Implementation</li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Feed-forward Networks Primer</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Feed-forward networks channel information through a series of operations which take place in each node of the network. Feed-forward networks pass the information directly through each layer exactly once. This is different from other recurrent networks. We will talk about them in a later section. Generally feed-forward nets take an input and produce an output from it. This is also mostly a supervised learning step and the outcome most likely will be a classification. It behaves similarly to how a CNN behaves. Outputs can be expected to be classes like cats or dogs as labels.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A feed-forward network is trained on a set of pre labelled data. The objective of the training phase is to reduce the error while the feed-forward network tries to guess the class. Once training is done, the weights are used to classify new batches of data.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*SL8FESMwzSy6QTrcIzcRYw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*SL8FESMwzSy6QTrcIzcRYw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*SL8FESMwzSy6QTrcIzcRYw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*SL8FESMwzSy6QTrcIzcRYw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*SL8FESMwzSy6QTrcIzcRYw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*SL8FESMwzSy6QTrcIzcRYw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SL8FESMwzSy6QTrcIzcRYw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*SL8FESMwzSy6QTrcIzcRYw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*SL8FESMwzSy6QTrcIzcRYw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*SL8FESMwzSy6QTrcIzcRYw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*SL8FESMwzSy6QTrcIzcRYw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*SL8FESMwzSy6QTrcIzcRYw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*SL8FESMwzSy6QTrcIzcRYw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*SL8FESMwzSy6QTrcIzcRYw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*SL8FESMwzSy6QTrcIzcRYw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">A typical feed-forward network architecture</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">One important thing to note here. In a feed-forward network whatever image is shown to the classifier during test phase, it doesn‚Äôt alter the weights so the second decision is not affected. This is one very important difference between feed-forward networks and recurrent nets.</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">Feed-forward nets don‚Äôt remember historic input data at test time unlike recurrent networks.</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">It‚Äôs always point in time decision. They only remember things that were shown to them during the training phase.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Recurrent Networks</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Recurrent networks, on the other hand, take as their input not just the current input example they see, but also what they have perceived previously in time.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let‚Äôs try to build a <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron" target="_self">multi layer perceptron</a> to start with the explanation. In simple terms there is a input layer, a hidden layer with certain activations and finally we receive an output.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:49%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 376px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 1100w, https://miro.medium.com/v2/resize:fit:752/format:webp/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 752w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 376px" srcset="https://miro.medium.com/v2/resize:fit:640/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 1100w, https://miro.medium.com/v2/resize:fit:752/1*UXDlYTeJFlbq2an7MH1HbA.jpeg 752w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/376/1*UXDlYTeJFlbq2an7MH1HbA.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">A sample multi layer perceptron architecture</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If we increase the number of layers in the above example, input layer takes the input. Then the first hidden layer does the activation passing onto the next hidden layers and so on. Finally it reaches the output layer which gives the output. Each hidden layer has its own weights and biases. Now the question is can we input to the hidden layers.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*8m2AxT3aH7bHfnnaMj8Ptw.jpeg"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Each layer has its own weight (W), biases (B), Activation Functions (F). These layers behave differently and technically would be challenging to merge together. To be able to merge them, lets replace all the layers with the same weights and biases. It will look something like this.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*sL5dNMry95B_u4NLbuBNKg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*sL5dNMry95B_u4NLbuBNKg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*sL5dNMry95B_u4NLbuBNKg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*sL5dNMry95B_u4NLbuBNKg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*sL5dNMry95B_u4NLbuBNKg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*sL5dNMry95B_u4NLbuBNKg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sL5dNMry95B_u4NLbuBNKg.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*sL5dNMry95B_u4NLbuBNKg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*sL5dNMry95B_u4NLbuBNKg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*sL5dNMry95B_u4NLbuBNKg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*sL5dNMry95B_u4NLbuBNKg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*sL5dNMry95B_u4NLbuBNKg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*sL5dNMry95B_u4NLbuBNKg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*sL5dNMry95B_u4NLbuBNKg.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*sL5dNMry95B_u4NLbuBNKg.jpeg"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now we can merge all the layers together. All the hidden layers can be combined into a single recurrent layer. So they start looking somewhat like this:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:48%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 364px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:728/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 728w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 364px" srcset="https://miro.medium.com/v2/resize:fit:640/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:728/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 728w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/364/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We will provide input to the hidden layer at each step. A recurrent neuron now stores all the previous step input and merges that information with the current step input. Thus it also captures some information regarding the correlation between current data step and the previous steps. The decision at a time step <code>t-1</code> affects the decision taken at time <code>t</code>. This is very much like how we as humans take decisions in our life. We combine the present data with recent past to take a call on a particular problem at hand. This example is excessively rudimentary but in principle it aligns with our decision making capability. <em>This really intrigues me as to whether we as humans are intelligent or we have a very advanced neural network model. Our decisions are just the training data that we have been collecting throughout our life. Thus can we digitise our brains once we have a fairly advanced model and systems capable of storing and computing them in reasonable time periods. So what happens when we have models better and faster than our brains training on data from millions of people?</em></p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">Funny anecdote from another <a href="https://deeplearning4j.org/lstm.html" target="_self">article</a>: <strong>a person is haunted by their deeds</strong></p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let‚Äôs come back to the problem at hand and rephrase the above explanation with an example to predict what the next letter is after a sequence of letters. Imagine in the word <strong>namaskar</strong>. The word is of 8 letters.</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4"><strong>namaskar</strong>: a traditional Indian greeting or gesture of respect, made by bringing the palms together before the face or chest and bowing.</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If we were trying to figure out the 8th letter after 7 letters were fed to the network, what would have happened. The hidden layer would have gone through 8 iterations. If we were to unfold the network, it would be a 8 layer network, one layer for each letter. So you can imagine that a normal neural network is repeated multiple times. The number of times you unroll has a direct correlation with how far in the past it can remember. But more on this later.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*_mM83sFLjzKt8cRB439Y3Q.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*_mM83sFLjzKt8cRB439Y3Q.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*_mM83sFLjzKt8cRB439Y3Q.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*_mM83sFLjzKt8cRB439Y3Q.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*_mM83sFLjzKt8cRB439Y3Q.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*_mM83sFLjzKt8cRB439Y3Q.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*_mM83sFLjzKt8cRB439Y3Q.gif 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*_mM83sFLjzKt8cRB439Y3Q.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*_mM83sFLjzKt8cRB439Y3Q.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*_mM83sFLjzKt8cRB439Y3Q.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*_mM83sFLjzKt8cRB439Y3Q.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*_mM83sFLjzKt8cRB439Y3Q.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*_mM83sFLjzKt8cRB439Y3Q.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*_mM83sFLjzKt8cRB439Y3Q.gif 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*_mM83sFLjzKt8cRB439Y3Q.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">how recurrent neural networks work #deeplearning4j #dl4j</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Recurrent Neuron</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here we will look in more depth regarding the actual neuron that is responsible for the decision making. We will be using the <strong>namaskar </strong>example described above. We will try to figure out the 8th letter given all the previous 7 letters. Total vocabulary of the input data is {n,a,m,s,k,r}. In real world you will have more complex words or sentences. For simplicity we will use this simple vocabulary.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:48%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 364px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:728/format:webp/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 728w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 364px" srcset="https://miro.medium.com/v2/resize:fit:640/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:728/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg 728w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/364/1*EHd7wwjnogvNvH9vHLp3Uw.jpeg"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the above diagram, the hidden layer or the RNN block applies a formula to the current input as well as the previous state. In this case the letter <code>n</code> from namaste has nothing preceding it, so we will move on to the next letter which is <code>a</code>. During the time of letter <code>a</code> and the previous state which was letter <code>n</code> the formula is applied by the hidden layer. We will go through the formula in a bit. Each state when an input passes the network is a time step or a step. So if at time t, the input is <code>a</code>, then at time t-1, the input is <code>n</code>. After applying the formula to both <code>n</code> and <code>a</code>, we get a new state.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The formula for the current state can be written like this:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:23%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 192px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*cL2HAU5Q9qcwD-LKjgPdWw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*cL2HAU5Q9qcwD-LKjgPdWw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*cL2HAU5Q9qcwD-LKjgPdWw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*cL2HAU5Q9qcwD-LKjgPdWw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*cL2HAU5Q9qcwD-LKjgPdWw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*cL2HAU5Q9qcwD-LKjgPdWw.png 1100w, https://miro.medium.com/v2/resize:fit:384/format:webp/1*cL2HAU5Q9qcwD-LKjgPdWw.png 384w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 192px" srcset="https://miro.medium.com/v2/resize:fit:640/1*cL2HAU5Q9qcwD-LKjgPdWw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*cL2HAU5Q9qcwD-LKjgPdWw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*cL2HAU5Q9qcwD-LKjgPdWw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*cL2HAU5Q9qcwD-LKjgPdWw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*cL2HAU5Q9qcwD-LKjgPdWw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*cL2HAU5Q9qcwD-LKjgPdWw.png 1100w, https://miro.medium.com/v2/resize:fit:384/1*cL2HAU5Q9qcwD-LKjgPdWw.png 384w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/192/1*cL2HAU5Q9qcwD-LKjgPdWw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><code>ht</code> is the new state and <code>ht-1</code> is the previous state. <code>xt</code> is the input at time <code>t</code>. We now have a sense of the previous inputs after it has gone through the same formula from the previous time steps. We will go through 7 such inputs to the network which passes by the same weights and same function at each step.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now let‚Äôs try to define <code>f()</code> in a simple fashion. We will take <code>tanh</code> as the activation function. The weights are defined by the matrix <code>Whh</code> and the input is defined by the matrix <code>Wxh</code>. So the formula looks like:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:45%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 346px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*rZCv_pub_2Kdzb7sqsXEsg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*rZCv_pub_2Kdzb7sqsXEsg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*rZCv_pub_2Kdzb7sqsXEsg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*rZCv_pub_2Kdzb7sqsXEsg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*rZCv_pub_2Kdzb7sqsXEsg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*rZCv_pub_2Kdzb7sqsXEsg.png 1100w, https://miro.medium.com/v2/resize:fit:692/format:webp/1*rZCv_pub_2Kdzb7sqsXEsg.png 692w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 346px" srcset="https://miro.medium.com/v2/resize:fit:640/1*rZCv_pub_2Kdzb7sqsXEsg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*rZCv_pub_2Kdzb7sqsXEsg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*rZCv_pub_2Kdzb7sqsXEsg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*rZCv_pub_2Kdzb7sqsXEsg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*rZCv_pub_2Kdzb7sqsXEsg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*rZCv_pub_2Kdzb7sqsXEsg.png 1100w, https://miro.medium.com/v2/resize:fit:692/1*rZCv_pub_2Kdzb7sqsXEsg.png 692w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/346/1*rZCv_pub_2Kdzb7sqsXEsg.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The above example takes only the last step as memory and thus merging with the data of last step. To increase the memory capacity of the network, and hold longer sequences in memory, we have to add more states to the equation, like <code>ht-2</code>, <code>ht-3</code> etc. Finally the output can be calculated as during test time:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:18%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 158px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*kBJUiDmobt-ZbzoXwUSAgw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*kBJUiDmobt-ZbzoXwUSAgw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*kBJUiDmobt-ZbzoXwUSAgw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*kBJUiDmobt-ZbzoXwUSAgw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*kBJUiDmobt-ZbzoXwUSAgw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*kBJUiDmobt-ZbzoXwUSAgw.png 1100w, https://miro.medium.com/v2/resize:fit:316/format:webp/1*kBJUiDmobt-ZbzoXwUSAgw.png 316w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 158px" srcset="https://miro.medium.com/v2/resize:fit:640/1*kBJUiDmobt-ZbzoXwUSAgw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*kBJUiDmobt-ZbzoXwUSAgw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*kBJUiDmobt-ZbzoXwUSAgw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*kBJUiDmobt-ZbzoXwUSAgw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*kBJUiDmobt-ZbzoXwUSAgw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*kBJUiDmobt-ZbzoXwUSAgw.png 1100w, https://miro.medium.com/v2/resize:fit:316/1*kBJUiDmobt-ZbzoXwUSAgw.png 316w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/158/1*kBJUiDmobt-ZbzoXwUSAgw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">where <code>yt</code> is the output. The output is compared to the actual output and then an error value is computed. The network learns by back propagating the error via the network to update the weights. We will talk about backpropagation in the next section.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Backpropagation Through Time (BPTT)</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This section considers that you are aware of Backpropagation as a concept. If you need to understand Backpropagation then please visit this <a href="http://cs231n.github.io/optimization-2/" target="_self">link </a>to read more.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So now we understand how a RNN actually works, but how does the training actually work? How do we decide the weights for each connection? And how do we initialise these weights for these hidden units. The purpose of recurrent nets is to accurately classify sequential input. We rely on the backpropagation of error and gradient descent to do so. But a standard backpropagation like how used in feed forward networks can‚Äôt be used here.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The problem with RNNs is that they are cyclic graphs unlike feed-forward networks which are acyclic directional graphs. In feed-forward networks we could calculate the error derivatives from the layer above. In a RNN we don‚Äôt have such layering.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The answer lies in what we had discussed above. We need to unroll the network. We will unroll it and make it look like a feed-forward network.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*T1_uXU6oW4Bt5UFoaqvAiw.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Unrolling a RNN</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We take a RNN‚Äôs hidden units and replicate it for every time step. Each replication through time step is like a layer in a feed-forward network. Each time step <code>t</code> layer connects to all possible layers in the time step <code>t+1</code>. Thus we randomly initialise the weights, unroll the network and then use backpropagation to optimise the weights in the hidden layer. Initialisation is done by passing parameters to the lowest layer. These parameters are also optimised as a part of backpropagation.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">An outcome of the unrolling is that each layer now starts maintaining different weights and thus end up getting optimised differently. The errors calculated w.r.t the weights are not guaranteed to be equal. So each layer can have different weights at the end of a single run. We definitely don‚Äôt want that to happen. The easy solution out is to aggregate the errors across all the layers in some fashion. We can average out the errors or even sum them up. This way we can have a single layer in all time steps to maintain the same weights.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">RNN Implementation</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here is a sample code where we have tried to implement a RNN using Keras models. Here is the direct link to the <a href="https://gist.github.com/09aefc5231972618d2c13ccedb0e22cc.git" target="_self">gist</a>. We are trying to predict the next sequence given a set of text.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This model was built by <a href="https://github.com/yashk2810/Predicting-Next-Character-using-RNN" target="_self">Yash Katariya</a>. I have updated the code slightly to fit the requirements of this article. The code is commented as you go along, it‚Äôs pretty self explanatory.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*HwRiD82qcfUfMJiGiEcBeA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*HwRiD82qcfUfMJiGiEcBeA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*HwRiD82qcfUfMJiGiEcBeA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*HwRiD82qcfUfMJiGiEcBeA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*HwRiD82qcfUfMJiGiEcBeA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*HwRiD82qcfUfMJiGiEcBeA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HwRiD82qcfUfMJiGiEcBeA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*HwRiD82qcfUfMJiGiEcBeA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*HwRiD82qcfUfMJiGiEcBeA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*HwRiD82qcfUfMJiGiEcBeA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*HwRiD82qcfUfMJiGiEcBeA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*HwRiD82qcfUfMJiGiEcBeA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*HwRiD82qcfUfMJiGiEcBeA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*HwRiD82qcfUfMJiGiEcBeA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*HwRiD82qcfUfMJiGiEcBeA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Conclusion</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Well so we have come to the end of this article. What we have discussed so far is just a basic implementation of a RNN. There are so many things that we need to cover to get a full understanding on this topic. I‚Äôll be writing a second article within a week. I will try to cover the following topics.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">Vanishing and Exploding Gradients</li><li class="ff3" style="font-size:22px;">The Problem of Long-Term Dependencies</li><li class="ff3" style="font-size:22px;">Long Short Term Memory networks(LSTM)</li><li class="ff3" style="font-size:22px;">LSTM Gate</li><li class="ff3" style="font-size:22px;">Bidirectional RNNs</li><li class="ff3" style="font-size:22px;">Deep (Bidirectional) RNNs</li><li class="ff3" style="font-size:22px;">GRU (Gated Recurrent Unit) Cells</li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you want me to cover things apart from this, please drop a message in the comments section. RNNs are really powerful stuff, and it is very close to how a human brain seems to work. I will be looking out for more development in this area and also am personally working on this. Any improvement I‚Äôll surely share here. So please follow me either here on <a href="https://medium.com/@debarko" target="_self">Medium</a> or on <a href="https://twitter.com/debarko" target="_self">Twitter</a> to stay updated.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7"><strong>If you liked this article, please hit the üëè button to support it. This will help other Medium users find it. </strong><a href="http://twitter.com/intent/tweet?text=%40debarko%20just%20released%20an%20article%20on%20%23RNN.%20It%20talks%20about%20how%20you%20can%20build%20a%20%23RecurrentNeuralNetwork%20%F0%9F%9A%80and%20its%20workings.%20%23AI%20%23ML%20%23NeuralNetworks%20%23MachineLearning%20https%3A%2F%2Fgoo.gl%2FFPPwYN" target="_self">Share this on Twitter</a><strong> to help out reach as many readers as possible.</strong></h4></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>