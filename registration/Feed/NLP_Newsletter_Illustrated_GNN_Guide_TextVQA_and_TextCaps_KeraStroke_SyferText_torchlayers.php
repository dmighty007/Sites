<!DOCTYPE html>
                <html>
                <head>
                    <title>NLP Newsletter: Illustrated GNN Guide, TextVQA and TextCaps, KeraStroke, SyferText, torchlayers,…</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/dair-ai/nlp-newsletter-illustrated-gnn-guide-textvqa-and-textcaps-kerastroke-syfertext-torchlayers-482da18a8cd9"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@ibelmopan?source=post_page-----482da18a8cd9--------------------------------">Author : elvis</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>NLP Newsletter: Illustrated GNN Guide, TextVQA and TextCaps, KeraStroke, SyferText, torchlayers,…</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5 text-muted">This issue includes topics that range from a privacy-preserving NLP tool to interactive tools for searching COVID-19 related papers to an illustrated guide to graph neural networks.</h4></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Vq-bFSTjqYjDGAR4Ja1abw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Vq-bFSTjqYjDGAR4Ja1abw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Vq-bFSTjqYjDGAR4Ja1abw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Vq-bFSTjqYjDGAR4Ja1abw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Vq-bFSTjqYjDGAR4Ja1abw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Vq-bFSTjqYjDGAR4Ja1abw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vq-bFSTjqYjDGAR4Ja1abw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Vq-bFSTjqYjDGAR4Ja1abw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Vq-bFSTjqYjDGAR4Ja1abw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Vq-bFSTjqYjDGAR4Ja1abw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Vq-bFSTjqYjDGAR4Ja1abw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Vq-bFSTjqYjDGAR4Ja1abw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Vq-bFSTjqYjDGAR4Ja1abw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Vq-bFSTjqYjDGAR4Ja1abw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*Vq-bFSTjqYjDGAR4Ja1abw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Welcome to the 9th issue of the NLP Newsletter. We hope that you and your loved ones are well and staying safe. This issue includes topics that range from a privacy-preserving NLP tool to interactive tools for searching COVID-19 related papers to an illustrated guide to graph neural networks.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Research and Publications 📙</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Neuroevolution of Self-Interpretable Agents</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Tang et al. (2020) present an interesting and creative <a href="https://attentionagent.github.io/" target="_self">work</a> that aims to evolve an agent to take a fraction of its visual input with the goal to survive a task (e.g. avoid crashing on a curve and dodging fireballs, as seen in the figure below). Using <a href="https://en.wikipedia.org/wiki/Neuroevolution" target="_self">neuroevolution</a> to train <em>self-attention architectures,</em> the authors were able to train reinforcement learning agents to perform different tasks while only allowing a fraction of the input. The benefits of the model include a substantial reduction in the size of parameters, policy interpretability, and enabling the model to attend to only the t<em>ask-critical visual hints.</em></p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Gm8jlCUvP_JECEPspDypWg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Gm8jlCUvP_JECEPspDypWg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Gm8jlCUvP_JECEPspDypWg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Gm8jlCUvP_JECEPspDypWg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Gm8jlCUvP_JECEPspDypWg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Gm8jlCUvP_JECEPspDypWg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gm8jlCUvP_JECEPspDypWg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Gm8jlCUvP_JECEPspDypWg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Gm8jlCUvP_JECEPspDypWg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Gm8jlCUvP_JECEPspDypWg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Gm8jlCUvP_JECEPspDypWg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Gm8jlCUvP_JECEPspDypWg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Gm8jlCUvP_JECEPspDypWg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Gm8jlCUvP_JECEPspDypWg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*Gm8jlCUvP_JECEPspDypWg.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Introducing RONEC — the Romanian Named Entity Corpus</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://arxiv.org/abs/1909.01247" target="_self">RONEC</a> is a named entity corpus for the Romanian language that contains over 26000 entities in ~5000 annotated sentences, belonging to 16 distinct classes. The sentences have been extracted from a copy-right free newspaper, covering several styles. This corpus represents the first initiative in the Romanian language space specifically targeted for named entity recognition. It is available in BIO and CoNLL-U Plus formats, and it is free to use and extend <a href="https://github.com/dumitrescustefan/ronec" target="_self">here</a>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Scaling Laws for Neural Language Models</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Researchers from John Hopkins and OpenAI have conducted an empirical <a href="https://arxiv.org/abs/2001.08361" target="_self">study</a> to understand the scaling laws for language model performance. This type of study can be used as a guide to making better decisions on how to more effectively use resources. Overall, it was found that larger models are significantly more sample-efficient; if there is limited compute and data, it is better to train a large model with a few steps of training as opposed to training a smaller model until it converges (see results summarized in the figure below). Authors provide more findings and recommendations when training large language models (e.g. Transformers) in the aspects of overfitting, choosing the optimal batch size, fine-tuning, architecture decisions, etc.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*plbjqswVe4Cq8UVggqPH1w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*plbjqswVe4Cq8UVggqPH1w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*plbjqswVe4Cq8UVggqPH1w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*plbjqswVe4Cq8UVggqPH1w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*plbjqswVe4Cq8UVggqPH1w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*plbjqswVe4Cq8UVggqPH1w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*plbjqswVe4Cq8UVggqPH1w.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*plbjqswVe4Cq8UVggqPH1w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*plbjqswVe4Cq8UVggqPH1w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*plbjqswVe4Cq8UVggqPH1w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*plbjqswVe4Cq8UVggqPH1w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*plbjqswVe4Cq8UVggqPH1w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*plbjqswVe4Cq8UVggqPH1w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*plbjqswVe4Cq8UVggqPH1w.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*plbjqswVe4Cq8UVggqPH1w.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><a href="https://arxiv.org/abs/2001.08361" target="_self">Kaplan et al. (2020)</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Calibration of Pre-trained Transformers</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">With pre-trained Transformers being used increasingly in real-world applications, it is important to understand how <em>trustworthy</em> their outputs are. Recent <a href="https://arxiv.org/abs/2003.07892" target="_self">work</a> by UT Austin shows BERT and RoBERTa’s posterior probabilities are relatively calibrated (i.e., consistent with empirical outcomes) on three tasks (natural language inference, paraphrase detection, commonsense reasoning) with both in-domain and challenging out-of-domain datasets. Results show that: (1) when used out-of-the-box, pre-trained models are calibrated in-domain; and (2) temperature scaling is effective at further reducing calibration error in-domain, while label smoothing to increase empirical uncertainty helps calibrate posteriors out-of-domain.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:87%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 643px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ose0s-G0WfPFoleZJ1htrQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ose0s-G0WfPFoleZJ1htrQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ose0s-G0WfPFoleZJ1htrQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ose0s-G0WfPFoleZJ1htrQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ose0s-G0WfPFoleZJ1htrQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ose0s-G0WfPFoleZJ1htrQ.png 1100w, https://miro.medium.com/v2/resize:fit:1286/format:webp/1*ose0s-G0WfPFoleZJ1htrQ.png 1286w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 643px" srcset="https://miro.medium.com/v2/resize:fit:640/1*ose0s-G0WfPFoleZJ1htrQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ose0s-G0WfPFoleZJ1htrQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ose0s-G0WfPFoleZJ1htrQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ose0s-G0WfPFoleZJ1htrQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ose0s-G0WfPFoleZJ1htrQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ose0s-G0WfPFoleZJ1htrQ.png 1100w, https://miro.medium.com/v2/resize:fit:1286/1*ose0s-G0WfPFoleZJ1htrQ.png 1286w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/643/1*ose0s-G0WfPFoleZJ1htrQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><a href="https://arxiv.org/pdf/2003.07892.pdf" target="_self">Desai and Durrett (2020)</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Statistical Mechanics of Deep Learning</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A recent <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-conmatphys-031119-050745" target="_self">paper</a> takes a closer look at the connection between physical/mathematical topics and deep learning. The authors aim to discuss deeper topics intersecting statistical mechanics and machine learning with the objective of answering questions that help to understand the theoretical side of deep neural networks and why they have been successful.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Towards an ImageNet Moment for Speech-to-Text</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In a new <a href="https://thegradient.pub/towards-an-imagenet-moment-for-speech-to-text/" target="_self">article</a> published in The Gradient, Alexander Veysov explains why they believe that the ImageNet moment for Speech-to-Text (STT) has arrived in the context of the Russian Language. In the last couple of years, researchers have also made this claim about NLP. However, in order to achieve such a moment in STT, Alexander claims that many pieces have to come together, such as making models widely available, minimize computational requirements and improve the accessibility of pre-trained large models.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Creativity, Ethics, and Society 🌎</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Browsing and searching COVID-19 related articles</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Last week we featured a public dataset called <a href="https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge" target="_self">CORD-19</a> which contains COVID-related papers. Gabriele Sarti wrote an <a href="https://github.com/gsarti/covid-papers-browser" target="_self">interactive tool </a>that allows you to more efficiently search and browse through these papers by leveraging a <a href="https://huggingface.co/gsarti/scibert-nli" target="_self">SciBERT fine-tuned model</a>.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*tu8nzUIEuSizuW5-.gif 640w, https://miro.medium.com/v2/resize:fit:720/0*tu8nzUIEuSizuW5-.gif 720w, https://miro.medium.com/v2/resize:fit:750/0*tu8nzUIEuSizuW5-.gif 750w, https://miro.medium.com/v2/resize:fit:786/0*tu8nzUIEuSizuW5-.gif 786w, https://miro.medium.com/v2/resize:fit:828/0*tu8nzUIEuSizuW5-.gif 828w, https://miro.medium.com/v2/resize:fit:1100/0*tu8nzUIEuSizuW5-.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/0*tu8nzUIEuSizuW5-.gif 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*tu8nzUIEuSizuW5-.gif 640w, https://miro.medium.com/v2/resize:fit:720/0*tu8nzUIEuSizuW5-.gif 720w, https://miro.medium.com/v2/resize:fit:750/0*tu8nzUIEuSizuW5-.gif 750w, https://miro.medium.com/v2/resize:fit:786/0*tu8nzUIEuSizuW5-.gif 786w, https://miro.medium.com/v2/resize:fit:828/0*tu8nzUIEuSizuW5-.gif 828w, https://miro.medium.com/v2/resize:fit:1100/0*tu8nzUIEuSizuW5-.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/0*tu8nzUIEuSizuW5-.gif 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*tu8nzUIEuSizuW5-.gif"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">reciTAL has also released a project called <a href="https://covidsmartsearch.recital.ai/" target="_self">COVID-19 Smart Search Engine</a> to help improve search and browse on COVID-19 related articles with the goal to help researchers and healthcare professionals to quickly and efficiently find and discover information related to COVID-19.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Y5W3sib4y6UxSr3YkQSu5Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Y5W3sib4y6UxSr3YkQSu5Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Y5W3sib4y6UxSr3YkQSu5Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Y5W3sib4y6UxSr3YkQSu5Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Y5W3sib4y6UxSr3YkQSu5Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Y5W3sib4y6UxSr3YkQSu5Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y5W3sib4y6UxSr3YkQSu5Q.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Y5W3sib4y6UxSr3YkQSu5Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Y5W3sib4y6UxSr3YkQSu5Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Y5W3sib4y6UxSr3YkQSu5Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Y5W3sib4y6UxSr3YkQSu5Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Y5W3sib4y6UxSr3YkQSu5Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Y5W3sib4y6UxSr3YkQSu5Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Y5W3sib4y6UxSr3YkQSu5Q.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*Y5W3sib4y6UxSr3YkQSu5Q.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>SyferText</strong>OpenMined releases <a href="https://github.com/OpenMined/SyferText" target="_self">SyferText</a>, a new privacy-preserving NLP library that aims to enable secure and private NLP and processing of text for private datasets. It is in its early stages but we believe this is a very important effort towards safer and ethical AI systems. Here are some <a href="https://github.com/OpenMined/SyferText/tree/master/tutorials" target="_self">tutorials</a> to get started.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>David over Goliath: towards smaller models for cheaper, faster, and greener NLP</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Is bigger always better? When looking at the evolution of language model size in the past few years, one may think the answer is yes. Yet, the financial and environmental cost of training such monsters is very high. Also, bigger in this case usually means slower, but speed is critical in most applications. This motivates the current trend in NLP pushing for smaller, faster, and greener models while preserving performance. In this blog post, <a href="https://www.linkedin.com/in/ACoAABs605YB_jMmGA0iLFongpVm1iKjFmKLSts/" target="_self">Manuel Tonneau</a> presents this new trend favoring smaller models focusing on three recent and popular models, DistilBERT from <a href="https://www.linkedin.com/company/huggingface/" target="_self">Hugging Face</a>, PD-BERT from <a href="https://www.linkedin.com/company/google/" target="_self">Google</a> and BERT-of-Theseus from <a href="https://www.linkedin.com/company/microsoft/" target="_self">Microsoft</a>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>A Survey of Deep Learning for Scientific Discovery</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Many of the large companies today that have focused efforts in AI research believe that deep learning can be used as a tool for scientific discovery. This <a href="https://arxiv.org/abs/2003.11755" target="_self">paper</a> provides a comprehensive overview of the commonly used deep learning models for different scientific use cases. The paper also shares implementation tips, tutorials, other research summaries, and tools.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Tools and Datasets ⚙️</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>TextVQA and TextCaps</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In an effort to encourage building models that can better detect and read the text in images and further reason about it to answer questions and generate captions, Facebook AI is hosting two separate competitions. The competitions are called <a href="https://textvqa.org/challenge" target="_self">TextVQA</a> Challenge and <a href="https://textvqa.org/textcaps/challenge" target="_self">TextCaps</a> Challenge to address the visual question answering and caption generation tasks, respectively.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>KeraStroke</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">One of the largest hurdles to overcome while designing neural nets is overfitting. Current generalization-improvement techniques such as Dropout, Regularization, and Early Stopping are very effective for most use cases, however, they can tend to fall short when using large models or smaller datasets. In response to this, Charles Averill has developed <a href="https://pypi.org/project/kerastroke/#description" target="_self">KeraStroke</a>, a novel generalization-improvement technique suite useful for large models or small datasets. By altering weight values in certain cases during training, models dynamically adapt to the training data they’re being fed.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>torchlayers</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://github.com/szymonmaszke/torchlayers" target="_self">torchlayers</a> is a new tool built on top of PyTorch that allows for automatic shape and dimensionality inference of layers available in the torch.nn module such as convolutional, recurrent, transformer, etc. This means that you don’t need to explicitly define the shape of input features which has to be specified manually in the layers. This simplifies a model’s definition in PyTorch. See an example of a basic classifier implemented with torchlayers below:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:71%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 525px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*tHOme2pZ39sNziqdUCsn4g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*tHOme2pZ39sNziqdUCsn4g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*tHOme2pZ39sNziqdUCsn4g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*tHOme2pZ39sNziqdUCsn4g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*tHOme2pZ39sNziqdUCsn4g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*tHOme2pZ39sNziqdUCsn4g.png 1100w, https://miro.medium.com/v2/resize:fit:1050/format:webp/1*tHOme2pZ39sNziqdUCsn4g.png 1050w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 525px" srcset="https://miro.medium.com/v2/resize:fit:640/1*tHOme2pZ39sNziqdUCsn4g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*tHOme2pZ39sNziqdUCsn4g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*tHOme2pZ39sNziqdUCsn4g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*tHOme2pZ39sNziqdUCsn4g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*tHOme2pZ39sNziqdUCsn4g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*tHOme2pZ39sNziqdUCsn4g.png 1100w, https://miro.medium.com/v2/resize:fit:1050/1*tHOme2pZ39sNziqdUCsn4g.png 1050w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/525/1*tHOme2pZ39sNziqdUCsn4g.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">We can see from the code snippet that the Linear layer only requires the size of output features as opposed to both the output and input size. This is inferred by the torchlayers based on the input size.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Haystack: Open-Source Framework for Question Answering at Scale</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://github.com/deepset-ai/haystack/" target="_self">Haystack</a> allows you to use transformer models at scale for question-answering. It uses a Retriever-Reader-Pipeline, where the Retriever is a fast algorithm to find candidate documents and the Reader is a Transformer that extracts the granular answer. It’s building upon Hugging Face’s Transformers and Elasticsearch. It’s open-source, highly modular and easy to extend.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Teaching an AI to summarise news articles: A new dataset for abstractive summarisation</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Curation Corp is open-sourcing 40,000 professionally-written summaries of news articles. This <a href="https://medium.com/curation-corporation/teaching-an-ai-to-abstract-a-new-dataset-for-abstractive-auto-summarisation-5227f546caa8" target="_self">article</a> provides a nice introduction to text summarisation and challenges that exist with this particular task. In addition, it introduces the dataset, the problems that can be addressed with it, including a discussion around fine-tuning methods and evaluation metrics for text summarization, and wrapping up with a discussion for the future work. Instructions for how to access the dataset can be found in this <a href="https://github.com/CurationCorp/curation-corpus" target="_self">Github repository</a>, along with <a href="https://github.com/CurationCorp/curation-corpus/tree/master/examples" target="_self">examples</a> of using the dataset for fine-tuning.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">On the topic of text summarization, the HuggingFace team has added both <a href="https://github.com/pytorch/fairseq/blob/master/examples/bart/README.md" target="_self">BART</a> and <a href="https://github.com/dair-ai/nlp_paper_summaries/blob/master/Language%20Modeling/t5-text-to-text-transformer.md" target="_self">T5</a> as part of their <a href="https://github.com/huggingface/transformers/releases" target="_self">Transformers</a> library. These additions allow for all sorts of NLP tasks such as abstractive summarization, translation, and question-answering, among others.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Articles and Blog posts ✍️</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>An Illustrated Guide to Graph Neural Networks</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Graph neural networks have recently seen more adoption for tasks such as enhancing computer vision models and predicting side-effects due to drug interactions. In this <a href="https://dair.ai/An_Illustrated_Guide_to_Graph_Neural_Networks/" target="_self">overview</a>, Rish presents an intuitive and illustrated guide to GNNs. (<em>Featured on </em><a href="https://dair.ai/" target="_self">dair.ai</a>)</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/format:webp/1*Ru3CizrB14hvpZQ7ZtgIag.png 640w, https://miro.medium.com/v2/format:webp/1*Ru3CizrB14hvpZQ7ZtgIag.png 720w, https://miro.medium.com/v2/format:webp/1*Ru3CizrB14hvpZQ7ZtgIag.png 750w, https://miro.medium.com/v2/format:webp/1*Ru3CizrB14hvpZQ7ZtgIag.png 786w, https://miro.medium.com/v2/format:webp/1*Ru3CizrB14hvpZQ7ZtgIag.png 828w, https://miro.medium.com/v2/format:webp/1*Ru3CizrB14hvpZQ7ZtgIag.png 1100w, https://miro.medium.com/v2/format:webp/1*Ru3CizrB14hvpZQ7ZtgIag.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/1*Ru3CizrB14hvpZQ7ZtgIag.png 640w, https://miro.medium.com/v2/1*Ru3CizrB14hvpZQ7ZtgIag.png 720w, https://miro.medium.com/v2/1*Ru3CizrB14hvpZQ7ZtgIag.png 750w, https://miro.medium.com/v2/1*Ru3CizrB14hvpZQ7ZtgIag.png 786w, https://miro.medium.com/v2/1*Ru3CizrB14hvpZQ7ZtgIag.png 828w, https://miro.medium.com/v2/1*Ru3CizrB14hvpZQ7ZtgIag.png 1100w, https://miro.medium.com/v2/1*Ru3CizrB14hvpZQ7ZtgIag.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/proxy/1*Ru3CizrB14hvpZQ7ZtgIag.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Finetuning Transformers with JAX + Haiku</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Just last month DeepMind open-sourced Haiku, the JAX version of their TensorFlow neural network library Sonnet. This <a href="https://www.pragmatic.ml/finetuning-transformers-with-jax-and-haiku/" target="_self">post</a> walks through the full source of a port of the RoBERTa pre-trained model to JAX + Haiku, then demonstrates finetuning the model to solve a downstream task. It’s intended to be a practical guide to using the utilities Haiku exposes for allowing the use of light object-oriented “modules” within the context of JAX’s functional programming constraints.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>A small journey in the valley of Natural Language Processing and Text Pre-Processing for German language</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Flávio Clésio<strong> </strong>wrote a very detailed <a href="https://flavioclesio.com/2020/02/17/a-small-journey-in-the-valley-of-natural-language-processing-and-text-pre-processing-for-german-language/" target="_self">article</a> about the challenges of dealing with NLP problems in the German language. He shares many lessons learned, what worked and didn’t work, discusses several state-of-the-art methods, common issues to avoid, and a ton of learning resources, papers and blog posts.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>French language keeping pace with AI: FlauBERT, CamemBERT, PIAF</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Over the last few months, interesting French NLP resources were developed. We are talking about CamemBERT, FlauBERT, and PIAF (Pour une IA Francophone, For a French Speaking AI). The first two are pre-trained language models and the last one is a native French Question-Answering (QA) dataset. This <a href="https://piaf.etalab.studio/francophonie-ia-english/" target="_self">blog post</a> discusses all these three projects and some of the challenges presented along the way. This is a nice read and guide for those people working on different models in their own language.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Custom classifier on top of BERT-like language model</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Marcin wrote another excellent <a href="https://zablo.net/blog/post/custom-classifier-on-bert-model-guide-polemo2-sentiment-analysis/" target="_self">guide</a> showing how to build your own classifier (e.g. sentiment classifier) on top of BERT-like language models. It’s a great tutorial because it also shows how to use other modern libraries for the different parts of the model such as HuggingFace Tokenizer and PyTorchLightning. Find the Google Colab notebook <a href="https://colab.research.google.com/drive/1sajgpLTrTJDzRSlxycy8aE6ysxGqaT18" target="_self">here</a>.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*66IKvwYU2Lq1kjyn.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*66IKvwYU2Lq1kjyn.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*66IKvwYU2Lq1kjyn.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*66IKvwYU2Lq1kjyn.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*66IKvwYU2Lq1kjyn.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*66IKvwYU2Lq1kjyn.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*66IKvwYU2Lq1kjyn.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*66IKvwYU2Lq1kjyn.png 640w, https://miro.medium.com/v2/resize:fit:720/0*66IKvwYU2Lq1kjyn.png 720w, https://miro.medium.com/v2/resize:fit:750/0*66IKvwYU2Lq1kjyn.png 750w, https://miro.medium.com/v2/resize:fit:786/0*66IKvwYU2Lq1kjyn.png 786w, https://miro.medium.com/v2/resize:fit:828/0*66IKvwYU2Lq1kjyn.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*66IKvwYU2Lq1kjyn.png 1100w, https://miro.medium.com/v2/resize:fit:1400/0*66IKvwYU2Lq1kjyn.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*66IKvwYU2Lq1kjyn.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><a href="https://zablo.net/blog/post/custom-classifier-on-bert-model-guide-polemo2-sentiment-analysis/" target="_self">Source</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Education 🎓</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Exploratory Data Analysis for Text Data</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this <a href="https://dair.ai/Exploratory_Data_Analysis_for_Text_Data/" target="_self">code walkthrough</a>, Yonathan Hadar goes through several methods for exploratory analysis of textual data with various code examples. We featured this tutorial at dair.ai because it is a very comprehensive tutorial that uses standard methods for analyzing data that any data scientist will find useful. It’s a good starting point for anyone starting to play with textual data.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Embeddings in Natural Language Processing</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Mohammad Taher Pilehvar and Jose Camacho-Collados publicly released their first draft of an upcoming <a href="http://josecamachocollados.com/book_embNLP_draft.pdf" target="_self">book</a> called “Embeddings in Natural Language Processing”. The idea with this book is to discuss the concept of embeddings which represent some of the most widely used techniques in NLP. As <a href="https://twitter.com/CamachoCollados/status/1246013768074747906?s=20" target="_self">stated</a> by the authors, the book includes “basics in vector space models and word embeddings to more recent sentence and contextualized embedding techniques based on pre-trained language models.”</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>A Brief Guide to Artificial Intelligence</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Dr. James V Stone recently published his new <a href="https://jim-stone.staff.shef.ac.uk/AIGuide/" target="_self">book</a> on “A Brief Guide to Artificial Intelligence” with the goal to provide a comprehensive overview of current AI systems and their achievement to perform a series of tasks. As stated in the summary, the book is “written in an informal style, with a comprehensive glossary and a list of further readings, which makes it an ideal introduction to the rapidly evolving field of AI.”</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*I2YYXTCQTBmk_YiF.jpg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*I2YYXTCQTBmk_YiF.jpg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*I2YYXTCQTBmk_YiF.jpg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*I2YYXTCQTBmk_YiF.jpg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*I2YYXTCQTBmk_YiF.jpg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*I2YYXTCQTBmk_YiF.jpg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*I2YYXTCQTBmk_YiF.jpg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*I2YYXTCQTBmk_YiF.jpg 640w, https://miro.medium.com/v2/resize:fit:720/0*I2YYXTCQTBmk_YiF.jpg 720w, https://miro.medium.com/v2/resize:fit:750/0*I2YYXTCQTBmk_YiF.jpg 750w, https://miro.medium.com/v2/resize:fit:786/0*I2YYXTCQTBmk_YiF.jpg 786w, https://miro.medium.com/v2/resize:fit:828/0*I2YYXTCQTBmk_YiF.jpg 828w, https://miro.medium.com/v2/resize:fit:1100/0*I2YYXTCQTBmk_YiF.jpg 1100w, https://miro.medium.com/v2/resize:fit:1400/0*I2YYXTCQTBmk_YiF.jpg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*I2YYXTCQTBmk_YiF.jpg"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>ML and Deep Learning Courses</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Sebastian Raschka has released two recorded <a href="https://www.youtube.com/watch?time_continue=1&v=QQD9Y2FiotQ&feature=emb_logo" target="_self">episodes</a> for his course on “Introduction to Deep Learning and Generative Models”. You can find lecture notes and other materials in this <a href="https://github.com/rasbt/stat453-deep-learning-ss20" target="_self">repo</a>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here is another excellent set of <a href="https://www.youtube.com/watch?v=e-erMrqBd1w&feature=youtu.be" target="_self">lectures</a> on the topic of “Discrete Differential Geometry”.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Peter Bloem has released the full <a href="https://mlvu.github.io/" target="_self">syllabus</a>, including videos and lecture slides, for their introductory course on Machine Learning delivered at the VU University Amsterdam. Topics range from linear models and search to probabilistic models to models for sequential data.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>CNN Architecture — Implementations</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Dimitris Katsios provides a set of excellent <a href="https://github.com/Machine-Learning-Tokyo/CNN-Architectures/tree/master/Implementations" target="_self">tutorials</a> that provide guidance on how to implement convolutional neural network (CNN) architectures from original papers. He proposes a recipe on how to go about implementing these while sharing the step-by-step that includes diagrams and code with the ability to infer the structure of the model. There is a lot to learn from these guides in terms of guiding others to more efficiently implementing papers.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Noteworthy Mentions ⭐️</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You can find the previous newsletter <a href="https://dair.ai/NLP_Newsletter_8/" target="_self">here</a>. You can also find the translated versions of the previous issues of the NLP Newsletter <a href="https://github.com/dair-ai/nlp_newsletter" target="_self">here</a>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A couple of months back we featured Luis Serrano’s excellent book on Grokking Machine Learning. <a href="https://content.alegion.com/podcast/grokking-machine-learning-with-luis-serrano" target="_self">Listen</a> to Luis discuss a bit more about his book and his journey to becoming a successful educator in the field of ML.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here are several newsletters that may be worth your attention: <a href="http://newsletter.ruder.io/" target="_self">Sebastian Ruder’s NLP News</a>, <a href="https://madewithml.com/blog/newsletter/2020-03-25/" target="_self">Made With ML</a>, <a href="https://sigtyp.github.io/sigtyp-newsletter-Mar-2020.html" target="_self">SIGTYP’s newsletter</a>, <a href="https://mailchi.mp/c70ebcf424b2/mlt-newsletter-6" target="_self">MLT Newsletter</a>, <a href="http://newsletter.airstreet.com/issues/your-guide-to-ai-in-q1-2020-part-1-2-212335" target="_self">Nathan’s AI newsletter</a>, etc…</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Jupyter now comes with a <a href="https://blog.jupyter.org/a-visual-debugger-for-jupyter-914e61716559" target="_self">visual debugger.</a> This will allow this popular data science framework to be used more easily for general purposes.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*FE5Fj5DFb0U9565a.gif 640w, https://miro.medium.com/v2/resize:fit:720/0*FE5Fj5DFb0U9565a.gif 720w, https://miro.medium.com/v2/resize:fit:750/0*FE5Fj5DFb0U9565a.gif 750w, https://miro.medium.com/v2/resize:fit:786/0*FE5Fj5DFb0U9565a.gif 786w, https://miro.medium.com/v2/resize:fit:828/0*FE5Fj5DFb0U9565a.gif 828w, https://miro.medium.com/v2/resize:fit:1100/0*FE5Fj5DFb0U9565a.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/0*FE5Fj5DFb0U9565a.gif 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*FE5Fj5DFb0U9565a.gif 640w, https://miro.medium.com/v2/resize:fit:720/0*FE5Fj5DFb0U9565a.gif 720w, https://miro.medium.com/v2/resize:fit:750/0*FE5Fj5DFb0U9565a.gif 750w, https://miro.medium.com/v2/resize:fit:786/0*FE5Fj5DFb0U9565a.gif 786w, https://miro.medium.com/v2/resize:fit:828/0*FE5Fj5DFb0U9565a.gif 828w, https://miro.medium.com/v2/resize:fit:1100/0*FE5Fj5DFb0U9565a.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/0*FE5Fj5DFb0U9565a.gif 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*FE5Fj5DFb0U9565a.gif"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Abhishek Thakur has a great YouTube <a href="https://www.youtube.com/channel/UCBPRJjIWfyNG4X-CRbnv78A" target="_self">channel</a> where he walks through code showing how to use modern methods in machine learning and NLP. Some of his videos range from fine-tuning BERT models to performing handwritten grapheme classification to building a machine learning framework.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">David Silver, a renowned reinforcement learning professor and researcher, is <a href="https://awards.acm.org/about/2019-acm-prize" target="_self">awarded</a> the ACM Prize in Computing for breakthrough advances in computer game-playing. Silver lead the Alpha Go team that beat Lee Sedol in Go.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For those interested to learn the differences and the inner working behind popular methods for NLP such as BERT and word2vec, Mohd <a href="https://www.analyticsvidhya.com/blog/2019/09/demystifying-bert-groundbreaking-nlp-framework/" target="_self">provides</a> an excellent, approachable, and detailed overview of these approaches.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">TensorFlow 2.2.0-rc-1 has been <a href="https://github.com/tensorflow/tensorflow/releases/tag/v2.2.0-rc1?linkId=85073218" target="_self">released</a>. It includes features such as a Profiler that helps spot bottlenecks in your ML models and guide optimization of these models. Also, Colab now uses TensorFlow 2 by <a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/advanced.ipynb?linkId=85251566" target="_self">default</a>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Gabriel Peyré provides a nice set of <a href="https://mathematical-tours.github.io/book-sources/optim-ml/OptimML.pdf" target="_self">notes</a> for his course on ML optimization. Notes include convex analysis, SGD, autodiff, MLP, among other topics.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">dair.ai updates</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><strong>Call for Contributions to Open Science: </strong>We have opened a call for contributions to open science. There are many interesting collaborations in the pipeline. We want to open the invitation to anyone that’s interested in contributing to open science. Looking for volunteers, writers, reviewers, editors, developers, speakers, researchers, project maintainers,… <a href="https://github.com/dair-ai/dair-ai.github.io/issues/54" target="_self">Join us</a>!</li><li class="ff3" style="font-size:22px;"><strong>NLP Research Highlights Issue #1:</strong> ICYMI, in this <a href="https://dair.ai/NLP_Research_Highlights_-_Issue_-1/" target="_self">article</a> we highlight some NLP trends and topics with a focus on summarizing the what, how, and why of a selection of interesting and important NLP papers published in the last few months.</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you have any datasets, projects, blog posts, tutorials, or papers that you wish to share in the next issue of the NLP Newsletter, please submit them directly using this <a href="https://forms.gle/3b7Q2w2bzsXE6uYo9" target="_self">form</a>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://dair.ai/newsletter/" target="_self">Subscribe</a><em> 🔖 to the NLP Newsletter to receive future issues in your inbox.</em></p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>