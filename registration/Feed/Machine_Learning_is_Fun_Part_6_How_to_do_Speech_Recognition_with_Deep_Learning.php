<!DOCTYPE html>
                <html>
                <head>
                    <title>Machine Learning is Fun Part 6: How to do Speech Recognition with Deep Learning</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@ageitgey?source=post_page-----28293c162f7a--------------------------------">Author : Adam Geitgey</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Machine Learning is Fun Part 6: How to do Speech Recognition with Deep Learning</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Update:</strong><em> This article is part of a series. Check out the full series: </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471" target="_self">Part 1</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3" target="_self">Part 2</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721" target="_self">Part 3</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78" target="_self">Part 4</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa" target="_self">Part 5</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a" target="_self">Part 6</a><em>, </em><a href="https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7" target="_self">Part 7</a><em> and </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-8-how-to-intentionally-trick-neural-networks-b55da32b7196" target="_self">Part 8</a><em>! You can also read this article in </em><a href="https://zhuanlan.zhihu.com/p/24703268" target="_self">普通话</a><em> , </em><a href="https://medium.com/@jongdae.lim/기계-학습-machine-learning-은-즐겁다-part-6-eb0ed6b0ed1d" target="_self">한국어</a><em>, </em><a href="https://viblo.asia/p/machine-learning-that-thu-vi-6-nhan-dien-giong-noi-1Je5E8DylnL" target="_self">Tiếng Việt</a><em>, </em><a href="https://shahaab-co.ir/mag/edu/ml/machine-learning-is-fun-part-6" target="_self">فارسی</a><em> or </em><a href="http://algotravelling.com/ru/%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D1%8D%D1%82%D0%BE-%D0%B2%D0%B5%D1%81%D0%B5%D0%BB%D0%BE-6/" target="_self">Русский</a><em>.</em></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Giant update:</strong><em> </em><a href="https://www.machinelearningisfun.com/get-the-book/" target="_self">I’ve written a new book based on these articles</a><em>! It not only expands and updates all my articles, but it has tons of brand new content and lots of hands-on coding projects. </em><a href="https://www.machinelearningisfun.com/get-the-book/" target="_self">Check it out now</a><em>!</em></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Speech recognition is invading our lives. It’s built into our phones, our game consoles and our smart watches. It’s even automating our homes. For just $50, you can get an Amazon Echo Dot — a magic box that allows you to order pizza, get a weather report or even buy trash bags — just by speaking out loud:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*z2BKMXtFGhsW6_NFfguecg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*z2BKMXtFGhsW6_NFfguecg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*z2BKMXtFGhsW6_NFfguecg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*z2BKMXtFGhsW6_NFfguecg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*z2BKMXtFGhsW6_NFfguecg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*z2BKMXtFGhsW6_NFfguecg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z2BKMXtFGhsW6_NFfguecg.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*z2BKMXtFGhsW6_NFfguecg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*z2BKMXtFGhsW6_NFfguecg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*z2BKMXtFGhsW6_NFfguecg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*z2BKMXtFGhsW6_NFfguecg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*z2BKMXtFGhsW6_NFfguecg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*z2BKMXtFGhsW6_NFfguecg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*z2BKMXtFGhsW6_NFfguecg.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*z2BKMXtFGhsW6_NFfguecg.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Alexa, order a large pizza!</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The Echo Dot has been so popular this holiday season that Amazon <a href="https://www.bloomberg.com/news/articles/2016-12-21/amazon-sells-out-of-echo-speakers-in-midst-of-holiday-rush" target="_self">can’t seem to keep them in stock</a>!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But speech recognition has been around for decades, so why is it just now hitting the mainstream? The reason is that deep learning finally made speech recognition accurate enough to be useful outside of carefully controlled environments.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://en.wikipedia.org/wiki/Andrew_Ng" target="_self">Andrew Ng</a> has long predicted that as speech recognition goes from 95% accurate to 99% accurate, it will become a primary way that we interact with computers. The idea is that this 4% accuracy gap is the difference between <em>annoyingly unreliable </em>and <em>incredibly useful</em>. Thanks to Deep Learning, we’re finally cresting that peak.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s learn how to do speech recognition with deep learning!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Machine Learning isn’t always a Black Box</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you know <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa" target="_self">how neural machine translation works</a>, you might guess that we could simply feed sound recordings into a neural network and train it to produce text:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*nJNxFmJaHxyJTtVFkhGTlg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*nJNxFmJaHxyJTtVFkhGTlg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*nJNxFmJaHxyJTtVFkhGTlg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*nJNxFmJaHxyJTtVFkhGTlg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*nJNxFmJaHxyJTtVFkhGTlg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*nJNxFmJaHxyJTtVFkhGTlg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nJNxFmJaHxyJTtVFkhGTlg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*nJNxFmJaHxyJTtVFkhGTlg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*nJNxFmJaHxyJTtVFkhGTlg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*nJNxFmJaHxyJTtVFkhGTlg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*nJNxFmJaHxyJTtVFkhGTlg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*nJNxFmJaHxyJTtVFkhGTlg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*nJNxFmJaHxyJTtVFkhGTlg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*nJNxFmJaHxyJTtVFkhGTlg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*nJNxFmJaHxyJTtVFkhGTlg.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">That’s the holy grail of speech recognition with deep learning, but we aren’t quite there yet (at least at the time that I wrote this — I bet that we will be in a couple of years).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The big problem is that speech varies in speed. One person might say “hello!” very quickly and another person might say “heeeelllllllllllllooooo!” very slowly, producing a much longer sound file with much more data. Both both sound files should be recognized as exactly the same text — “hello!” Automatically aligning audio files of various lengths to a fixed-length piece of text turns out to be pretty hard.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To work around this, we have to use some special tricks and extra precessing in addition to a deep neural network. Let’s see how it works!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Turning Sounds into Bits</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The first step in speech recognition is obvious — we need to feed sound waves into a computer.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.wukv4xnp4" target="_self">Part 3</a>, we learned how to take an image and treat it as an array of numbers so that we can feed directly into a neural network for image recognition:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:79%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 581px" srcset="https://miro.medium.com/v2/resize:fit:640/1*zY1qFB9aFfZz66YxxoI2aw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*zY1qFB9aFfZz66YxxoI2aw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*zY1qFB9aFfZz66YxxoI2aw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*zY1qFB9aFfZz66YxxoI2aw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*zY1qFB9aFfZz66YxxoI2aw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*zY1qFB9aFfZz66YxxoI2aw.gif 1100w, https://miro.medium.com/v2/resize:fit:1162/1*zY1qFB9aFfZz66YxxoI2aw.gif 1162w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 581px" srcset="https://miro.medium.com/v2/resize:fit:640/1*zY1qFB9aFfZz66YxxoI2aw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*zY1qFB9aFfZz66YxxoI2aw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*zY1qFB9aFfZz66YxxoI2aw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*zY1qFB9aFfZz66YxxoI2aw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*zY1qFB9aFfZz66YxxoI2aw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*zY1qFB9aFfZz66YxxoI2aw.gif 1100w, https://miro.medium.com/v2/resize:fit:1162/1*zY1qFB9aFfZz66YxxoI2aw.gif 1162w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/581/1*zY1qFB9aFfZz66YxxoI2aw.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Images are just arrays of numbers that encode the intensity of each pixel</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But sound is transmitted as <em>waves</em>. How do we turn sound waves into numbers? Let’s use this sound clip of me saying “Hello”:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*6_q1VIVJuavYa-9Uby_L-A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*6_q1VIVJuavYa-9Uby_L-A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*6_q1VIVJuavYa-9Uby_L-A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*6_q1VIVJuavYa-9Uby_L-A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*6_q1VIVJuavYa-9Uby_L-A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*6_q1VIVJuavYa-9Uby_L-A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6_q1VIVJuavYa-9Uby_L-A.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*6_q1VIVJuavYa-9Uby_L-A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*6_q1VIVJuavYa-9Uby_L-A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*6_q1VIVJuavYa-9Uby_L-A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*6_q1VIVJuavYa-9Uby_L-A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*6_q1VIVJuavYa-9Uby_L-A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*6_q1VIVJuavYa-9Uby_L-A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*6_q1VIVJuavYa-9Uby_L-A.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*6_q1VIVJuavYa-9Uby_L-A.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">A waveform of me saying “Hello”</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Sound waves are one-dimensional. At every moment in time, they have a single value based on the height of the wave. Let’s zoom in on one tiny part of the sound wave and take a look:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*dqWhWUIzIyOLIqVReTBaiA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*dqWhWUIzIyOLIqVReTBaiA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*dqWhWUIzIyOLIqVReTBaiA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*dqWhWUIzIyOLIqVReTBaiA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*dqWhWUIzIyOLIqVReTBaiA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*dqWhWUIzIyOLIqVReTBaiA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dqWhWUIzIyOLIqVReTBaiA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*dqWhWUIzIyOLIqVReTBaiA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*dqWhWUIzIyOLIqVReTBaiA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*dqWhWUIzIyOLIqVReTBaiA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*dqWhWUIzIyOLIqVReTBaiA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*dqWhWUIzIyOLIqVReTBaiA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*dqWhWUIzIyOLIqVReTBaiA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*dqWhWUIzIyOLIqVReTBaiA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*dqWhWUIzIyOLIqVReTBaiA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To turn this sound wave into numbers, we just record of the height of the wave at equally-spaced points:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*dICZCcmEm_EWWx0yA6B3Cw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*dICZCcmEm_EWWx0yA6B3Cw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*dICZCcmEm_EWWx0yA6B3Cw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*dICZCcmEm_EWWx0yA6B3Cw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*dICZCcmEm_EWWx0yA6B3Cw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*dICZCcmEm_EWWx0yA6B3Cw.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*dICZCcmEm_EWWx0yA6B3Cw.gif 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*dICZCcmEm_EWWx0yA6B3Cw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*dICZCcmEm_EWWx0yA6B3Cw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*dICZCcmEm_EWWx0yA6B3Cw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*dICZCcmEm_EWWx0yA6B3Cw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*dICZCcmEm_EWWx0yA6B3Cw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*dICZCcmEm_EWWx0yA6B3Cw.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*dICZCcmEm_EWWx0yA6B3Cw.gif 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*dICZCcmEm_EWWx0yA6B3Cw.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Sampling a sound wave</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is called <em>sampling</em>. We are taking a reading thousands of times a second and recording a number representing the height of the sound wave at that point in time. That’s basically all an uncompressed .wav audio file is.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">“CD Quality” audio is sampled at 44.1khz (44,100 readings per second). But for speech recognition, a sampling rate of 16khz (16,000 samples per second) is enough to cover the frequency range of human speech.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Lets sample our “Hello” sound wave 16,000 times per second. Here’s the first 100 samples:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*BG4iFbx7qhb5v_JTr958PQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*BG4iFbx7qhb5v_JTr958PQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*BG4iFbx7qhb5v_JTr958PQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*BG4iFbx7qhb5v_JTr958PQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*BG4iFbx7qhb5v_JTr958PQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*BG4iFbx7qhb5v_JTr958PQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BG4iFbx7qhb5v_JTr958PQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*BG4iFbx7qhb5v_JTr958PQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*BG4iFbx7qhb5v_JTr958PQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*BG4iFbx7qhb5v_JTr958PQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*BG4iFbx7qhb5v_JTr958PQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*BG4iFbx7qhb5v_JTr958PQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*BG4iFbx7qhb5v_JTr958PQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*BG4iFbx7qhb5v_JTr958PQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*BG4iFbx7qhb5v_JTr958PQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Each number represents the amplitude of the sound wave at 1/16000th of a second intervals</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">A Quick Sidebar on Digital Sampling</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You might be thinking that sampling is only creating a rough approximation of the original sound wave because it’s only taking occasional readings. There’s gaps in between our readings so we must be losing data, right?</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*KkWfr3a6HtRSZ8-4LUw0kg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*KkWfr3a6HtRSZ8-4LUw0kg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*KkWfr3a6HtRSZ8-4LUw0kg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*KkWfr3a6HtRSZ8-4LUw0kg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*KkWfr3a6HtRSZ8-4LUw0kg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*KkWfr3a6HtRSZ8-4LUw0kg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KkWfr3a6HtRSZ8-4LUw0kg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*KkWfr3a6HtRSZ8-4LUw0kg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*KkWfr3a6HtRSZ8-4LUw0kg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*KkWfr3a6HtRSZ8-4LUw0kg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*KkWfr3a6HtRSZ8-4LUw0kg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*KkWfr3a6HtRSZ8-4LUw0kg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*KkWfr3a6HtRSZ8-4LUw0kg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*KkWfr3a6HtRSZ8-4LUw0kg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*KkWfr3a6HtRSZ8-4LUw0kg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Can digital samples perfectly recreate the original analog sound wave? What about those gaps?</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But thanks to the <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem" target="_self">Nyquist theorem</a>, we know that we can use math to perfectly reconstruct the original sound wave from the spaced-out samples — as long as we sample at least twice as fast as the highest frequency we want to record.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">I mention this only because <a href="http://gizmodo.com/dont-buy-what-neil-young-is-selling-1678446860" target="_self">nearly everyone gets this wrong</a> and assumes that using higher sampling rates always leads to better audio quality. It doesn’t.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">&lt;/end rant&gt;</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Pre-processing our Sampled Sound Data</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We now have an array of numbers with each number representing the sound wave’s amplitude at 1/16,000th of a second intervals.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We <em>could</em> feed these numbers right into a neural network. But trying to recognize speech patterns by processing these samples directly is difficult. Instead, we can make the problem easier by doing some pre-processing on the audio data.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s start by grouping our sampled audio into 20-millisecond-long chunks. Here’s our first 20 milliseconds of audio (i.e., our first 320 samples):</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*_qUExEvllTKFhsrITxsa-A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*_qUExEvllTKFhsrITxsa-A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*_qUExEvllTKFhsrITxsa-A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*_qUExEvllTKFhsrITxsa-A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*_qUExEvllTKFhsrITxsa-A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*_qUExEvllTKFhsrITxsa-A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_qUExEvllTKFhsrITxsa-A.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*_qUExEvllTKFhsrITxsa-A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*_qUExEvllTKFhsrITxsa-A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*_qUExEvllTKFhsrITxsa-A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*_qUExEvllTKFhsrITxsa-A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*_qUExEvllTKFhsrITxsa-A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*_qUExEvllTKFhsrITxsa-A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*_qUExEvllTKFhsrITxsa-A.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*_qUExEvllTKFhsrITxsa-A.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Plotting those numbers as a simple line graph gives us a rough approximation of the original sound wave for that 20 millisecond period of time:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ZMxcyjNFqIOVzJRM9BCMWw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ZMxcyjNFqIOVzJRM9BCMWw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ZMxcyjNFqIOVzJRM9BCMWw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ZMxcyjNFqIOVzJRM9BCMWw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ZMxcyjNFqIOVzJRM9BCMWw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ZMxcyjNFqIOVzJRM9BCMWw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZMxcyjNFqIOVzJRM9BCMWw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*ZMxcyjNFqIOVzJRM9BCMWw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ZMxcyjNFqIOVzJRM9BCMWw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ZMxcyjNFqIOVzJRM9BCMWw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ZMxcyjNFqIOVzJRM9BCMWw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ZMxcyjNFqIOVzJRM9BCMWw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ZMxcyjNFqIOVzJRM9BCMWw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*ZMxcyjNFqIOVzJRM9BCMWw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*ZMxcyjNFqIOVzJRM9BCMWw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This recording is only <em>1/50th of a second</em> <em>long</em>. But even this short recording is a complex mish-mash of different frequencies of sound. There’s some low sounds, some mid-range sounds, and even some high-pitched sounds sprinkled in. But taken all together, these different frequencies mix together to make up the complex sound of human speech.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To make this data easier for a neural network to process, we are going to break apart this complex sound wave into it’s component parts. We’ll break out the low-pitched parts, the next-lowest-pitched-parts, and so on. Then by adding up how much energy is in each of those frequency bands (from low to high), we create a <em>fingerprint</em> of sorts for this audio snippet.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Imagine you had a recording of someone playing a C Major chord on a piano. That sound is the combination of three musical notes— C, E and G — all mixed together into one complex sound. We want to break apart that complex sound into the individual notes to discover that they were C, E and G. This is the exact same idea.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We do this using a mathematic operation called a <a href="https://en.wikipedia.org/wiki/Fourier_transform" target="_self">Fourier transform</a>. It breaks apart the complex sound wave into the simple sound waves that make it up. Once we have those individual sound waves, we add up how much energy is contained in each one.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The end result is a score of how important each frequency range is, from low pitch (i.e. bass notes) to high pitch. Each number below represents how much energy was in each 50hz band of our 20 millisecond audio clip:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*2Vg8z3--moE-E7KybJlUPg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*2Vg8z3--moE-E7KybJlUPg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*2Vg8z3--moE-E7KybJlUPg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*2Vg8z3--moE-E7KybJlUPg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*2Vg8z3--moE-E7KybJlUPg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*2Vg8z3--moE-E7KybJlUPg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Vg8z3--moE-E7KybJlUPg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*2Vg8z3--moE-E7KybJlUPg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*2Vg8z3--moE-E7KybJlUPg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*2Vg8z3--moE-E7KybJlUPg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*2Vg8z3--moE-E7KybJlUPg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*2Vg8z3--moE-E7KybJlUPg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*2Vg8z3--moE-E7KybJlUPg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*2Vg8z3--moE-E7KybJlUPg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*2Vg8z3--moE-E7KybJlUPg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Each number in the list represents how much <em>energy</em> was in that 50hz frequency band</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But this is a lot easier to see when you draw this as a chart:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*A4CxgdyqYd_nrF3e-7ETWA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*A4CxgdyqYd_nrF3e-7ETWA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*A4CxgdyqYd_nrF3e-7ETWA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*A4CxgdyqYd_nrF3e-7ETWA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*A4CxgdyqYd_nrF3e-7ETWA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*A4CxgdyqYd_nrF3e-7ETWA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A4CxgdyqYd_nrF3e-7ETWA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*A4CxgdyqYd_nrF3e-7ETWA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*A4CxgdyqYd_nrF3e-7ETWA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*A4CxgdyqYd_nrF3e-7ETWA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*A4CxgdyqYd_nrF3e-7ETWA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*A4CxgdyqYd_nrF3e-7ETWA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*A4CxgdyqYd_nrF3e-7ETWA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*A4CxgdyqYd_nrF3e-7ETWA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*A4CxgdyqYd_nrF3e-7ETWA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">You can see that our 20 millisecond sound snippet has a lot of low-frequency energy and not much energy in the higher frequencies. That’s typical of “male” voices.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If we repeat this process on every 20 millisecond chunk of audio, we end up with a spectrogram (each column from left-to-right is one 20ms chunk):</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*bhd7B-s-Qnds3HGV6LOo8A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*bhd7B-s-Qnds3HGV6LOo8A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*bhd7B-s-Qnds3HGV6LOo8A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*bhd7B-s-Qnds3HGV6LOo8A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*bhd7B-s-Qnds3HGV6LOo8A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*bhd7B-s-Qnds3HGV6LOo8A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bhd7B-s-Qnds3HGV6LOo8A.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*bhd7B-s-Qnds3HGV6LOo8A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*bhd7B-s-Qnds3HGV6LOo8A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*bhd7B-s-Qnds3HGV6LOo8A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*bhd7B-s-Qnds3HGV6LOo8A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*bhd7B-s-Qnds3HGV6LOo8A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*bhd7B-s-Qnds3HGV6LOo8A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*bhd7B-s-Qnds3HGV6LOo8A.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*bhd7B-s-Qnds3HGV6LOo8A.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">The full spectrogram of the “hello” sound clip</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A spectrogram is cool because you can actually <em>see</em> musical notes and other pitch patterns in audio data. A neural network can find patterns in this kind of data more easily than raw sound waves. So this is the data representation we’ll actually feed into our neural network.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Recognizing Characters from Short Sounds</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now that we have our audio in a format that’s easy to process, we will feed it into a deep neural network. The input to the neural network will be 20 millisecond audio chunks. For each little audio slice, it will try to figure out the <em>letter</em> that corresponds the sound currently being spoken.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*z1Nf0ES1YVUfdZZGW0PSdQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*z1Nf0ES1YVUfdZZGW0PSdQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We’ll use a <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3" target="_self">recurrent neural network</a> — that is, a neural network that has a memory that influences future predictions. That’s because each letter it predicts should affect the likelihood of the next letter it will predict too. For example, if we have said “HEL” so far, it’s very likely we will say “LO” next to finish out the word “Hello”. It’s much less likely that we will say something unpronounceable next like “XYZ”. So having that memory of previous predictions helps the neural network make more accurate predictions going forward.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">After we run our entire audio clip through the neural network (one chunk at a time), we’ll end up with a mapping of each audio chunk to the letters most likely spoken during that chunk. Here’s what that mapping looks like for me saying “Hello”:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*d1ktMdOnFOJRKKyjFP6sqQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*d1ktMdOnFOJRKKyjFP6sqQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*d1ktMdOnFOJRKKyjFP6sqQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*d1ktMdOnFOJRKKyjFP6sqQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*d1ktMdOnFOJRKKyjFP6sqQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*d1ktMdOnFOJRKKyjFP6sqQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d1ktMdOnFOJRKKyjFP6sqQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*d1ktMdOnFOJRKKyjFP6sqQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*d1ktMdOnFOJRKKyjFP6sqQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*d1ktMdOnFOJRKKyjFP6sqQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*d1ktMdOnFOJRKKyjFP6sqQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*d1ktMdOnFOJRKKyjFP6sqQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*d1ktMdOnFOJRKKyjFP6sqQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*d1ktMdOnFOJRKKyjFP6sqQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*d1ktMdOnFOJRKKyjFP6sqQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Our neural net is predicting that one likely thing I said was “HHHEE_LL_LLLOOO”. But it also thinks that it was possible that I said “HHHUU_LL_LLLOOO” or even “AAAUU_LL_LLLOOO”.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We have some steps we follow to clean up this output. First, we’ll replace any repeated characters a single character:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">HHHEE_LL_LLLOOO becomes HE_L_LO</li><li class="ff3" style="font-size:22px;">HHHUU_LL_LLLOOO becomes HU_L_LO</li><li class="ff3" style="font-size:22px;">AAAUU_LL_LLLOOO becomes AU_L_LO</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Then we’ll remove any blanks:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">HE_L_LO becomes HELLO</li><li class="ff3" style="font-size:22px;">HU_L_LO becomes HULLO</li><li class="ff3" style="font-size:22px;">AU_L_LO becomes AULLO</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">That leaves us with three possible transcriptions — “Hello”, “Hullo” and “Aullo”. If you say them out loud, all of these sound similar to “Hello”. Because it’s predicting one character at a time, the neural network will come up with these very <em>sounded-out</em> transcriptions. For example if you say “He would not go”, it might give one possible transcription as “He wud net go”.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The trick is to combine these pronunciation-based predictions with likelihood scores based on large database of written text (books, news articles, etc). You throw out transcriptions that seem the least likely to be real and keep the transcription that seems the most realistic.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Of our possible transcriptions “Hello”, “Hullo” and “Aullo”, obviously “Hello” will appear more frequently in a database of text (not to mention in our original audio-based training data) and thus is probably correct. So we’ll pick “Hello” as our final transcription instead of the others. Done!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Wait a second!</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You might be thinking <em>“But what if someone says ‘</em><a href="https://www.merriam-webster.com/dictionary/hullo" target="_self">Hullo</a><em>’? It’s a valid word. Maybe ‘Hello’ is the wrong transcription!”</em></p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*YzVDel59VoKFmZDKhPE-cQ.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*YzVDel59VoKFmZDKhPE-cQ.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">“Hullo! Who dis?”</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Of course it is possible that someone actually said “Hullo” instead of “Hello”. But a speech recognition system like this (trained on American English) will basically never produce “Hullo” as the transcription. It’s just such an unlikely thing for a user to say compared to “Hello” that it will always think you are saying “Hello” no matter how much you emphasize the ‘U’ sound.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Try it out! If your phone is set to American English, try to get your phone’s digital assistant to recognize the world “Hullo.” You can’t! It refuses! It will always understand it as “Hello.”</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Not recognizing “Hullo” is a reasonable behavior, but sometimes you’ll find annoying cases where your phone just refuses to understand something valid you are saying. That’s why these speech recognition models are always being retrained with more data to fix these edge cases.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Can I Build My Own Speech Recognition System?</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">One of the coolest things about machine learning is how simple it sometimes seems. You get a bunch of data, feed it into a machine learning algorithm, and then magically you have a world-class AI system running on your gaming laptop’s video card…<em> Right</em>?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">That sort of true in some cases, but not for speech. Recognizing speech is a hard problem. You have to overcome almost limitless challenges: bad quality microphones, background noise, reverb and echo, accent variations, and on and on. All of these issues need to be present in your training data to make sure the neural network can deal with them.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here’s another example: Did you know that when you speak in a loud room you unconsciously raise the pitch of your voice to be able to talk over the noise? Humans have no problem understanding you either way, but neural networks need to be trained to handle this special case. So you need training data with people yelling over noise!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To build a voice recognition system that performs on the level of Siri, Google Now!, or Alexa, you will need a <em>lot</em> of training data — far more data than you can likely get without hiring hundreds of people to record it for you. And since users have low tolerance for poor quality voice recognition systems, you can’t skimp on this. No one wants a voice recognition system that works 80% of the time.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For a company like Google or Amazon, hundreds of thousands of hours of spoken audio recorded in real-life situations is <em>gold</em>. That’s the single biggest thing that separates their world-class speech recognition system from your hobby system. The whole point of putting <em>Google Now!</em> and <em>Siri</em> on every cell phone for free or selling $50 <em>Alexa</em> units that have no subscription fee is to get you to <strong>use them as much as possible</strong>. Every single thing you say into one of these systems is <strong>recorded forever</strong> and used as training data for future versions of speech recognition algorithms. That’s the whole game!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Don’t believe me? If you have an Android phone with <em>Google Now!</em>, <a href="https://myactivity.google.com/udc/vaa" target="_self">click here to listen to actual recordings of yourself saying every dumb thing you’ve ever said into it</a>:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*lwfLuSOFH032tbttD52Evw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*lwfLuSOFH032tbttD52Evw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*lwfLuSOFH032tbttD52Evw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*lwfLuSOFH032tbttD52Evw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*lwfLuSOFH032tbttD52Evw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*lwfLuSOFH032tbttD52Evw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lwfLuSOFH032tbttD52Evw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*lwfLuSOFH032tbttD52Evw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*lwfLuSOFH032tbttD52Evw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*lwfLuSOFH032tbttD52Evw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*lwfLuSOFH032tbttD52Evw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*lwfLuSOFH032tbttD52Evw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*lwfLuSOFH032tbttD52Evw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*lwfLuSOFH032tbttD52Evw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*lwfLuSOFH032tbttD52Evw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">You can access the same thing for Amazon via your <em>Alexa</em> app. Apple unfortunately doesn’t let you access your Siri voice data.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><mark>So if you are looking for a start-up idea, I wouldn’t recommend trying to build your own speech recognition system to compete with Google. Instead, figure out a way to get people to give you recordings of themselves talking for hours. The data can be your product instead.</mark></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Where to Learn More</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">The algorithm (roughly) described here to deal with variable-length audio is called Connectionist Temporal Classification or CTC. You can <a href="http://www.cs.toronto.edu/~graves/icml_2006.pdf" target="_self">read the original paper</a> from 2006.</li><li class="ff3" style="font-size:22px;"><a href="https://cs.stanford.edu/~acoates/" target="_self">Adam Coates</a> of Baidu gave a great presentation on Deep Learning for Speech Recognition at the Bay Area Deep Learning School. You can <a href="https://youtu.be/9dXiAecyJrY?t=13874" target="_self">watch the video on YouTube</a> (his talk starts at 3:51:00). Highly recommended.</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you liked this article, please consider <a href="http://eepurl.com/b9fg2T" target="_self">signing up for my Machine Learning is Fun! email list</a>. I’ll only email you when I have something new and awesome to share. It’s the best way to find out when I write more articles like this.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You can also follow me on Twitter at <a href="https://twitter.com/ageitgey" target="_self">@ageitgey</a>, <a href="mailto:ageitgey@gmail.com" target="_self">email me directly</a> or <a href="https://www.linkedin.com/in/ageitgey" target="_self">find me on linkedin</a>. I’d love to hear from you if I can help you or your team with machine learning.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7" target="_self">Now continue on to Machine Learning is Fun! Part 7</a><em>!</em></p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>