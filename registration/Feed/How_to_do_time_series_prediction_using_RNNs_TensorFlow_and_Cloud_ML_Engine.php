<!DOCTYPE html>
                <html>
                <head>
                    <title>How to do time series prediction using RNNs, TensorFlow and Cloud ML Engine</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@lakshmanok?source=post_page-----2ad2eeb189e8--------------------------------">Author : Lak Lakshmanan</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>How to do time series prediction using RNNs, TensorFlow and Cloud ML Engine</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The Estimators API in tf.contrib.learn is a very convenient way to get started using TensorFlow. The really cool thing from my perspective about the Estimators API is that using it is a very easy way to create <strong>distributed</strong> TensorFlow models. Many of the TensorFlow samples that you see floating around on the internets are not distributed — they assume that you will be running the code on a single machine. People start with such code and then are immeasurably saddened to learn that the low-level TensorFlow code doesn’t actually work on their complete dataset. They then have to do lots of work to add distributed training code around the original sample, and who wants to edit somebody else’s code?</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">Note: Estimators have now moved into core Tensorflow. <a href="https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/deepdive/09_sequence/sinemodel" target="_self">Updated code that uses tf.estimator instead of tf.contrib.learn.estimator is now on GitHub</a> — use the updated code as a starting point.</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So, please, please, please, if you see a TensorFlow sample that doesn’t use the Estimators API, ignore it. It will be a lot of work to make it work on your production (read: large) datasets — there will be monitors, coordinators, parameter servers, and all kinds of systems programming craziness that you don’t want to have to dive into. Start with the Estimator API and use the Experiment class. (Disclaimer: my views, not that of my employer).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Time series prediction needs a custom estimator</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The Estimators API comes with a Deep Neural Network classifier and regressor. If you have typical structured data, follow the tutorial linked above or take this <a href="https://cloud.google.com/training/courses/data-engineering" target="_self">training course</a> from Google Cloud (soon to be available on Coursera) and you’ll be on your way to creating machine learning models that work on real-world, large datasets in your relational data warehouse. But what if you don’t have a typical structured data problem? In that case, you will often need to create a custom estimator. In this blog post, I will show you how.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A common type of data that you will want to do machine learning on is time-series data. Essentially, your inputs are a set of numbers and you want to predict the next number in that sequence. In this article, I will make it a bit more general and assume that you want to predict the last <em>two</em> numbers of the sequence. As the Computer Science proverb goes, if you can do two, you can do N.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The traditional neural network architecture that is used for sequence-to-sequence prediction is called a Recurrent Neural Network (RNN). See this <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_self">article</a> and <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_self">this</a> one for a very accessible introduction to RNNs. But you don’t need to know how to implement a RNN to use one, so once those articles go deeper than you want, quit.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To follow along with this article, have <a href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/timeseries/rnn_cloudmle.ipynb" target="_self">my Jupyter notebook</a> open in another browser window. I am only showing key snippets of code here. The notebook (and the <a href="https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/deepdive/09_sequence/" target="_self">GitHub folder</a>) contains all of the code.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Simulate some time-series data</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">It’s usually easier to learn with a small toy dataset that you can generate as much as you want of. Real data will come with its own quirks! So, let’s generate a bunch of time-series data. Each sequence will consist of 10 numbers. We will use the first eight as inputs and the last two as the <em>labels</em> (i.e., what is to be predicted):</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:74%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 550px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*heIQAa4sV1M-YaMvjXSc7g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*heIQAa4sV1M-YaMvjXSc7g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*heIQAa4sV1M-YaMvjXSc7g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*heIQAa4sV1M-YaMvjXSc7g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*heIQAa4sV1M-YaMvjXSc7g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*heIQAa4sV1M-YaMvjXSc7g.png 1100w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*heIQAa4sV1M-YaMvjXSc7g.png 1100w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 550px" srcset="https://miro.medium.com/v2/resize:fit:640/1*heIQAa4sV1M-YaMvjXSc7g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*heIQAa4sV1M-YaMvjXSc7g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*heIQAa4sV1M-YaMvjXSc7g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*heIQAa4sV1M-YaMvjXSc7g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*heIQAa4sV1M-YaMvjXSc7g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*heIQAa4sV1M-YaMvjXSc7g.png 1100w, https://miro.medium.com/v2/resize:fit:1100/1*heIQAa4sV1M-YaMvjXSc7g.png 1100w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/550/1*heIQAa4sV1M-YaMvjXSc7g.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The code to generate these time-series sequences using numpy (np):</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>SEQ_LEN = 10<br/>def create_time_series():<br/>  freq = (np.random.random()*0.5) + 0.1  # 0.1 to 0.6<br/>  ampl = np.random.random() + 0.5  # 0.5 to 1.5<br/>  x = np.sin(np.arange(0,SEQ_LEN) * freq) * ampl<br/>  return x</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Write a bunch of these time-series sequences to CSV files (train.csv and valid.csv) and we are in business. We’ve got data.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Input Function</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The way the Estimators API in TensorFlow works is that you need to provide an input_fn to read your data. You don’t provide x and y values. Instead, you provide a function that returns inputs and labels. The inputs is a dictionary of all your inputs (name-of-input to tensor) and the labels is a tensor.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In our case, our CSV file simply consists of 10 floating point numbers. The DEFAULTS serves to specify the data type for the tensors. We want to read the data 20 lines at a time; that’s the BATCH_SIZE. A batch is the number of samples over which gradient descent is performed. You will need to experiment with this number — if it is too large, your training will be slow and if it is too small, your training will bounce around won’t converge. Since we have only input, the name you give that input doesn’t really matter. We’ll call it rawdata.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>DEFAULTS = [[0.0] for x in xrange(0, SEQ_LEN)]<br/>BATCH_SIZE = 20<br/>TIMESERIES_COL = 'rawdata'<br/>N_OUTPUTS = 2  # in each sequence, 1-8 are features, and 9-10 is label<br/>N_INPUTS = SEQ_LEN - N_OUTPUTS</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The input_fn that the Estimators API wants should take no parameters. However, we do want to be able to provide the filename(s) to read on the command line. So, Let’s write a read_dataset() function that returns an input_fn.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span># read data and convert to needed format<br/>def read_dataset(filename, mode=tf.contrib.learn.ModeKeys.TRAIN):<br/>  def _input_fn():<br/>    num_epochs = 100 if mode == tf.contrib.learn.ModeKeys.TRAIN else 1</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The first thing that we do is to decide the number of epochs. This is how many times we need to go through the dataset. We’ll go through the dataset 100 times if we are training, but only once if we are evaluating.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Next, we’ll do wild-card expansion. Lots of times, Big Data programs produce sharded files such as train.csv-0001-of-0036 and so, we’d like to simply provide train.csv* as the input. We use this to populate a filename queue and then use a TextLineReader to read the data:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span># could be a path to one file or a file pattern.<br/>input_file_names = tf.train.match_filenames_once(filename)<br/>filename_queue = tf.train.string_input_producer(<br/>        input_file_names, num_epochs=num_epochs, shuffle=True)</span><span>reader = tf.TextLineReader()<br/>    _, value = reader.read_up_to(filename_queue, num_records=BATCH_SIZE)</span><span>value_column = tf.expand_dims(value, -1)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">After this, we decode the data, treating the first 8 numbers as inputs and the last two as the label. The inputs, when we read it, is a list of 8 tensors each of which is batchsize x 1. Using tf.concat makes it a single 8xbatchsize tensor. This is important because the Estimators API wants tensors not lists.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span># all_data is a list of tensors<br/>all_data = tf.decode_csv(value_column, record_defaults=DEFAULTS)<br/>inputs = all_data[:len(all_data)-N_OUTPUTS]  # first few values<br/>label = all_data[len(all_data)-N_OUTPUTS : ] # last few values<br/>   <br/># from list of tensors to tensor with one more dimension<br/>inputs = tf.concat(inputs, axis=1)<br/>label = tf.concat(label, axis=1)<br/>print 'inputs={}'.format(inputs)<br/>   <br/>return {TIMESERIES_COL: inputs}, label   # dict of features, label</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Define a RNN</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If we we were using a LinearRegressor, DNNRegressor, DNNLinearCombinedRegressor, etc., we could have simply used the existing class. But because we are doing sequence-to-sequence prediction, we have to write our own model function. At least right now, the Estimators API doesn’t come with an out-of-the-box RNNRegressor. So, let’s roll out our own RNN model using low-level TensorFlow functions.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>LSTM_SIZE = 3  <em># number of hidden layers in each of the LSTM cells</em><br/><br/><em># create the inference model</em><br/><strong>def</strong> simple_rnn(features, targets, mode):<br/>  <em># 0. Reformat input shape to become a sequence</em><br/>  x = tf.split(features[TIMESERIES_COL], N_INPUTS, 1)<br/>  <em>#print 'x={}'.format(x)</em><br/>    <br/>  <em># 1. configure the RNN</em><br/>  lstm_cell = rnn.BasicLSTMCell(LSTM_SIZE, forget_bias=1.0)<br/>  outputs, _ = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)<br/><br/>  <em># slice to keep only the last cell of the RNN</em><br/>  outputs = outputs[-1]<br/>  <em>#print 'last outputs={}'.format(outputs)</em><br/>  <br/>  <em># output is result of linear activation of last layer of RNN</em><br/>  weight = tf.Variable(tf.random_normal([LSTM_SIZE, N_OUTPUTS]))<br/>  bias = tf.Variable(tf.random_normal([N_OUTPUTS]))<br/>  predictions = tf.matmul(outputs, weight) + bias<br/>    <br/>  <em># 2. Define the loss function for training/evaluation</em><br/>  <em>#print 'targets={}'.format(targets)</em><br/>  <em>#print 'preds={}'.format(predictions)</em><br/>  loss = tf.losses.mean_squared_error(targets, predictions)<br/>  eval_metric_ops = {<br/>      "rmse": tf.metrics.root_mean_squared_error(targets, predictions)<br/>  }<br/>  <br/>  <em># 3. Define the training operation/optimizer</em><br/>  train_op = tf.contrib.layers.optimize_loss(<br/>      loss=loss,<br/>      global_step=tf.contrib.framework.get_global_step(),<br/>      learning_rate=0.01,<br/>      optimizer="SGD")<br/><br/>  <em># 4. Create predictions</em><br/>  predictions_dict = {"predicted": predictions}<br/>  <br/>  <em># 5. return ModelFnOps</em><br/>  <strong>return</strong> tflearn.ModelFnOps(<br/>      mode=mode,<br/>      predictions=predictions_dict,<br/>      loss=loss,<br/>      train_op=train_op,<br/>      eval_metric_ops=eval_metric_ops)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Recall that we had to package up the inputs into a single tensor to pass it as the features out of the input_fn. Step 0 simply reverses that process and gets back the list of tensors.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A Recurrent Neural Network consists of a BasicLSTMLCell to which you pass in the input. You get back outputs and states. Slice it to keep only the last cell of the RNN — we are not using any of the previous states. Other architectures are possible. For example, I could have trained the network to have only one output always and used rolling windows. I’ll talk about how to modify my example to do that at the end of this article.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The comments in the code above are pretty self-explanatory regarding the other steps. We are not doing anything surprising there. This is a regression problem, so I’m using RMSE.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Create an Experiment</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The Experiment class is the smart one in the Estimators API. It knows how to take the model function, input functions for training and validation and do reasonable things regarding distribution, early stopping, etc. So, let’s hand off our pieces to it:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><strong>def</strong> get_train():<br/>  <strong>return</strong> read_dataset('train.csv', mode=tf.contrib.learn.ModeKeys.TRAIN)<br/><br/><strong>def</strong> get_valid():<br/>  <strong>return</strong> read_dataset('valid.csv', mode=tf.contrib.learn.ModeKeys.EVAL)<br/><br/><strong>def</strong> experiment_fn(output_dir):<br/>    <em># run experiment</em><br/>    <strong>return</strong> tflearn.Experiment(<br/>        tflearn.Estimator(model_fn=simple_rnn, model_dir=output_dir),<br/>        train_input_fn=get_train(),<br/>        eval_input_fn=get_valid(),<br/>        eval_metrics={<br/>            'rmse': tflearn.MetricSpec(<br/>                metric_fn=metrics.streaming_root_mean_squared_error<br/>            )<br/>        }<br/>    )<br/><br/>shutil.rmtree('outputdir', ignore_errors=True) <em># start fresh each time</em><br/>learn_runner.run(experiment_fn, 'outputdir')</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Training on the Cloud</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The code above works on a single machine, and if you package it up into a Python module, you can also submit it to Cloud ML Engine to have it trained in a serverless way:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>OUTDIR=gs://${BUCKET}/simplernn/model_trained<br/>JOBNAME=simplernn_$(date -u +%y%m%d_%H%M%S)<br/>REGION=us-central1<br/>gsutil -m rm -rf $OUTDIR<br/>gcloud ml-engine jobs submit training $JOBNAME \<br/>   --region=$REGION \<br/>   --module-name=trainer.task \<br/>   --package-path=${REPO}/simplernn/trainer \<br/>   --job-dir=$OUTDIR \<br/>   --staging-bucket=gs://$BUCKET \<br/>   --scale-tier=BASIC \<br/>   --runtime-version=1.0 \<br/>   -- \<br/>   --train_data_paths="gs://${BUCKET}/train.csv*" \<br/>   --eval_data_paths="gs://${BUCKET}/valid.csv*"  \<br/>   --output_dir=$OUTDIR \<br/>   --num_epochs=100</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">A common variant: very long time-series</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this article, I assumed that you have thousands of short (10-element) sequences. What if you have a very long sequence? For example, you might have the price of a stock or the temperature reading from a sensor. In such cases, what you could do is to break up your long sequence into rolling sequences of fixed length. This length is obviously arbitrary, but think of it as the “look-back” interval of the RNN. Here is TensorFlow code that will take a long sequence and break into smaller, overlapping sequences of a fixed length:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>import tensorflow as tf<br/>import numpy as np</span><span>def breakup(sess, x, lookback_len):<br/>  N = sess.run(tf.size(x))<br/>  windows = [tf.slice(x, [b], [lookback_len]) for b in xrange(0, N-lookback_len)]<br/>  windows = tf.stack(windows)<br/>  return windows</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For example:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>x = tf.constant(np.arange(1,11, dtype=np.float32))<br/>with tf.Session() as sess:<br/>    print 'input=', x.eval()<br/>    seqx = breakup(sess, x, 5)<br/>    print 'output=', seqx.eval()</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">will result in:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>input= [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.]<br/>output= [[ 1.  2.  3.  4.  5.]<br/> [ 2.  3.  4.  5.  6.]<br/> [ 3.  4.  5.  6.  7.]<br/> [ 4.  5.  6.  7.  8.]<br/> [ 5.  6.  7.  8.  9.]]</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Once you have these fixed length sequences, everything is the same as before.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Happy coding!</p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>