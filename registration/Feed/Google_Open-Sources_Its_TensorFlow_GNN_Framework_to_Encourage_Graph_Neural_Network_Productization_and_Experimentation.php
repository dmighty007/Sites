<!DOCTYPE html>
                <html>
                <head>
                    <title>Google Open-Sources Its TensorFlow GNN Framework to Encourage Graph Neural Network Productization and Experimentation</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/syncedreview/google-open-sources-its-tensorflow-gnn-framework-to-encourage-graph-neural-network-productization-a1e97ae089a0"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@synced?source=post_page-----a1e97ae089a0--------------------------------">Author : Synced</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Google Open-Sources Its TensorFlow GNN Framework to Encourage Graph Neural Network Productization and Experimentation</h3></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*-6Wa6cKuLbHsn5lwWr-jCA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*-6Wa6cKuLbHsn5lwWr-jCA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*-6Wa6cKuLbHsn5lwWr-jCA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*-6Wa6cKuLbHsn5lwWr-jCA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*-6Wa6cKuLbHsn5lwWr-jCA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*-6Wa6cKuLbHsn5lwWr-jCA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-6Wa6cKuLbHsn5lwWr-jCA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*-6Wa6cKuLbHsn5lwWr-jCA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*-6Wa6cKuLbHsn5lwWr-jCA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*-6Wa6cKuLbHsn5lwWr-jCA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*-6Wa6cKuLbHsn5lwWr-jCA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*-6Wa6cKuLbHsn5lwWr-jCA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*-6Wa6cKuLbHsn5lwWr-jCA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*-6Wa6cKuLbHsn5lwWr-jCA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*-6Wa6cKuLbHsn5lwWr-jCA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Graph Neural Networks (GNNs) that operate on graph-based data bring multimodal capabilities to machine learning models and have practical applications in areas as diverse as the modelling of physics systems, learning molecular fingerprints, predicting protein interfaces, classifying social networks and more. A key component for pushing GNN development is better software frameworks for learning from graph-structured data.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the new paper <em>TF-GNN: Graph Neural Networks in TensorFlow</em>, a research team from Google Core ML, Google Research, and DeepMind open-sources the TensorFlow GNN (TF-GNN) scalable library, which leverages heterogeneous relational data to create GNN models and enable GNN training and inference on arbitrary graph-structured data.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*ST4gtSaXZ3ncknmQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*ST4gtSaXZ3ncknmQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*ST4gtSaXZ3ncknmQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*ST4gtSaXZ3ncknmQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*ST4gtSaXZ3ncknmQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*ST4gtSaXZ3ncknmQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ST4gtSaXZ3ncknmQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*ST4gtSaXZ3ncknmQ.png 640w, https://miro.medium.com/v2/resize:fit:720/0*ST4gtSaXZ3ncknmQ.png 720w, https://miro.medium.com/v2/resize:fit:750/0*ST4gtSaXZ3ncknmQ.png 750w, https://miro.medium.com/v2/resize:fit:786/0*ST4gtSaXZ3ncknmQ.png 786w, https://miro.medium.com/v2/resize:fit:828/0*ST4gtSaXZ3ncknmQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*ST4gtSaXZ3ncknmQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/0*ST4gtSaXZ3ncknmQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*ST4gtSaXZ3ncknmQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The research team summarizes their main contributions as follows:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">We present TF-GNN, an open-source Python library, to create graph neural network models that can leverage heterogeneous relational data.</li><li class="ff3" style="font-size:22px;">TF-GNN enables training and inference of Graph Neural Networks (GNNs) on arbitrary graph-structured data.</li><li class="ff3" style="font-size:22px;">TF-GNN’s four API levels allow developers of all skill levels access to powerful GNN models.</li><li class="ff3" style="font-size:22px;">As a native citizen of the TensorFlow ecosystem, TF-GNN shares its benefits, including pre-trained models for various modalities (e.g., an NLP model) and support for fast mathematical hardware such as Tensor Processing Units (TPUs).</li></ol></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*-rFfPPtyuzz9WT0W.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*-rFfPPtyuzz9WT0W.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*-rFfPPtyuzz9WT0W.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*-rFfPPtyuzz9WT0W.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*-rFfPPtyuzz9WT0W.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*-rFfPPtyuzz9WT0W.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-rFfPPtyuzz9WT0W.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*-rFfPPtyuzz9WT0W.png 640w, https://miro.medium.com/v2/resize:fit:720/0*-rFfPPtyuzz9WT0W.png 720w, https://miro.medium.com/v2/resize:fit:750/0*-rFfPPtyuzz9WT0W.png 750w, https://miro.medium.com/v2/resize:fit:786/0*-rFfPPtyuzz9WT0W.png 786w, https://miro.medium.com/v2/resize:fit:828/0*-rFfPPtyuzz9WT0W.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*-rFfPPtyuzz9WT0W.png 1100w, https://miro.medium.com/v2/resize:fit:1400/0*-rFfPPtyuzz9WT0W.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*-rFfPPtyuzz9WT0W.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">TF-GNN includes four API components of varying abstraction levels to assist developers with varying machine learning expertise in creating graph models: 1) a <strong>data level</strong> for representing heterogeneous graphs and loading them into TensorFlow, which will appeal to proficient users; 2) a <strong>data exchange level</strong> for sending information between its nodes, edges, and the graph context, aimed at intermediate users; 3) a <strong>model level</strong> that offers trainable transformations of the data exchanged across the graphs; and 4) a <strong>minimal-code experience level</strong> for beginners, where an “Orchestrator” toolkit that includes popular graph learning objectives, distributed training capabilities and accelerator support — and can handle some of the vexing TensorFlow idiosyncrasies — enables simpler data input, feature processing, graph objectives, training and validation.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">TF-GNN models are currently being used by many Google teams, and the company hopes the library’s open-sourcing will facilitate the creation of GNNs for developers of all levels and push the industrial adaptation of these promising models at more organizations.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The paper <em>TF-GNN: Graph Neural Networks in TensorFlow</em> is on <a href="https://arxiv.org/abs/2207.03522" target="_self">arXiv</a>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Author</strong>: Hecate He | <strong>Editor</strong>: Michael Sarazen</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*tpa-jGl17euqfeB9.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*tpa-jGl17euqfeB9.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*tpa-jGl17euqfeB9.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*tpa-jGl17euqfeB9.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*tpa-jGl17euqfeB9.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*tpa-jGl17euqfeB9.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tpa-jGl17euqfeB9.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*tpa-jGl17euqfeB9.png 640w, https://miro.medium.com/v2/resize:fit:720/0*tpa-jGl17euqfeB9.png 720w, https://miro.medium.com/v2/resize:fit:750/0*tpa-jGl17euqfeB9.png 750w, https://miro.medium.com/v2/resize:fit:786/0*tpa-jGl17euqfeB9.png 786w, https://miro.medium.com/v2/resize:fit:828/0*tpa-jGl17euqfeB9.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*tpa-jGl17euqfeB9.png 1100w, https://miro.medium.com/v2/resize:fit:1400/0*tpa-jGl17euqfeB9.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*tpa-jGl17euqfeB9.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We know you don’t want to miss any news or research breakthroughs. <strong>Subscribe to our popular newsletter </strong><a href="https://mailchi.mp/2fb3aa308ad3/welcome-to-synced-global-ai-weekly-newsletter" target="_self">Synced Global AI Weekly</a><strong> to get weekly AI updates.</strong></p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>