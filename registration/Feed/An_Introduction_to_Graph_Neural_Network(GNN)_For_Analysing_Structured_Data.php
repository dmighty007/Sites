<!DOCTYPE html>
                <html>
                <head>
                    <title>An Introduction to Graph Neural Network(GNN) For Analysing Structured Data</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://towardsdatascience.com/an-introduction-to-graph-neural-network-gnn-for-analysing-structured-data-afce79f4cfdc"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://hongxuenong.medium.com/?source=post_page-----afce79f4cfdc--------------------------------">Author : Shanon Hong</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>An Introduction to Graph Neural Network(GNN) For Analysing Structured Data</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Understand What GNN Is and What GNN Can Do</h4></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*SkXaIgBCjF7F8g99.jpg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*SkXaIgBCjF7F8g99.jpg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*SkXaIgBCjF7F8g99.jpg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*SkXaIgBCjF7F8g99.jpg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*SkXaIgBCjF7F8g99.jpg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*SkXaIgBCjF7F8g99.jpg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SkXaIgBCjF7F8g99.jpg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*SkXaIgBCjF7F8g99.jpg 640w, https://miro.medium.com/v2/resize:fit:720/0*SkXaIgBCjF7F8g99.jpg 720w, https://miro.medium.com/v2/resize:fit:750/0*SkXaIgBCjF7F8g99.jpg 750w, https://miro.medium.com/v2/resize:fit:786/0*SkXaIgBCjF7F8g99.jpg 786w, https://miro.medium.com/v2/resize:fit:828/0*SkXaIgBCjF7F8g99.jpg 828w, https://miro.medium.com/v2/resize:fit:1100/0*SkXaIgBCjF7F8g99.jpg 1100w, https://miro.medium.com/v2/resize:fit:1400/0*SkXaIgBCjF7F8g99.jpg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*SkXaIgBCjF7F8g99.jpg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">source: <a href="https://pixabay.com/users/manuchi-1728328/?tab=popular&pagi=2" target="_self">Manuchi</a>, via <a href="https://pixabay.com/en/labrador-breed-dogs-animal-animals-805838/" target="_self">pixabay</a> (CC0)</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Graph Neural Network(GNN) recently has received a lot of attention due to its ability to analyze graph structural data. This article gives a gentle introduction to Graph Neural Network. It covers some graph theories for the ease to understand graphs and the problems in analyzing graphs. It then introduces Graph Neural Network in different forms and their principles. It also covers what GNN can do and some applications of GNN.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Graph Theory</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">First, we need to know what is a graph.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A graph is a data structure consisting of two components: <strong>vertices, </strong>and <strong>edges</strong>. It is used as a mathematical structure to analyze the pair-wise relationship between objects and entities. Typically, a graph is defined as <em>G=(V, E), </em>where <em>V </em>is a set of nodes and <em>E </em>is the edges between them.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:12%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 112px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*2TzGbB-dqiNPZArYKu1y9g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*2TzGbB-dqiNPZArYKu1y9g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*2TzGbB-dqiNPZArYKu1y9g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*2TzGbB-dqiNPZArYKu1y9g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*2TzGbB-dqiNPZArYKu1y9g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*2TzGbB-dqiNPZArYKu1y9g.png 1100w, https://miro.medium.com/v2/resize:fit:224/format:webp/1*2TzGbB-dqiNPZArYKu1y9g.png 224w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 112px" srcset="https://miro.medium.com/v2/resize:fit:640/1*2TzGbB-dqiNPZArYKu1y9g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*2TzGbB-dqiNPZArYKu1y9g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*2TzGbB-dqiNPZArYKu1y9g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*2TzGbB-dqiNPZArYKu1y9g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*2TzGbB-dqiNPZArYKu1y9g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*2TzGbB-dqiNPZArYKu1y9g.png 1100w, https://miro.medium.com/v2/resize:fit:224/1*2TzGbB-dqiNPZArYKu1y9g.png 224w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/112/1*2TzGbB-dqiNPZArYKu1y9g.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">A simple graph. Figure by author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A graph is often represented by an Adjacency matrix, <em>A. </em>If a graph has <em>N </em>nodes, then A has a dimension of (<em>N</em>x<em>N</em>). People sometimes provide another feature matrix to describe the nodes in the graph. If each node has <em>F </em>numbers of features, then the feature matrix <em>X </em>has a dimension of (<em>N</em>x<em>F</em>).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Why Is a Graph Difficult To Analyze?</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Firstly, a graph does not exist in a Euclidean space, which means it cannot be represented by any coordinate systems that we are familiar with. This makes the interpretation of graph data much harder as compared to other types of data such as waves, images, or time-series signals(“text” can also be treated as time-series), which can be easily mapped to a 2-D or 3-D Euclidean space.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Secondly, a graph does not have a fixed form. Why? Look at the example below. Graph (A) and Graph (B) have a completely different structure and visually different. But when we convert it to adjacency matrix representation, the two graphs have the same adjacency matrix (if we don’t consider the weight of edges). So should we consider these two graphs are the same or different?</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:15%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 138px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*9TagaOGBuXWP2X1rD2uSvg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*9TagaOGBuXWP2X1rD2uSvg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*9TagaOGBuXWP2X1rD2uSvg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*9TagaOGBuXWP2X1rD2uSvg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*9TagaOGBuXWP2X1rD2uSvg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*9TagaOGBuXWP2X1rD2uSvg.png 1100w, https://miro.medium.com/v2/resize:fit:276/format:webp/1*9TagaOGBuXWP2X1rD2uSvg.png 276w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 138px" srcset="https://miro.medium.com/v2/resize:fit:640/1*9TagaOGBuXWP2X1rD2uSvg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*9TagaOGBuXWP2X1rD2uSvg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*9TagaOGBuXWP2X1rD2uSvg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*9TagaOGBuXWP2X1rD2uSvg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*9TagaOGBuXWP2X1rD2uSvg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*9TagaOGBuXWP2X1rD2uSvg.png 1100w, https://miro.medium.com/v2/resize:fit:276/1*9TagaOGBuXWP2X1rD2uSvg.png 276w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/138/1*9TagaOGBuXWP2X1rD2uSvg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Graph (A). Figure by author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:18%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 154px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*xiSWbn1V21YfSJ7m852WoA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*xiSWbn1V21YfSJ7m852WoA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*xiSWbn1V21YfSJ7m852WoA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*xiSWbn1V21YfSJ7m852WoA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*xiSWbn1V21YfSJ7m852WoA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*xiSWbn1V21YfSJ7m852WoA.png 1100w, https://miro.medium.com/v2/resize:fit:308/format:webp/1*xiSWbn1V21YfSJ7m852WoA.png 308w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 154px" srcset="https://miro.medium.com/v2/resize:fit:640/1*xiSWbn1V21YfSJ7m852WoA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*xiSWbn1V21YfSJ7m852WoA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*xiSWbn1V21YfSJ7m852WoA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*xiSWbn1V21YfSJ7m852WoA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*xiSWbn1V21YfSJ7m852WoA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*xiSWbn1V21YfSJ7m852WoA.png 1100w, https://miro.medium.com/v2/resize:fit:308/1*xiSWbn1V21YfSJ7m852WoA.png 308w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/154/1*xiSWbn1V21YfSJ7m852WoA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Graph (B). Figure by author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">And lastly, a graph is in general hard to visualize for human interpretation. I’m not talking about small graphs like the examples above. I’m talking about giant graphs that involve hundreds or thousands of nodes. The dimension is very high and nodes are densely grouped, making it even difficult for a human to understand the graph. Therefore, it is challenging to train a machine for this task. The example below shows a graph modeling the logic gates in an integrated circuit.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*pdX_wV_GHyYFUdudzgIXLA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*pdX_wV_GHyYFUdudzgIXLA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*pdX_wV_GHyYFUdudzgIXLA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*pdX_wV_GHyYFUdudzgIXLA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*pdX_wV_GHyYFUdudzgIXLA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*pdX_wV_GHyYFUdudzgIXLA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pdX_wV_GHyYFUdudzgIXLA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*pdX_wV_GHyYFUdudzgIXLA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*pdX_wV_GHyYFUdudzgIXLA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*pdX_wV_GHyYFUdudzgIXLA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*pdX_wV_GHyYFUdudzgIXLA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*pdX_wV_GHyYFUdudzgIXLA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*pdX_wV_GHyYFUdudzgIXLA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*pdX_wV_GHyYFUdudzgIXLA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*pdX_wV_GHyYFUdudzgIXLA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Example of a giant graph: circuit netlist. Figure from J. Baehr et. al. “Machine Learning and Structural Characteristics of Reverse Engineering”</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Why Use Graphs?</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The reasons that people choose to work on graphs can be summarized in a few points as listed below:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">Graphs provide a better way of dealing with abstract concepts like relationships and interactions. They also offer an intuitively visual way of thinking about these concepts. Graphs also form a natural basis for analyzing relationships in a social context.</li><li class="ff3" style="font-size:22px;">Graphs can solve more complex problems by simplifying the problems into simpler representations or transform the problems into representations from different perspectives.</li><li class="ff3" style="font-size:22px;">Graph Theories and concepts are used to study and model Social Networks, Fraud patterns, Power consumption patterns, Virality and Influence in Social Media. Social Network Analysis (SNA) is probably the best-known application of Graph Theory for <a href="https://courses.analyticsvidhya.com/courses/introduction-to-data-science-2?utm_source=blog&utm_medium=IntroductionGraphTheoryarticle" target="_self">Data Science</a>.</li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Traditional Graph Analysis Methods</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Traditional methods are mostly algorithm-based, such as :</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">searching algorithms, e.g. BFS, DFS</li><li class="ff3" style="font-size:22px;">shortest path algorithms, e.g. Dijkstra’s algorithm, Nearest Neighbour</li><li class="ff3" style="font-size:22px;">spanning-tree algorithms, e.g. Prim’s algorithm</li><li class="ff3" style="font-size:22px;">clustering methods, e.g. Highly Connected Components, k-mean</li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The limitation of such algorithms is that we need to gain prior knowledge of the graph at certain confidence before we can apply the algorithm. In other words, it provides no mean for us to study the graph itself. And most importantly, there is no way to perform graph level classification.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Graph Neural Network</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Graph Neural Network, as how it is called, is a neural network that can directly be applied to graphs. It provides a convenient way for node level, edge level, and graph level prediction task.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">There are mainly three types of graph neural networks in the literature:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">Recurrent Graph Neural Network</li><li class="ff3" style="font-size:22px;">Spatial Convolutional Network</li><li class="ff3" style="font-size:22px;">Spectral Convolutional Network</li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The intuition of GNN is that nodes are naturally defined by their neighbors and connections. To understand this we can simply imagine that if we remove the neighbors and connections around a node, then the node will lose all its information. Therefore, the neighbors of a node and connections to neighbors define the concept of the node.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Having this in mind, we then give every node a state <em>(x)</em> to represent its concept. We can use the node state <em>(x)</em> to produce an output <em>(o)</em>, i.e. decision about the concept. The final state <em>(x_n) </em>of the node is normally called “node embedding”. <mark>The task of all GNN is to determine the “node embedding” of each node, by looking at the information on its neighboring nodes.</mark></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We will start with the most pioneer version of Graph Neural Network, Recurrent Graph Neural Network, or <em>RecGNN</em>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Recurrent Graph Neural Network</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As introduced in the <a href="https://ieeexplore.ieee.org/document/4700287" target="_self">original GNN paper</a>, RecGNN is built with an assumption of Banach Fixed-Point Theorem. Banach Fixed-Point Theorem states that: <em>Let (X,d) be a complete metric space and let (T:X→X) be a contraction mapping. Then T has a unique fixed point (x∗) and for any x∈X the sequence T_n(x) for n→∞ converges to (x∗). </em>This means if I apply the mapping <em>T </em>on<em> x </em>for <em>k </em>times, x^k should be almost equal to x^(k-1), i.e.:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:68%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 506px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*sdk_VhgQHQqZKz75kWYX_g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*sdk_VhgQHQqZKz75kWYX_g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*sdk_VhgQHQqZKz75kWYX_g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*sdk_VhgQHQqZKz75kWYX_g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*sdk_VhgQHQqZKz75kWYX_g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*sdk_VhgQHQqZKz75kWYX_g.png 1100w, https://miro.medium.com/v2/resize:fit:1012/format:webp/1*sdk_VhgQHQqZKz75kWYX_g.png 1012w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 506px" srcset="https://miro.medium.com/v2/resize:fit:640/1*sdk_VhgQHQqZKz75kWYX_g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*sdk_VhgQHQqZKz75kWYX_g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*sdk_VhgQHQqZKz75kWYX_g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*sdk_VhgQHQqZKz75kWYX_g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*sdk_VhgQHQqZKz75kWYX_g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*sdk_VhgQHQqZKz75kWYX_g.png 1100w, https://miro.medium.com/v2/resize:fit:1012/1*sdk_VhgQHQqZKz75kWYX_g.png 1012w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/506/1*sdk_VhgQHQqZKz75kWYX_g.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">RecGNN defines a parameterized function <em>f_w:</em></p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:69%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 516px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*mSHmW58lfL2onzATerldpw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*mSHmW58lfL2onzATerldpw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*mSHmW58lfL2onzATerldpw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*mSHmW58lfL2onzATerldpw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*mSHmW58lfL2onzATerldpw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*mSHmW58lfL2onzATerldpw.png 1100w, https://miro.medium.com/v2/resize:fit:1032/format:webp/1*mSHmW58lfL2onzATerldpw.png 1032w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 516px" srcset="https://miro.medium.com/v2/resize:fit:640/1*mSHmW58lfL2onzATerldpw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*mSHmW58lfL2onzATerldpw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*mSHmW58lfL2onzATerldpw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*mSHmW58lfL2onzATerldpw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*mSHmW58lfL2onzATerldpw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*mSHmW58lfL2onzATerldpw.png 1100w, https://miro.medium.com/v2/resize:fit:1032/1*mSHmW58lfL2onzATerldpw.png 1032w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/516/1*mSHmW58lfL2onzATerldpw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">where <strong>l_n, l_co, x_ne, l_ne</strong><em> </em>represents the features of the current node <strong>[n]</strong>, the edges of the node <strong>[n]</strong>, the state of the neighboring nodes, and the features of the neighboring nodes. (In the original paper, the author referred node features as node labels. This might make some confusion.)</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*vvPgUpwk17qHGRgUOkH1kQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*vvPgUpwk17qHGRgUOkH1kQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*vvPgUpwk17qHGRgUOkH1kQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*vvPgUpwk17qHGRgUOkH1kQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*vvPgUpwk17qHGRgUOkH1kQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*vvPgUpwk17qHGRgUOkH1kQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vvPgUpwk17qHGRgUOkH1kQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*vvPgUpwk17qHGRgUOkH1kQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*vvPgUpwk17qHGRgUOkH1kQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*vvPgUpwk17qHGRgUOkH1kQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*vvPgUpwk17qHGRgUOkH1kQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*vvPgUpwk17qHGRgUOkH1kQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*vvPgUpwk17qHGRgUOkH1kQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*vvPgUpwk17qHGRgUOkH1kQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*vvPgUpwk17qHGRgUOkH1kQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">An illustration of node state update based on the information in its neighbors. Figure from “The Graph Neural Network Model”</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Finally, after k iterations, the final node state is used to produce an output to make a decision about each node. The output function is defined as:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:36%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 280px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 1100w, https://miro.medium.com/v2/resize:fit:560/format:webp/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 560w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 280px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 1100w, https://miro.medium.com/v2/resize:fit:560/1*Vmo93eMtu9xLpUi8Ex3-Ow.png 560w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/280/1*Vmo93eMtu9xLpUi8Ex3-Ow.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Spatial Convolutional Network</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The intuition of Spatial Convolution Network is similar to that of the famous CNN which dominates the literature of image classification and segmentation tasks. To understand CNN on images, you can check out this <a href="https://medium.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" target="_self">post</a> which explains CNN in detail.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In short, the idea of convolution on an image is to sum the neighboring pixels around a center pixel, specified by a filter with parameterized size and learnable weight. Spatial Convolutional Network adopts the same idea by aggregate the features of neighboring nodes into the center node.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:41%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 318px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*3cE5PnjfPC1VGckCS21k_A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*3cE5PnjfPC1VGckCS21k_A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*3cE5PnjfPC1VGckCS21k_A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*3cE5PnjfPC1VGckCS21k_A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*3cE5PnjfPC1VGckCS21k_A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*3cE5PnjfPC1VGckCS21k_A.png 1100w, https://miro.medium.com/v2/resize:fit:636/format:webp/1*3cE5PnjfPC1VGckCS21k_A.png 636w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 318px" srcset="https://miro.medium.com/v2/resize:fit:640/1*3cE5PnjfPC1VGckCS21k_A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*3cE5PnjfPC1VGckCS21k_A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*3cE5PnjfPC1VGckCS21k_A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*3cE5PnjfPC1VGckCS21k_A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*3cE5PnjfPC1VGckCS21k_A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*3cE5PnjfPC1VGckCS21k_A.png 1100w, https://miro.medium.com/v2/resize:fit:636/1*3cE5PnjfPC1VGckCS21k_A.png 636w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/318/1*3cE5PnjfPC1VGckCS21k_A.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Left: Convolution on a regular graph such as an image. Right: Convolution on the arbitrary graph structure. Figure from “<a href="https://arxiv.org/abs/1901.00596" target="_self">A Comprehensive Survey on Graph Neural Networks</a>”</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Spectral Convolutional Network</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As compared to other types of GNN, this type of graph convolution network has a very strong mathematics foundation. Spectral Convolutional Network is built on graph signal processing theory. And by simplification And approximation of graph convolution.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">By <em>Chebyshev polynomial approximation</em> <a href="https://arxiv.org/pdf/0912.3848.pdf" target="_self">(Hammond et al. 2011)</a>, graph convolution can be simplified to below form:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:62%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 468px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*OMoUnN7C2UmFEXekBeTqLw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*OMoUnN7C2UmFEXekBeTqLw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*OMoUnN7C2UmFEXekBeTqLw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*OMoUnN7C2UmFEXekBeTqLw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*OMoUnN7C2UmFEXekBeTqLw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*OMoUnN7C2UmFEXekBeTqLw.png 1100w, https://miro.medium.com/v2/resize:fit:936/format:webp/1*OMoUnN7C2UmFEXekBeTqLw.png 936w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 468px" srcset="https://miro.medium.com/v2/resize:fit:640/1*OMoUnN7C2UmFEXekBeTqLw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*OMoUnN7C2UmFEXekBeTqLw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*OMoUnN7C2UmFEXekBeTqLw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*OMoUnN7C2UmFEXekBeTqLw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*OMoUnN7C2UmFEXekBeTqLw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*OMoUnN7C2UmFEXekBeTqLw.png 1100w, https://miro.medium.com/v2/resize:fit:936/1*OMoUnN7C2UmFEXekBeTqLw.png 936w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/468/1*OMoUnN7C2UmFEXekBeTqLw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">After further simplification, the <a href="https://arxiv.org/abs/1609.02907" target="_self">GCN paper</a> suggests a 2-layered neural network structure, which can be described in one equation as below:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*WkKAzrFJi9AFxj1hTgQgLw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*WkKAzrFJi9AFxj1hTgQgLw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*WkKAzrFJi9AFxj1hTgQgLw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*WkKAzrFJi9AFxj1hTgQgLw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*WkKAzrFJi9AFxj1hTgQgLw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*WkKAzrFJi9AFxj1hTgQgLw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WkKAzrFJi9AFxj1hTgQgLw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*WkKAzrFJi9AFxj1hTgQgLw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*WkKAzrFJi9AFxj1hTgQgLw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*WkKAzrFJi9AFxj1hTgQgLw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*WkKAzrFJi9AFxj1hTgQgLw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*WkKAzrFJi9AFxj1hTgQgLw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*WkKAzrFJi9AFxj1hTgQgLw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*WkKAzrFJi9AFxj1hTgQgLw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*WkKAzrFJi9AFxj1hTgQgLw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">where A_head is the pre-processed Laplacian of original graph adjacency matrix A. (Details of the mathematics can be found in GCN paper. It will take much effort to fully explain.)</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This formula looks very familiar if you have some experience in machine learning. This is nothing but two fully-connected layer structure that is commonly used. But it indeed serves as graph convolution in this case. I will show why it can perform graph convolution below.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:80%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 594px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Zgf5j2l_UJmpl8KXmsiw9w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Zgf5j2l_UJmpl8KXmsiw9w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Zgf5j2l_UJmpl8KXmsiw9w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Zgf5j2l_UJmpl8KXmsiw9w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Zgf5j2l_UJmpl8KXmsiw9w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Zgf5j2l_UJmpl8KXmsiw9w.png 1100w, https://miro.medium.com/v2/resize:fit:1188/format:webp/1*Zgf5j2l_UJmpl8KXmsiw9w.png 1188w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 594px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Zgf5j2l_UJmpl8KXmsiw9w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Zgf5j2l_UJmpl8KXmsiw9w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Zgf5j2l_UJmpl8KXmsiw9w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Zgf5j2l_UJmpl8KXmsiw9w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Zgf5j2l_UJmpl8KXmsiw9w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Zgf5j2l_UJmpl8KXmsiw9w.png 1100w, https://miro.medium.com/v2/resize:fit:1188/1*Zgf5j2l_UJmpl8KXmsiw9w.png 1188w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/594/1*Zgf5j2l_UJmpl8KXmsiw9w.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Example of a graph with a feature assigned to each node. Figured by author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s consider we have a simple graph with 4 nodes. Each of these nodes is assigned a feature matrix as shown in the figure above. It is easy to come out with a graph adjacency matrix and feature matrix as shown below:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*jy7A04FrEoAU4y9p9_2ynA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*jy7A04FrEoAU4y9p9_2ynA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*jy7A04FrEoAU4y9p9_2ynA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*jy7A04FrEoAU4y9p9_2ynA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*jy7A04FrEoAU4y9p9_2ynA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*jy7A04FrEoAU4y9p9_2ynA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jy7A04FrEoAU4y9p9_2ynA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*jy7A04FrEoAU4y9p9_2ynA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*jy7A04FrEoAU4y9p9_2ynA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*jy7A04FrEoAU4y9p9_2ynA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*jy7A04FrEoAU4y9p9_2ynA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*jy7A04FrEoAU4y9p9_2ynA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*jy7A04FrEoAU4y9p9_2ynA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*jy7A04FrEoAU4y9p9_2ynA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*jy7A04FrEoAU4y9p9_2ynA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Example of the adjacency matrix and feature matrix. Figure by author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><em>Note that the diagonal of the adjacency matrix is purposely changed to ‘1’ to add a self-loop for every node. This is to include the feature of every node itself when we perform feature aggregation.</em></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We then perform <em>A</em>x<em>X (</em>let’s forget about the Laplacian of A and the weight matrix <em>W</em> first for simplicity of explanation.<em>)</em></p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*KMZrQGKua0WB_Tmwl2PycQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*KMZrQGKua0WB_Tmwl2PycQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*KMZrQGKua0WB_Tmwl2PycQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*KMZrQGKua0WB_Tmwl2PycQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*KMZrQGKua0WB_Tmwl2PycQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*KMZrQGKua0WB_Tmwl2PycQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KMZrQGKua0WB_Tmwl2PycQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*KMZrQGKua0WB_Tmwl2PycQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*KMZrQGKua0WB_Tmwl2PycQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*KMZrQGKua0WB_Tmwl2PycQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*KMZrQGKua0WB_Tmwl2PycQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*KMZrQGKua0WB_Tmwl2PycQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*KMZrQGKua0WB_Tmwl2PycQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*KMZrQGKua0WB_Tmwl2PycQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*KMZrQGKua0WB_Tmwl2PycQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Example of graph convolution by matrix multiplication. Figure by author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The result of matrix multiplication is shown in the rightmost matrix. Let’s look at the resulted feature of the first node as an example. It is not hard to notice that the result is a sum of all features of [node 1] including the feature of [node 1] itself, and features in [node 4] are not included since its not the neighbor of [node 1]. Mathematically, the adjacency matrix of the graph has value ‘1’ only when there is an edge, and ‘0’ otherwise. This makes the matrix multiplication become the summation of features of nodes that are connected to the reference node.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Therefore, Spectral Convolutional Network and Spatial Convolutional Network, although started on a different basis, share the same propagation rule.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">All convolutional graph neural networks currently available share the same format. They all try to learn a function to pass the node information around and update node state by this message passing process.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Any Graph Neural Network can be expressed as a Message Passing Neural Network (J. Gilmer et al. , 2017) with a <strong>message-passing </strong>function, a <strong>node update </strong>function and a <strong>readout </strong>function.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Ki0XMgBSZu-WS7XSM8zljw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Ki0XMgBSZu-WS7XSM8zljw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Ki0XMgBSZu-WS7XSM8zljw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Ki0XMgBSZu-WS7XSM8zljw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Ki0XMgBSZu-WS7XSM8zljw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Ki0XMgBSZu-WS7XSM8zljw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ki0XMgBSZu-WS7XSM8zljw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Ki0XMgBSZu-WS7XSM8zljw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Ki0XMgBSZu-WS7XSM8zljw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Ki0XMgBSZu-WS7XSM8zljw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Ki0XMgBSZu-WS7XSM8zljw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Ki0XMgBSZu-WS7XSM8zljw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Ki0XMgBSZu-WS7XSM8zljw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Ki0XMgBSZu-WS7XSM8zljw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*Ki0XMgBSZu-WS7XSM8zljw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">What Can GNN do?</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The problems that GNN solve can be broadly classified into three categories:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">Node Classification</li><li class="ff3" style="font-size:22px;">Link Prediction</li><li class="ff3" style="font-size:22px;">Graph Classification</li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In <em>node classification</em>, the task is to predict the node embedding for every node in a graph. This type of problem is usually trained in a semi-supervised way, where only part of the graph is labeled. Typical applications for node classification include citation networks, Reddit posts, Youtube videos, and Facebook friends relationships.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In <em>link prediction</em>, the task is to understand the relationship between entities in graphs and predict if two entities have a connection in between. For example, a recommender system can be treated as link prediction problem where the model is given a set of users’ reviews of different products, the task is to predict the users’ preferences and tune the recommender system to push more relevant products according to users’ interest.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In <em>graph classification</em>, the task is to classify the whole graph into different categories. It is similar to image classification but the target changes into graph domain. There is a wide range of industrial problems where graph classification can be applied, for example, in chemistry, biomedical, physics, where the model is given a molecular structure and asked to classify the target into meaningful categories. It accelerates the analysis of atom, molecule or any other structured data types.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Some Real Applications</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Having understand what types of analysis that GNN can perform, you must be wondering what are the real things that I can do with graphs. Well, this section will give you more insights into GNN’s real-world applications.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">GNN in Natural Language Processing</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">GNN is widely used in Natural Language Processing (NLP). Actually, this is also where GNN initially gets started. If some of you have experience in NLP, you must be thinking that text should be a type of sequential or temporal data which can be best described by an RNN or an LTSM. Well, GNN approaches the problem from a completely different angle. GNN utilized the inner relations of words or documents to predict the categories. For example, the citation network is trying to predict the label of each paper in the network given by the paper citation relationship and the words that are cited in other papers. It can also build a syntactic model by looking at different parts of a sentence instead of purely sequential as in RNN or LTSM.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">GNN in Computer Vision</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Many CNN based methods have achieved state-of-the-art performance in object detections in images, but yet we do not know the relationships of the objects. One successful employment of GNN in CV is using graphs to model the relationships between objects detected by a CNN based detector. After objects are detected from the images, they are then fed into a GNN inference for relationship prediction. The outcome of the GNN inference is a generated graph that models the relationships between different objects.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:56%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 425px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*bV3JKhMl_imslqT41hvHug.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*bV3JKhMl_imslqT41hvHug.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*bV3JKhMl_imslqT41hvHug.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*bV3JKhMl_imslqT41hvHug.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*bV3JKhMl_imslqT41hvHug.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*bV3JKhMl_imslqT41hvHug.png 1100w, https://miro.medium.com/v2/resize:fit:850/format:webp/1*bV3JKhMl_imslqT41hvHug.png 850w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 425px" srcset="https://miro.medium.com/v2/resize:fit:640/1*bV3JKhMl_imslqT41hvHug.png 640w, https://miro.medium.com/v2/resize:fit:720/1*bV3JKhMl_imslqT41hvHug.png 720w, https://miro.medium.com/v2/resize:fit:750/1*bV3JKhMl_imslqT41hvHug.png 750w, https://miro.medium.com/v2/resize:fit:786/1*bV3JKhMl_imslqT41hvHug.png 786w, https://miro.medium.com/v2/resize:fit:828/1*bV3JKhMl_imslqT41hvHug.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*bV3JKhMl_imslqT41hvHug.png 1100w, https://miro.medium.com/v2/resize:fit:850/1*bV3JKhMl_imslqT41hvHug.png 850w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/425/1*bV3JKhMl_imslqT41hvHug.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Scene Graph Generation. Figure from D. Xu, Y. Zhu, C. B. Choy, and L. Fei-Fei, “Scene graph generation by iterative message passing,” in <em>Proc. of CVPR</em>, 2017</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Another interesting application in CV is image generation from graph descriptions. This can be interpreted as almost the reverse of the application mentioned above. The traditional way of image generation is text-to-image generation using GAN or autoencoder. Instead of using text for image description, graph to image generation provides more information on the semantic structures of the images.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:88%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 650px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*gj0mWilPILG4gX4_uVnvHg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*gj0mWilPILG4gX4_uVnvHg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*gj0mWilPILG4gX4_uVnvHg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*gj0mWilPILG4gX4_uVnvHg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*gj0mWilPILG4gX4_uVnvHg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*gj0mWilPILG4gX4_uVnvHg.png 1100w, https://miro.medium.com/v2/resize:fit:1300/format:webp/1*gj0mWilPILG4gX4_uVnvHg.png 1300w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 650px" srcset="https://miro.medium.com/v2/resize:fit:640/1*gj0mWilPILG4gX4_uVnvHg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*gj0mWilPILG4gX4_uVnvHg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*gj0mWilPILG4gX4_uVnvHg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*gj0mWilPILG4gX4_uVnvHg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*gj0mWilPILG4gX4_uVnvHg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*gj0mWilPILG4gX4_uVnvHg.png 1100w, https://miro.medium.com/v2/resize:fit:1300/1*gj0mWilPILG4gX4_uVnvHg.png 1300w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/650/1*gj0mWilPILG4gX4_uVnvHg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image generated from scene graphs. Figure from J. Johnson, A. Gupta, and L. Fei-Fei, “Image generation from scene graphs,” in <em>Proc. of CVPR</em>, 2018</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The most interesting application I would like to share is zero-shot learning (ZSL). You can find <a href="https://medium.com/applications-of-zero-shot-learning-f65bb232963f" target="_self">this post</a> for a comprehensive introduction to ZSL. In short, ZSL is trying to learn to classify a class given <strong>NO</strong> training samples (of the target classes) at all. It was quite challenging because if no training samples were given, we need to let the model “think” logically to recognize a target. For example, if we were given three images (as shown in the figure below) and told to find “okapi” among them. We may not have seen an “okapi” before. But if we were also given the information that an “okapi” is a deer-face animal with four legs and has zebra-striped skin, then it is not hard for us to figure out which one is “okapi”. Typical methods are simulating this “thinking process” by converting the detected features into text. However, text encodings are independent among each other. It is hard to model the relationships between the text descriptions. In other hard, graph representations well model these relationships, making the machine to think in a more “human-like” manner.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*C-XfrIURP8ZxkvDgaDTGjg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*C-XfrIURP8ZxkvDgaDTGjg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*C-XfrIURP8ZxkvDgaDTGjg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*C-XfrIURP8ZxkvDgaDTGjg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*C-XfrIURP8ZxkvDgaDTGjg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*C-XfrIURP8ZxkvDgaDTGjg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C-XfrIURP8ZxkvDgaDTGjg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*C-XfrIURP8ZxkvDgaDTGjg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*C-XfrIURP8ZxkvDgaDTGjg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*C-XfrIURP8ZxkvDgaDTGjg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*C-XfrIURP8ZxkvDgaDTGjg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*C-XfrIURP8ZxkvDgaDTGjg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*C-XfrIURP8ZxkvDgaDTGjg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*C-XfrIURP8ZxkvDgaDTGjg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*C-XfrIURP8ZxkvDgaDTGjg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure from X. Wang, Y. Ye, and A. Gupta, “Zero-shot recognition via semantic embeddings and knowledge graphs,” in <em>CVPR 2018</em></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">GNN in Other Domains</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">More practical applications of GNN include human behavior detection, traffic control, molecular structure study, recommender system, program verification, logical reasoning, social influence prediction, and adversarial attack prevention. Below shows a graph that models the relationships of people in a social network. GNN can be applied to cluster people into different community groups.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*vOf5GavAOEeO3fM1.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*vOf5GavAOEeO3fM1.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*vOf5GavAOEeO3fM1.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*vOf5GavAOEeO3fM1.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*vOf5GavAOEeO3fM1.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*vOf5GavAOEeO3fM1.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vOf5GavAOEeO3fM1.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*vOf5GavAOEeO3fM1.png 640w, https://miro.medium.com/v2/resize:fit:720/0*vOf5GavAOEeO3fM1.png 720w, https://miro.medium.com/v2/resize:fit:750/0*vOf5GavAOEeO3fM1.png 750w, https://miro.medium.com/v2/resize:fit:786/0*vOf5GavAOEeO3fM1.png 786w, https://miro.medium.com/v2/resize:fit:828/0*vOf5GavAOEeO3fM1.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*vOf5GavAOEeO3fM1.png 1100w, https://miro.medium.com/v2/resize:fit:1400/0*vOf5GavAOEeO3fM1.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*vOf5GavAOEeO3fM1.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Graph of Social Network. Image from <a href="https://pixabay.com/vectors/social-media-connections-networking-3846597/" target="_self">GDJ</a>, via Pixabay</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Conclusion</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We went through some graph theories in this article and emphasized on the importance to analyze graphs. People always see machine learning algorithm as a “<strong>black box</strong>”. Most machine learning algorithms only learn from the features of training data but there is no actual logic to perform. With graphs, we might be able to pass some “logics” to the machine and let it “think” more naturally.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">GNN is still a relatively new area and is worthy of more research attention. It is a powerful tool to analyze graph data. Yet it is not limited to only problems in graphs. It can be easily generalized to any studies that can be modeled by graphs. And graph modeling is a natural way to analyze a problem.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">References:</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">F.Scarselli, M.Gori, “The graph neural network model,” <em>IEEE Transactions on Neural Networks, 2009</em></li><li class="ff3" style="font-size:22px;">T. N. Kipf and M. Welling, “Semi-supervised classification with graph convolutional networks,” in <em>Proc. of ICLR</em>, 2017.</li><li class="ff3" style="font-size:22px;">Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, Philip S. Yu, “A Comprehensive Survey on Graph Neural Networks”, <a href="https://arxiv.org/abs/1901.00596" target="_self">arXiv:1901.00596</a></li><li class="ff3" style="font-size:22px;">D. Xu, Y. Zhu, C. B. Choy, and L. Fei-Fei, “Scene graph generation by iterative message passing,” in <em>Proc. of CVPR</em>, vol. 2, 2017</li><li class="ff3" style="font-size:22px;">J. Johnson, A. Gupta, and L. Fei-Fei, “Image generation from scene graphs,” in <em>Proc. of CVPR</em>, 2018</li><li class="ff3" style="font-size:22px;">X. Wang, Y. Ye, and A. Gupta, “Zero-shot recognition via semantic embeddings and knowledge graphs,” in <em>CVPR 2018</em></li></ol></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>