<!DOCTYPE html>
                <html>
                <head>
                    <title>RNN Language Modelling with PyTorch — Packed Batching and Tied Weights</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/@florijan.stamenkovic_99541/rnn-language-modelling-with-pytorch-packed-batching-and-tied-weights-9d8952db35a9"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@florijan.stamenkovic_99541?source=post_page-----9d8952db35a9--------------------------------">Author : Florijan Stamenković</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>RNN Language Modelling with PyTorch — Packed Batching and Tied Weights</h3></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:86%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 632px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*JxlLbEz9M8-SOmzFiz0kBQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*JxlLbEz9M8-SOmzFiz0kBQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*JxlLbEz9M8-SOmzFiz0kBQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*JxlLbEz9M8-SOmzFiz0kBQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*JxlLbEz9M8-SOmzFiz0kBQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*JxlLbEz9M8-SOmzFiz0kBQ.png 1100w, https://miro.medium.com/v2/resize:fit:1264/format:webp/1*JxlLbEz9M8-SOmzFiz0kBQ.png 1264w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 632px" srcset="https://miro.medium.com/v2/resize:fit:640/1*JxlLbEz9M8-SOmzFiz0kBQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*JxlLbEz9M8-SOmzFiz0kBQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*JxlLbEz9M8-SOmzFiz0kBQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*JxlLbEz9M8-SOmzFiz0kBQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*JxlLbEz9M8-SOmzFiz0kBQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*JxlLbEz9M8-SOmzFiz0kBQ.png 1100w, https://miro.medium.com/v2/resize:fit:1264/1*JxlLbEz9M8-SOmzFiz0kBQ.png 1264w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/632/1*JxlLbEz9M8-SOmzFiz0kBQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Language Models</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Language models are a crucial part of systems that generate text. They’re used in image captioning, speech-to-text, machine translation, sentiment analysis etc. They model the probability of word sequences. For example, the sequence “Fine weather today.” is more probable then “walk. pair REd”.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Recurrent Neural Nets</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you are reading this, you are most likely already familiar with RNNs. If not, take a look at some of the many online resources on the subject (here’s a nice <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_self">intro</a>). Using an RNN for natural language modelling is a very common approach, well explained on the page just mentioned.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">This Post</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">An increasingly popular framework for neural nets, PyTorch naturally supports RNNs. There are <a href="https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html" target="_self">tutorials</a> on the subject. Some aspects of PyTorch RNNs are not that clearly explained in the tutorials and there’s some confusion in other online resources, hence this post. In short, here’s what it’s about:<br></br>• Implementing tied embedding weights.<br></br>• PackedSequence batching with word embeddings.<br></br>• PyTorch RNN extendability.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Context</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A common dataset for benchmarking language models is the WikiText long-term dependency language modelling <a href="https://einstein.ai/research/the-wikitext-long-term-dependency-language-modeling-dataset" target="_self">dataset</a>. I’ll be using the WikiText-2 version that contains roughly 2.5 million words.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">All the code is available on my <a href="https://github.com/florijanstamenkovic/PytorchRnnLM" target="_self">GitHub page</a>. I also made a <a href="https://drive.google.com/file/d/1gT0S5Lyzcm9KoxJGDdqQ9X8QSyzwgNDE/view?usp=sharing" target="_self">Google Colab notebook</a> that prepares and trains the model. Training with the default params on a Colab GPU takes about 10 minutes with a decent final perplexity score of 135.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Word Embeddings with Tied Weights</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In neural-net based language models (NNLMs) each word is encoded as a numeric vectors of dimensionality <em>d₁</em>. These vectors constitute an “embedding matrix” of size <em>(|V|, d₁) </em>that’s learned during training (<em>V</em> is the vocabulary). An NNLM typically predicts a word from the vocabulary using a softmax output layer that accepts a <em>d₂-</em>dimensional vector as input. The softmax layer weights are a (<em>d₂</em>, <em>|V|)</em> matrix. Since <em>V</em> is very large, these two matrices contain many (in the millions) parameters that need to be trained.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">I like the idea of tied input and output embeddings presented by <a href="https://arxiv.org/abs/1608.05859" target="_self">Press and Wolf in 2016</a>. If <em>d₁=d₂,</em> then it’s possible to use the same weights for both the “input and output embeddings”, as they can now be referred to. This greatly reduces the number of trainable parameters, while potentially improving the model.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Tied Embeddings In PyTorch</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Using word embeddings in PyTorch is very simple using the <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding" target="_self">pytorch.nn.Embedding</a> class. There’s a nice <a href="https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html" target="_self">tutorial</a> on the subject.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So, how to use tied weights? There are two obvious approaches: either use <code>torch.nn.Embedding</code> or <code>torch.nn.Linear</code> for both.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Tied Weights Using the torch.nn.Embedding class</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you use <code>torch.nn.Embedding</code> be mindful of it’s weight initialisation strategy. It initialises weights with a normal distribution with a zero mean and unit variance (see <a href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html#Embedding" target="_self">class source</a>). This is, generally speaking, not a good initialisation strategy for a fully connected layer, such as the softmax activation layer. For that reason a bit of initialisation juggling is necessary:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span># custom weight init in torch.nn.Embedding<br/>emb_w = torch.Tensor(V, d)<br/>stdv = 1. / math.sqrt(emb_w.size(1)) # like in nn.Linear<br/>emb_w.uniform_(-stdv, stdv)<br/>embedding = nn.Embedding(vocab_size, embedding_dim,    <br/>                         _weight=emb_w)</span><span># use it as an embedding layer<br/>word_inds = torch.tensor([3,1,7])<br/>word_vecs = embedding(word_vecs)</span><span># use it for softmax<br/>out = preious_layers(word_vecs).mm(s.embedding.weight.t()) + out_b</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Note that the <code>embedding</code> weights had to be transposed from <em>(|V|, d)</em> to <em>(d, |V|)</em>. Also, a bias was added manually, which <code>torch.nn.Linear</code> does for us by default.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Tied Weights Using the torch.nn.Linear</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The other approach to using tied weights is to use <code>torch.nn.Linear</code>:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>fc = nn.Linear(d, V)</span><span># here's how to treat it as an embedding layer<br/>word_inds = torch.tensor([3,1,7])<br/>word_vecs = fc.weight.index_select(0, word_inds)</span><span># standard usage for output activation<br/>out = fc(preious_layers(word_vecs))</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">With this approach you loose some of the added functionality of <code>nn.Embedding</code>, but overall the code is simpler. It’s not necessary to transpose the <code>fc</code> weights when using them for input embeddings as <code>nn.Linear</code> keeps them in a shape transposed w.r.t. the order of constructor arguments it takes.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Batching with Embeddings and PackedSequence</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Language models are often trained so that a single training sequence is one sentence from the training set. Keep in mind that sentence length varies.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">At the same time neural nets are often trained in batches since that both stabilises gradients and greatly increases training throughput on modern hardware (GPUs). In a simple PyTorch experiment I measured that using batching with a small RNN yields a <strong>10x throughput increase</strong>. This, of course, varies depending on the network, dataset etc. Batched RNN training is, as far as I know, not explained in PyTorch tutorials, but it’ actually well supported by the library. Check out the handy <a href="https://pytorch.org/docs/stable/nn.html#utilities" target="_self">PyTorch NN utils.</a></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So, how can we make batches of sequences that have different lengths?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Padding</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A common solution for this problem is to split/trim sentences to some maximum length and/or add padding to shorter ones so their length is uniform. This approach has several problems:<br></br>• Splitting/trimming sentences results in a loss of context and data.<br></br>• Padding adds useless overhead in forward propagation.<br></br>• Padding must be removed from the loss calculation to exclude it from backprop, which is tedious and unwieldy.<br></br>• Everything just takes more memory.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">All of this is especially bad if you consider sentence lengths in the WikiText-2 dataset:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:80%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 592px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 1100w, https://miro.medium.com/v2/resize:fit:1184/format:webp/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 1184w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 592px" srcset="https://miro.medium.com/v2/resize:fit:640/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 1100w, https://miro.medium.com/v2/resize:fit:1184/1*WtS_W5YtEWGX-Jt8o8ks8Q.png 1184w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/592/1*WtS_W5YtEWGX-Jt8o8ks8Q.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">WikiText-2 sentence length histogram</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Is there an alternative? Yes!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Packing</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Instead of padding to keep variable length sentences in a matrix, we can pack all the sequences into a single vector. To ensure that sentences can still be processed independently (their boundaries respected), the information about their lengths must be preserved. All of this is very conveniently handled by PyTorch’s <code>torch.nn.utils.rnn.PackedSequence</code> and accompanying utility functions. What’s even cooler is that a <code>PackedSequence</code> can be fed directly into PyTorch’s RNN layers! This is well documented in the <a href="https://pytorch.org/docs/stable/nn.html#recurrent-layers" target="_self">API specification,</a> but searching for relevant keywords in the tutorials yields nothing. Forums and blogs help though.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Packing and Word Embeddings</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">What I was unable to find either on official pages or in third-party how-tos is how to combine the <code>PackedSequence</code> functionality with word embeddings, without using padding as an intermediary format. Here’s how:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">Make a <code>PackedSequence</code> of your sentences (word tokens).</li><li class="ff3" style="font-size:22px;">Convert <code>PackedSequence.data</code> member into embedded vecs.</li><li class="ff3" style="font-size:22px;">Construct a new <code>PackedSequence</code> from the result and the old one’s sequence lengths. <strong>This is not officially supported by the API.</strong></li><li class="ff3" style="font-size:22px;">Pass the resulting <code>PackedSequence</code> into a recurrent layer of the net.</li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">It’s very simple, my guess is that the unsupported aspect of step 3. is why it’s not commonly used. I prefer this solution to alternatives I’ve found because it’s much simpler and avoids intermediary padding. This works with the current stable version of PyTorch (0.4.0).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As I mentioned, the code is <a href="https://github.com/florijanstamenkovic/PytorchRnnLM" target="_self">available on my GitHub</a>, but here’s a snippet anyway:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>import torch<br/>import torch.nn as nn</span><span># A list of sentences, each being a list of tokens.<br/>sents = [[4, 545, 23, 1], [34, 84], [23, 6, 774]]</span><span># Embedding for 10k words with d=128<br/>emb = nn.Embedding(1000, 128)</span><span># When packing a sequence it has to be sorted on length.<br/>sents.sort(key=len, reverse=True)<br/>packed = nn.utils.rnn.pack_sequence(<br/>    [torch.tensor(s) for s in sents])<br/>embedded = nn.utils.rnn.PackedSequence(<br/>    emb(packed.data), packed.batch_sizes)</span><span># An LSTM<br/>lstm_layer = nn.LSTM(128, 128)<br/>output = lstm_layer(embedded)</span><span># Output is a PackedSequence too</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Custom Neurons, Batching and Packing</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In RNN-based research it’s fairly common to modify the behaviour of the recurrent unit one way or the other. It could be for modifying the way internal state is manipulated (which gave birth to LSTM, GRUs etc.), for adding attention, etc. In PyTorch doing this is quite simple, as the RNN-based name classifier <a href="https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html" target="_self">tutorial</a> explains. However, there is no batching involved. Can we have easy batching, and maybe word embeddings, when working with a custom recurrent unit?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Taking a look at the <a href="https://pytorch.org/docs/stable/nn.html#recurrent-layers" target="_self">RNN layers in PyTorch,</a> we can see that there are RNN, LSTM and GRU classes, but also RNNCell, LSTMCell and GRUCell classes. This <em>could imply</em> a code organisation where there is a base RNN model class that different RNN units get plugged into:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:56%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 422px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*hyha1ZRPV2BmWPBbCtbccQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*hyha1ZRPV2BmWPBbCtbccQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*hyha1ZRPV2BmWPBbCtbccQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*hyha1ZRPV2BmWPBbCtbccQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*hyha1ZRPV2BmWPBbCtbccQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*hyha1ZRPV2BmWPBbCtbccQ.png 1100w, https://miro.medium.com/v2/resize:fit:844/format:webp/1*hyha1ZRPV2BmWPBbCtbccQ.png 844w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 422px" srcset="https://miro.medium.com/v2/resize:fit:640/1*hyha1ZRPV2BmWPBbCtbccQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*hyha1ZRPV2BmWPBbCtbccQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*hyha1ZRPV2BmWPBbCtbccQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*hyha1ZRPV2BmWPBbCtbccQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*hyha1ZRPV2BmWPBbCtbccQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*hyha1ZRPV2BmWPBbCtbccQ.png 1100w, https://miro.medium.com/v2/resize:fit:844/1*hyha1ZRPV2BmWPBbCtbccQ.png 844w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/422/1*hyha1ZRPV2BmWPBbCtbccQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Possible PyTorch RNN class hierarchy.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Browsing through the <a href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#RNN" target="_self">source</a> implies this is not far from the truth. Which in turn means we might easily plug our custom-defined recurrent unit into <code>RNNBase</code> and get all the benefits, such as batch- and packed-sequence-processing capabilities, which would be great.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Unfortunately, it doesn’t seem to work like this. Instead of containing a cell member and/or passing it to <code>RNNBase</code>'s constructor, the <code>RNN</code>, <code>LSTM</code> and <code>GRU</code> subclasses instead pass a string as the <code>mode</code> parameter. Based on <code>mode</code>, the <code>RNNBase</code> allocates parameter space (PyTorch code from <code>RNNBase</code> pasted below) and performs other initialisation.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>if mode == 'LSTM':<br/>    gate_size = 4 * hidden_size<br/>elif mode == 'GRU':<br/>    gate_size = 3 * hidden_size<br/>else:<br/>    gate_size = hidden_size</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This not only prevents us from reusing <code>RNNBase</code>'s functionality, but it just looks like bad design. There might be valid reasons why this is so, I have nowhere nearly enough knowledge of PyTorch’s codebase to authoritatively criticise, I’m just saying it <em>seems</em> wrong.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Thus, for the moment it doesn’t look like there’s an easy way of plugging a custom recurrent unit into PyTorch’s RNN goodness :(</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Conclusion</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Summing up how using PyTorch’s recurrent network capabilities feels:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>The good:</strong><br></br>• Making a basic RNNs is easy.<br></br>• Word embeddings are easy.<br></br>• Making a custom recurrent unit and training it one-at-a-time is easy.<br></br>• Batching is supported in RNN layers.<br></br>• Packing is supported too and there are cool utilities for it.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>The not-so-good:</strong><br></br>• Batching and packing are not explained in the tutorials.<br></br>• Combining packing with word embeddings is easy if using non-supported API, otherwise not really. It’s also not explained at all.<br></br>• RNN code does not seem to be written with custom-unit extensibility in mind.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Overall, I like PyTorch’s recurrent stuff a lot, despite the shortcomings. PyTorch offers some powerful capabilities out-of-the-box and they’re easy to use. Documentation seems slightly biased in favour of neural-net techniques versus expressing what the API can do, but that’s not always a bad thing. Extensibility is generally fine (PyTorch’s dynamic backprop’s flexibility is great), but there are shortcomings. It makes sense that the stable API is still in version 0.4.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So much for this time. Give a few claps if this was useful to you.</p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>