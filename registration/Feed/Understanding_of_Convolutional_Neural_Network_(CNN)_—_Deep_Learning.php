<!DOCTYPE html>
                <html>
                <head>
                    <title>Understanding of Convolutional Neural Network (CNN) — Deep Learning</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@RaghavPrabhu?source=post_page-----99760835f148--------------------------------">Author : Prabhu</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Understanding of Convolutional Neural Network (CNN) — Deep Learning</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In neural networks, Convolutional neural network (ConvNets or CNNs) is one of the main categories to do images recognition, images classifications. Objects detections, recognition faces etc., are some of the areas where CNNs are widely used.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">CNN image classifications takes an input image, process it and classify it under certain categories (Eg., Dog, Cat, Tiger, Lion). Computers sees an input image as array of pixels and it depends on the image resolution. Based on the image resolution, it will see h x w x d( h = Height, w = Width, d = Dimension ). Eg., An image of 6 x 6 x 3 array of matrix of RGB (3 refers to RGB values) and an image of 4 x 4 x 1 array of matrix of grayscale image.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:29%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 231px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*CBY94wikMUCZMB4-Xxs-pw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*CBY94wikMUCZMB4-Xxs-pw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*CBY94wikMUCZMB4-Xxs-pw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*CBY94wikMUCZMB4-Xxs-pw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*CBY94wikMUCZMB4-Xxs-pw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*CBY94wikMUCZMB4-Xxs-pw.png 1100w, https://miro.medium.com/v2/resize:fit:462/format:webp/1*CBY94wikMUCZMB4-Xxs-pw.png 462w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 231px" srcset="https://miro.medium.com/v2/resize:fit:640/1*CBY94wikMUCZMB4-Xxs-pw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*CBY94wikMUCZMB4-Xxs-pw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*CBY94wikMUCZMB4-Xxs-pw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*CBY94wikMUCZMB4-Xxs-pw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*CBY94wikMUCZMB4-Xxs-pw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*CBY94wikMUCZMB4-Xxs-pw.png 1100w, https://miro.medium.com/v2/resize:fit:462/1*CBY94wikMUCZMB4-Xxs-pw.png 462w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/231/1*CBY94wikMUCZMB4-Xxs-pw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><strong>Figure 1 : Array of RGB Matrix</strong></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Technically, deep learning CNN models to train and test, each input image will pass it through a series of convolution layers with filters (Kernals), Pooling, fully connected layers (FC) and apply Softmax function to classify an object with probabilistic values between 0 and 1. The below figure is a complete flow of CNN to process an input image and classifies the objects based on values.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><strong>Figure 2 : Neural network with many convolutional layers</strong></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Convolution Layer</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Convolution is the first layer to extract features from an input image. Convolution preserves the relationship between pixels by learning image features using small squares of input data. It is a mathematical operation that takes two inputs such as image matrix and a filter or kernel.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:61%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 461px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*kYSsNpy0b3fIonQya66VSQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*kYSsNpy0b3fIonQya66VSQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*kYSsNpy0b3fIonQya66VSQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*kYSsNpy0b3fIonQya66VSQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*kYSsNpy0b3fIonQya66VSQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*kYSsNpy0b3fIonQya66VSQ.png 1100w, https://miro.medium.com/v2/resize:fit:922/format:webp/1*kYSsNpy0b3fIonQya66VSQ.png 922w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 461px" srcset="https://miro.medium.com/v2/resize:fit:640/1*kYSsNpy0b3fIonQya66VSQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*kYSsNpy0b3fIonQya66VSQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*kYSsNpy0b3fIonQya66VSQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*kYSsNpy0b3fIonQya66VSQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*kYSsNpy0b3fIonQya66VSQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*kYSsNpy0b3fIonQya66VSQ.png 1100w, https://miro.medium.com/v2/resize:fit:922/1*kYSsNpy0b3fIonQya66VSQ.png 922w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/461/1*kYSsNpy0b3fIonQya66VSQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><strong>Figure 3: Image matrix multiplies kernel or filter matrix</strong></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Consider a 5 x 5 whose image pixel values are 0, 1 and filter matrix 3 x 3 as shown in below</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:55%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 413px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*4yv0yIH0nVhSOv3AkLUIiw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*4yv0yIH0nVhSOv3AkLUIiw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*4yv0yIH0nVhSOv3AkLUIiw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*4yv0yIH0nVhSOv3AkLUIiw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*4yv0yIH0nVhSOv3AkLUIiw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*4yv0yIH0nVhSOv3AkLUIiw.png 1100w, https://miro.medium.com/v2/resize:fit:826/format:webp/1*4yv0yIH0nVhSOv3AkLUIiw.png 826w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 413px" srcset="https://miro.medium.com/v2/resize:fit:640/1*4yv0yIH0nVhSOv3AkLUIiw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*4yv0yIH0nVhSOv3AkLUIiw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*4yv0yIH0nVhSOv3AkLUIiw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*4yv0yIH0nVhSOv3AkLUIiw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*4yv0yIH0nVhSOv3AkLUIiw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*4yv0yIH0nVhSOv3AkLUIiw.png 1100w, https://miro.medium.com/v2/resize:fit:826/1*4yv0yIH0nVhSOv3AkLUIiw.png 826w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/413/1*4yv0yIH0nVhSOv3AkLUIiw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><strong>Figure 4: Image matrix multiplies kernel or filter matrix</strong></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Then the convolution of 5 x 5 image matrix multiplies with 3 x 3 filter matrix which is called <strong>“Feature Map”</strong> as output shown in below</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:34%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 268px" srcset="https://miro.medium.com/v2/resize:fit:640/1*MrGSULUtkXc0Ou07QouV8A.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*MrGSULUtkXc0Ou07QouV8A.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*MrGSULUtkXc0Ou07QouV8A.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*MrGSULUtkXc0Ou07QouV8A.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*MrGSULUtkXc0Ou07QouV8A.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*MrGSULUtkXc0Ou07QouV8A.gif 1100w, https://miro.medium.com/v2/resize:fit:536/1*MrGSULUtkXc0Ou07QouV8A.gif 536w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 268px" srcset="https://miro.medium.com/v2/resize:fit:640/1*MrGSULUtkXc0Ou07QouV8A.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*MrGSULUtkXc0Ou07QouV8A.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*MrGSULUtkXc0Ou07QouV8A.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*MrGSULUtkXc0Ou07QouV8A.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*MrGSULUtkXc0Ou07QouV8A.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*MrGSULUtkXc0Ou07QouV8A.gif 1100w, https://miro.medium.com/v2/resize:fit:536/1*MrGSULUtkXc0Ou07QouV8A.gif 536w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/268/1*MrGSULUtkXc0Ou07QouV8A.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><strong>Figure 5: 3 x 3 Output matrix</strong></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Convolution of an image with different filters can perform operations such as edge detection, blur and sharpen by applying filters. The below example shows various convolution image after applying different types of filters (Kernels).</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:45%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 349px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*uJpkfkm2Lr72mJtRaqoKZg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*uJpkfkm2Lr72mJtRaqoKZg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*uJpkfkm2Lr72mJtRaqoKZg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*uJpkfkm2Lr72mJtRaqoKZg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*uJpkfkm2Lr72mJtRaqoKZg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*uJpkfkm2Lr72mJtRaqoKZg.png 1100w, https://miro.medium.com/v2/resize:fit:698/format:webp/1*uJpkfkm2Lr72mJtRaqoKZg.png 698w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 349px" srcset="https://miro.medium.com/v2/resize:fit:640/1*uJpkfkm2Lr72mJtRaqoKZg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*uJpkfkm2Lr72mJtRaqoKZg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*uJpkfkm2Lr72mJtRaqoKZg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*uJpkfkm2Lr72mJtRaqoKZg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*uJpkfkm2Lr72mJtRaqoKZg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*uJpkfkm2Lr72mJtRaqoKZg.png 1100w, https://miro.medium.com/v2/resize:fit:698/1*uJpkfkm2Lr72mJtRaqoKZg.png 698w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/349/1*uJpkfkm2Lr72mJtRaqoKZg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure 7 : Some common filters</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Strides</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><mark>Stride is the number of pixels shifts over the input matrix.</mark> When the stride is 1 then we move the filters to 1 pixel at a time. When the stride is 2 then we move the filters to 2 pixels at a time and so on. The below figure shows convolution would work with a stride of 2.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:95%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 695px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*nGHLq1hx0gt02OK4l8WmRg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*nGHLq1hx0gt02OK4l8WmRg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*nGHLq1hx0gt02OK4l8WmRg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*nGHLq1hx0gt02OK4l8WmRg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*nGHLq1hx0gt02OK4l8WmRg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*nGHLq1hx0gt02OK4l8WmRg.png 1100w, https://miro.medium.com/v2/resize:fit:1390/format:webp/1*nGHLq1hx0gt02OK4l8WmRg.png 1390w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 695px" srcset="https://miro.medium.com/v2/resize:fit:640/1*nGHLq1hx0gt02OK4l8WmRg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*nGHLq1hx0gt02OK4l8WmRg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*nGHLq1hx0gt02OK4l8WmRg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*nGHLq1hx0gt02OK4l8WmRg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*nGHLq1hx0gt02OK4l8WmRg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*nGHLq1hx0gt02OK4l8WmRg.png 1100w, https://miro.medium.com/v2/resize:fit:1390/1*nGHLq1hx0gt02OK4l8WmRg.png 1390w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/695/1*nGHLq1hx0gt02OK4l8WmRg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure 6 : Stride of 2 pixels</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Padding</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Sometimes filter does not fit perfectly fit the input image. We have two options:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">Pad the picture with zeros (zero-padding) so that it fits</li><li class="ff3" style="font-size:22px;">Drop the part of the image where the filter did not fit. This is called valid padding which keeps only valid part of the image.</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Non Linearity (ReLU)</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">ReLU stands for Rectified Linear Unit for a non-linear operation. The output is <strong>ƒ(x) = max(0,x).</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Why ReLU is important : ReLU’s purpose is to introduce non-linearity in our ConvNet. Since, the real world data would want our ConvNet to learn would be non-negative linear values.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:60%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 449px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*gcvuKm3nUePXwUOLXfLIMQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*gcvuKm3nUePXwUOLXfLIMQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*gcvuKm3nUePXwUOLXfLIMQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*gcvuKm3nUePXwUOLXfLIMQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*gcvuKm3nUePXwUOLXfLIMQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*gcvuKm3nUePXwUOLXfLIMQ.png 1100w, https://miro.medium.com/v2/resize:fit:898/format:webp/1*gcvuKm3nUePXwUOLXfLIMQ.png 898w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 449px" srcset="https://miro.medium.com/v2/resize:fit:640/1*gcvuKm3nUePXwUOLXfLIMQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*gcvuKm3nUePXwUOLXfLIMQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*gcvuKm3nUePXwUOLXfLIMQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*gcvuKm3nUePXwUOLXfLIMQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*gcvuKm3nUePXwUOLXfLIMQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*gcvuKm3nUePXwUOLXfLIMQ.png 1100w, https://miro.medium.com/v2/resize:fit:898/1*gcvuKm3nUePXwUOLXfLIMQ.png 898w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/449/1*gcvuKm3nUePXwUOLXfLIMQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure 7 : ReLU operation</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">There are other non linear functions such as tanh or sigmoid that can also be used instead of ReLU. Most of the data scientists use ReLU since performance wise ReLU is better than the other two.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Pooling Layer</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Pooling layers section would reduce the number of parameters when the images are too large. Spatial pooling also called subsampling or downsampling which reduces the dimensionality of each map but retains important information. Spatial pooling can be of different types:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">Max Pooling</li><li class="ff3" style="font-size:22px;">Average Pooling</li><li class="ff3" style="font-size:22px;">Sum Pooling</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Max pooling takes the largest element from the rectified feature map. Taking the largest element could also take the average pooling. Sum of all elements in the feature map call as sum pooling.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:82%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 602px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*SmiydxM5lbTjoKWYPiuzWQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*SmiydxM5lbTjoKWYPiuzWQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*SmiydxM5lbTjoKWYPiuzWQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*SmiydxM5lbTjoKWYPiuzWQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*SmiydxM5lbTjoKWYPiuzWQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*SmiydxM5lbTjoKWYPiuzWQ.png 1100w, https://miro.medium.com/v2/resize:fit:1204/format:webp/1*SmiydxM5lbTjoKWYPiuzWQ.png 1204w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 602px" srcset="https://miro.medium.com/v2/resize:fit:640/1*SmiydxM5lbTjoKWYPiuzWQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*SmiydxM5lbTjoKWYPiuzWQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*SmiydxM5lbTjoKWYPiuzWQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*SmiydxM5lbTjoKWYPiuzWQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*SmiydxM5lbTjoKWYPiuzWQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*SmiydxM5lbTjoKWYPiuzWQ.png 1100w, https://miro.medium.com/v2/resize:fit:1204/1*SmiydxM5lbTjoKWYPiuzWQ.png 1204w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/602/1*SmiydxM5lbTjoKWYPiuzWQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure 8 : Max Pooling</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Fully Connected Layer</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The layer we call as FC layer, we flattened our matrix into vector and feed it into a fully connected layer like a neural network.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:75%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 554px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Mw6LKUG8AWQhG73H1caT8w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Mw6LKUG8AWQhG73H1caT8w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Mw6LKUG8AWQhG73H1caT8w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Mw6LKUG8AWQhG73H1caT8w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Mw6LKUG8AWQhG73H1caT8w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Mw6LKUG8AWQhG73H1caT8w.png 1100w, https://miro.medium.com/v2/resize:fit:1108/format:webp/1*Mw6LKUG8AWQhG73H1caT8w.png 1108w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 554px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Mw6LKUG8AWQhG73H1caT8w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Mw6LKUG8AWQhG73H1caT8w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Mw6LKUG8AWQhG73H1caT8w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Mw6LKUG8AWQhG73H1caT8w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Mw6LKUG8AWQhG73H1caT8w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Mw6LKUG8AWQhG73H1caT8w.png 1100w, https://miro.medium.com/v2/resize:fit:1108/1*Mw6LKUG8AWQhG73H1caT8w.png 1108w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/554/1*Mw6LKUG8AWQhG73H1caT8w.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure 9 : After pooling layer, flattened as FC layer</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the above diagram, the feature map matrix will be converted as vector (x1, x2, x3, …). With the fully connected layers, we combined these features together to create a model. Finally, we have an activation function such as softmax or sigmoid to classify the outputs as cat, dog, car, truck etc.,</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*4GLv7_4BbKXnpc6BRb0Aew.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*4GLv7_4BbKXnpc6BRb0Aew.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*4GLv7_4BbKXnpc6BRb0Aew.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*4GLv7_4BbKXnpc6BRb0Aew.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*4GLv7_4BbKXnpc6BRb0Aew.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*4GLv7_4BbKXnpc6BRb0Aew.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4GLv7_4BbKXnpc6BRb0Aew.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*4GLv7_4BbKXnpc6BRb0Aew.png 640w, https://miro.medium.com/v2/resize:fit:720/1*4GLv7_4BbKXnpc6BRb0Aew.png 720w, https://miro.medium.com/v2/resize:fit:750/1*4GLv7_4BbKXnpc6BRb0Aew.png 750w, https://miro.medium.com/v2/resize:fit:786/1*4GLv7_4BbKXnpc6BRb0Aew.png 786w, https://miro.medium.com/v2/resize:fit:828/1*4GLv7_4BbKXnpc6BRb0Aew.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*4GLv7_4BbKXnpc6BRb0Aew.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*4GLv7_4BbKXnpc6BRb0Aew.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*4GLv7_4BbKXnpc6BRb0Aew.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure 10 : Complete CNN architecture</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Summary</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">Provide input image into convolution layer</li><li class="ff3" style="font-size:22px;">Choose parameters, apply filters with strides, padding if requires. Perform convolution on the image and apply ReLU activation to the matrix.</li><li class="ff3" style="font-size:22px;">Perform pooling to reduce dimensionality size</li><li class="ff3" style="font-size:22px;">Add as many convolutional layers until satisfied</li><li class="ff3" style="font-size:22px;">Flatten the output and feed into a fully connected layer (FC Layer)</li><li class="ff3" style="font-size:22px;">Output the class using an activation function (Logistic Regression with cost functions) and classifies images.</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the next post, I would like to talk about some popular CNN architectures such as AlexNet, VGGNet, GoogLeNet, and ResNet.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>References :</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><a href="https://www.mathworks.com/discovery/convolutional-neural-network.html" target="_self">https://www.mathworks.com/discovery/convolutional-neural-network.html</a></li><li class="ff3" style="font-size:22px;"><a href="https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/" target="_self">https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/</a></li><li class="ff3" style="font-size:22px;"><a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" target="_self">https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/</a></li><li class="ff3" style="font-size:22px;"><a href="https://blog.datawow.io/interns-explain-cnn-8a669d053f8b" target="_self">https://blog.datawow.io/interns-explain-cnn-8a669d053f8b</a>.</li></ul></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>