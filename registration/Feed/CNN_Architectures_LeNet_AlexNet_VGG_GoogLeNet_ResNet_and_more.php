<!DOCTYPE html>
                <html>
                <head>
                    <title>CNN Architectures: LeNet, AlexNet, VGG, GoogLeNet, ResNet and more…</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@sidereal?source=post_page-----666091488df5--------------------------------">Author : Siddharth Das</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>CNN Architectures: LeNet, AlexNet, VGG, GoogLeNet, ResNet and more…</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>A Convolutional Neural Network</strong> (<strong>CNN</strong>, or <strong>ConvNet</strong>) are a special kind of multi-layer neural networks, designed to recognize visual patterns directly from pixel images with minimal preprocessing.. The <strong>ImageNet</strong> project is a large visual database designed for use in visual object recognition software research. The ImageNet project runs an annual software contest, the <strong>ImageNet Large Scale Visual Recognition Challenge (</strong><a href="https://en.wikipedia.org/wiki/ImageNet#ImageNet_Challenge" target="_self">ILSVRC</a><strong>)</strong>, where software programs compete to correctly classify and detect objects and scenes. Here I will talk about CNN architectures of ILSVRC top competitors .</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*DBXf6dzNB78QPHGDofHA4Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*DBXf6dzNB78QPHGDofHA4Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*DBXf6dzNB78QPHGDofHA4Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*DBXf6dzNB78QPHGDofHA4Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*DBXf6dzNB78QPHGDofHA4Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*DBXf6dzNB78QPHGDofHA4Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DBXf6dzNB78QPHGDofHA4Q.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*DBXf6dzNB78QPHGDofHA4Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*DBXf6dzNB78QPHGDofHA4Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*DBXf6dzNB78QPHGDofHA4Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*DBXf6dzNB78QPHGDofHA4Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*DBXf6dzNB78QPHGDofHA4Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*DBXf6dzNB78QPHGDofHA4Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*DBXf6dzNB78QPHGDofHA4Q.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*DBXf6dzNB78QPHGDofHA4Q.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">LeNet-5 (1998)</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">LeNet-5, a pioneering 7-level convolutional network by LeCun et al in 1998, that classifies digits, was applied by several banks to recognise hand-written numbers on checks (cheques) digitized in 32x32 pixel greyscale inputimages. The ability to process higher resolution images requires larger and more convolutional layers, so this technique is constrained by the availability of computing resources.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*MU7G1aH1jw-6eFiD.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*MU7G1aH1jw-6eFiD.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*MU7G1aH1jw-6eFiD.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*MU7G1aH1jw-6eFiD.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*MU7G1aH1jw-6eFiD.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*MU7G1aH1jw-6eFiD.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MU7G1aH1jw-6eFiD.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*MU7G1aH1jw-6eFiD.png 640w, https://miro.medium.com/v2/resize:fit:720/0*MU7G1aH1jw-6eFiD.png 720w, https://miro.medium.com/v2/resize:fit:750/0*MU7G1aH1jw-6eFiD.png 750w, https://miro.medium.com/v2/resize:fit:786/0*MU7G1aH1jw-6eFiD.png 786w, https://miro.medium.com/v2/resize:fit:828/0*MU7G1aH1jw-6eFiD.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*MU7G1aH1jw-6eFiD.png 1100w, https://miro.medium.com/v2/resize:fit:1400/0*MU7G1aH1jw-6eFiD.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*MU7G1aH1jw-6eFiD.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">AlexNet (2012)</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In 2012, <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_self">AlexNet</a> significantly outperformed all the prior competitors and won the challenge by reducing the top-5 error from 26% to 15.3%. The second place top-5 error rate, which was not a CNN variation, was around 26.2%.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:94%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 686px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*xPOQ3btZ9rQO23LK.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*xPOQ3btZ9rQO23LK.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*xPOQ3btZ9rQO23LK.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*xPOQ3btZ9rQO23LK.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*xPOQ3btZ9rQO23LK.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*xPOQ3btZ9rQO23LK.png 1100w, https://miro.medium.com/v2/resize:fit:1372/format:webp/0*xPOQ3btZ9rQO23LK.png 1372w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 686px" srcset="https://miro.medium.com/v2/resize:fit:640/0*xPOQ3btZ9rQO23LK.png 640w, https://miro.medium.com/v2/resize:fit:720/0*xPOQ3btZ9rQO23LK.png 720w, https://miro.medium.com/v2/resize:fit:750/0*xPOQ3btZ9rQO23LK.png 750w, https://miro.medium.com/v2/resize:fit:786/0*xPOQ3btZ9rQO23LK.png 786w, https://miro.medium.com/v2/resize:fit:828/0*xPOQ3btZ9rQO23LK.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*xPOQ3btZ9rQO23LK.png 1100w, https://miro.medium.com/v2/resize:fit:1372/0*xPOQ3btZ9rQO23LK.png 1372w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/686/0*xPOQ3btZ9rQO23LK.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The network had a very similar architecture as <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" target="_self">LeNet</a> by Yann LeCun et al but was deeper, with more filters per layer, and with stacked convolutional layers. It consisted 11x11, 5x5,3x3, convolutions, max pooling, dropout, data augmentation, ReLU activations, SGD with momentum. It attached ReLU activations after every convolutional and fully-connected layer. AlexNet was trained for 6 days simultaneously on two Nvidia Geforce GTX 580 GPUs which is the reason for why their network is split into two pipelines. AlexNet was designed by the SuperVision group, consisting of Alex Krizhevsky, Geoffrey Hinton, and Ilya Sutskever.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">ZFNet(2013)</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Not surprisingly, the ILSVRC 2013 winner was also a CNN which became known as ZFNet. It achieved a top-5 error rate of 14.8% which is now already half of the prior mentioned non-neural error rate. It was mostly an achievement by tweaking the hyper-parameters of AlexNet while maintaining the same structure with additional Deep Learning elements as discussed earlier in this essay.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*g-Iwui1uFUPPHxuq8GfL6Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*g-Iwui1uFUPPHxuq8GfL6Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*g-Iwui1uFUPPHxuq8GfL6Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*g-Iwui1uFUPPHxuq8GfL6Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*g-Iwui1uFUPPHxuq8GfL6Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*g-Iwui1uFUPPHxuq8GfL6Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g-Iwui1uFUPPHxuq8GfL6Q.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*g-Iwui1uFUPPHxuq8GfL6Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*g-Iwui1uFUPPHxuq8GfL6Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*g-Iwui1uFUPPHxuq8GfL6Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*g-Iwui1uFUPPHxuq8GfL6Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*g-Iwui1uFUPPHxuq8GfL6Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*g-Iwui1uFUPPHxuq8GfL6Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*g-Iwui1uFUPPHxuq8GfL6Q.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*g-Iwui1uFUPPHxuq8GfL6Q.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">GoogLeNet/Inception(2014)</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The winner of the ILSVRC 2014 competition was GoogLeNet(a.k.a. Inception V1) from Google. It achieved a top-5 error rate of 6.67%! This was very close to human level performance which the organisers of the challenge were now forced to evaluate. As it turns out, this was actually rather hard to do and required some human training in order to beat GoogLeNets accuracy. After a few days of training, the human expert (Andrej Karpathy) was able to achieve a top-5 error rate of 5.1%(single model) and 3.6%(ensemble). The network used a CNN inspired by LeNet but implemented a novel element which is dubbed an inception module. It used batch normalization, image distortions and RMSprop. This module is based on several very small convolutions in order to drastically reduce the number of parameters. Their architecture consisted of a 22 layer deep CNN but reduced the number of parameters from 60 million (AlexNet) to 4 million.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*rbWRzjKvoGt9W3Mf.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*rbWRzjKvoGt9W3Mf.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*rbWRzjKvoGt9W3Mf.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*rbWRzjKvoGt9W3Mf.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*rbWRzjKvoGt9W3Mf.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*rbWRzjKvoGt9W3Mf.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rbWRzjKvoGt9W3Mf.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*rbWRzjKvoGt9W3Mf.png 640w, https://miro.medium.com/v2/resize:fit:720/0*rbWRzjKvoGt9W3Mf.png 720w, https://miro.medium.com/v2/resize:fit:750/0*rbWRzjKvoGt9W3Mf.png 750w, https://miro.medium.com/v2/resize:fit:786/0*rbWRzjKvoGt9W3Mf.png 786w, https://miro.medium.com/v2/resize:fit:828/0*rbWRzjKvoGt9W3Mf.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*rbWRzjKvoGt9W3Mf.png 1100w, https://miro.medium.com/v2/resize:fit:1400/0*rbWRzjKvoGt9W3Mf.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*rbWRzjKvoGt9W3Mf.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">VGGNet (2014)</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The runner-up at the ILSVRC 2014 competition is dubbed VGGNet by the community and was developed by Simonyan and Zisserman. <mark>VGGNet consists of 16 convolutional layers and is very appealing because of its very uniform architecture.</mark> Similar to AlexNet, only 3x3 convolutions, but lots of filters. Trained on 4 GPUs for 2–3 weeks. It is currently the most preferred choice in the community for extracting features from images. The weight configuration of the VGGNet is publicly available and has been used in many other applications and challenges as a baseline feature extractor. However, VGGNet consists of 138 million parameters, which can be a bit challenging to handle.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*V1muWIDnPVwZUuEv.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*V1muWIDnPVwZUuEv.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*V1muWIDnPVwZUuEv.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*V1muWIDnPVwZUuEv.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*V1muWIDnPVwZUuEv.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*V1muWIDnPVwZUuEv.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*V1muWIDnPVwZUuEv.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*V1muWIDnPVwZUuEv.png 640w, https://miro.medium.com/v2/resize:fit:720/0*V1muWIDnPVwZUuEv.png 720w, https://miro.medium.com/v2/resize:fit:750/0*V1muWIDnPVwZUuEv.png 750w, https://miro.medium.com/v2/resize:fit:786/0*V1muWIDnPVwZUuEv.png 786w, https://miro.medium.com/v2/resize:fit:828/0*V1muWIDnPVwZUuEv.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*V1muWIDnPVwZUuEv.png 1100w, https://miro.medium.com/v2/resize:fit:1400/0*V1muWIDnPVwZUuEv.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*V1muWIDnPVwZUuEv.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">ResNet(2015)</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">At last, at the ILSVRC 2015, the so-called Residual Neural Network (ResNet) by Kaiming He et al introduced anovel architecture with “skip connections” and features heavy batch normalization. Such skip connections are also known as gated units or gated recurrent units and have a strong similarity to recent successful elements applied in RNNs. Thanks to this technique they were able to train a NN with 152 layers while still having lower complexity than VGGNet. It achieves a top-5 error rate of 3.57% which beats human-level performance on this dataset.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*pkrso8DZa0m6IAcJ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*pkrso8DZa0m6IAcJ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*pkrso8DZa0m6IAcJ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*pkrso8DZa0m6IAcJ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*pkrso8DZa0m6IAcJ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*pkrso8DZa0m6IAcJ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pkrso8DZa0m6IAcJ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*pkrso8DZa0m6IAcJ.png 640w, https://miro.medium.com/v2/resize:fit:720/0*pkrso8DZa0m6IAcJ.png 720w, https://miro.medium.com/v2/resize:fit:750/0*pkrso8DZa0m6IAcJ.png 750w, https://miro.medium.com/v2/resize:fit:786/0*pkrso8DZa0m6IAcJ.png 786w, https://miro.medium.com/v2/resize:fit:828/0*pkrso8DZa0m6IAcJ.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*pkrso8DZa0m6IAcJ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/0*pkrso8DZa0m6IAcJ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*pkrso8DZa0m6IAcJ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">AlexNet has parallel two CNN line trained on two GPUs with cross-connections, GoogleNet has inception modules ,ResNet has residual connections.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ZqkLRkMU2ObOQWIHLBg8sw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ZqkLRkMU2ObOQWIHLBg8sw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ZqkLRkMU2ObOQWIHLBg8sw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ZqkLRkMU2ObOQWIHLBg8sw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ZqkLRkMU2ObOQWIHLBg8sw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ZqkLRkMU2ObOQWIHLBg8sw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZqkLRkMU2ObOQWIHLBg8sw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*ZqkLRkMU2ObOQWIHLBg8sw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ZqkLRkMU2ObOQWIHLBg8sw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ZqkLRkMU2ObOQWIHLBg8sw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ZqkLRkMU2ObOQWIHLBg8sw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ZqkLRkMU2ObOQWIHLBg8sw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ZqkLRkMU2ObOQWIHLBg8sw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*ZqkLRkMU2ObOQWIHLBg8sw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*ZqkLRkMU2ObOQWIHLBg8sw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Summary Table</strong></p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:73%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 539px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*q1QRxnGxg8COheh8tWXAiw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*q1QRxnGxg8COheh8tWXAiw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*q1QRxnGxg8COheh8tWXAiw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*q1QRxnGxg8COheh8tWXAiw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*q1QRxnGxg8COheh8tWXAiw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*q1QRxnGxg8COheh8tWXAiw.png 1100w, https://miro.medium.com/v2/resize:fit:1078/format:webp/1*q1QRxnGxg8COheh8tWXAiw.png 1078w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 539px" srcset="https://miro.medium.com/v2/resize:fit:640/1*q1QRxnGxg8COheh8tWXAiw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*q1QRxnGxg8COheh8tWXAiw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*q1QRxnGxg8COheh8tWXAiw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*q1QRxnGxg8COheh8tWXAiw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*q1QRxnGxg8COheh8tWXAiw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*q1QRxnGxg8COheh8tWXAiw.png 1100w, https://miro.medium.com/v2/resize:fit:1078/1*q1QRxnGxg8COheh8tWXAiw.png 1078w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/539/1*q1QRxnGxg8COheh8tWXAiw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><em>Please comment to correct me i f I am wrong and if you want me to add something :)</em></p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>