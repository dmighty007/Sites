<!DOCTYPE html>
                <html>
                <head>
                    <title>Time Series Forecasting with RNNs</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://towardsdatascience.com/time-series-forecasting-with-rnns-ff22683bbbb0"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@marekgalovic?source=post_page-----ff22683bbbb0--------------------------------">Author : Marek Galovič</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Time Series Forecasting with RNNs</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this article I want to give you an overview of a RNN model I built to forecast time series data. Main objectives of this work were to design a model that can not only predict the very next time step but rather generate a sequence of predictions and utilize multiple driving time series together with a set of static (scalar) features as its inputs.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Model architecture</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">On a high level, this model utilizes pretty standard sequence-to-sequence recurrent neural network architecture. Its inputs are past values of the predicted time series concatenated with other driving time series values (optional) and timestamp embeddings (optional). If static features are available the model can utilize them to condition the prediction too.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7"><strong>Encoder</strong></h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Encoder is used to encode time series inputs with their respective timestamp embeddings [<strong>x</strong>] to a fixed size vector representation [<strong>S</strong>]. It also produces latent vectors for individual time steps [<strong>h</strong>] which are used later in decoder attention. For this purpose, I utilized a multi-layer unidirectional <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" target="_self">recurrent neural network</a> where all layers except the first one are <a href="https://en.wikipedia.org/wiki/Residual_neural_network" target="_self">residual.</a></p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*frw-ZP6eFXfnU0aChdeXvg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*frw-ZP6eFXfnU0aChdeXvg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*frw-ZP6eFXfnU0aChdeXvg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*frw-ZP6eFXfnU0aChdeXvg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*frw-ZP6eFXfnU0aChdeXvg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*frw-ZP6eFXfnU0aChdeXvg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*frw-ZP6eFXfnU0aChdeXvg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*frw-ZP6eFXfnU0aChdeXvg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*frw-ZP6eFXfnU0aChdeXvg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*frw-ZP6eFXfnU0aChdeXvg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*frw-ZP6eFXfnU0aChdeXvg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*frw-ZP6eFXfnU0aChdeXvg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*frw-ZP6eFXfnU0aChdeXvg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*frw-ZP6eFXfnU0aChdeXvg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*frw-ZP6eFXfnU0aChdeXvg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Fig. 1. — Example 2-layer encoder</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In some cases you may have input sequences that are too long and can cause the training to fail because of GPU memory issues or slow it down significantly. To deal with this issue, the model convolves the input sequence with a 1D <a href="https://en.wikipedia.org/wiki/Convolution" target="_self">convolution</a> that has the same kernel size and stride before feeding it to the RNN encoder. This reduces the RNN input by a factor of <strong>n </strong>where <strong>n </strong>is the convolution kernel size.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Context</h4></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*wMjf8vGJBCciKtVTEUoHSA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*wMjf8vGJBCciKtVTEUoHSA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*wMjf8vGJBCciKtVTEUoHSA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*wMjf8vGJBCciKtVTEUoHSA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*wMjf8vGJBCciKtVTEUoHSA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*wMjf8vGJBCciKtVTEUoHSA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wMjf8vGJBCciKtVTEUoHSA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*wMjf8vGJBCciKtVTEUoHSA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*wMjf8vGJBCciKtVTEUoHSA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*wMjf8vGJBCciKtVTEUoHSA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*wMjf8vGJBCciKtVTEUoHSA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*wMjf8vGJBCciKtVTEUoHSA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*wMjf8vGJBCciKtVTEUoHSA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*wMjf8vGJBCciKtVTEUoHSA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*wMjf8vGJBCciKtVTEUoHSA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Fig. 2. — Context layer</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Context layer sits between the inputs encoder and a decoder layer. It concatenates encoder final state [<strong>S</strong>] with static features and static embeddings and produces a fixed size vector [<strong>C</strong>] which is then used as an initial state for the decoder.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Decoder</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Decoder layer is implemented as an <a href="https://en.wikipedia.org/wiki/Autoregressive_model" target="_self">autoregressive</a> recurrent neural network with <a href="https://arxiv.org/pdf/1409.0473.pdf" target="_self">attention</a>. Input at each step is a concatenation of previous sequence value and a timestamp embedding for that step. Feeding timestamp embeddings to the decoder helps the model learn patterns in seasonal data.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*gNc-M-kITbghpop0yJhpsg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*gNc-M-kITbghpop0yJhpsg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*gNc-M-kITbghpop0yJhpsg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*gNc-M-kITbghpop0yJhpsg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*gNc-M-kITbghpop0yJhpsg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*gNc-M-kITbghpop0yJhpsg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gNc-M-kITbghpop0yJhpsg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*gNc-M-kITbghpop0yJhpsg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*gNc-M-kITbghpop0yJhpsg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*gNc-M-kITbghpop0yJhpsg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*gNc-M-kITbghpop0yJhpsg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*gNc-M-kITbghpop0yJhpsg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*gNc-M-kITbghpop0yJhpsg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*gNc-M-kITbghpop0yJhpsg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*gNc-M-kITbghpop0yJhpsg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Fig. 3. — Decoder layer</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">At the first step, encoder takes the context [<strong>C</strong>] as an initial cell value and a concatenation of initial sequence value [<strong>v</strong>] and first timestamp embedding [<strong>E</strong>] as a cell input. First layer then emits attention query [<strong>q</strong>] that is fed to attention module which outputs a state [<strong>s</strong>] that is then used as a cell state in the next step. Lower layers of the decoder don’t use attention. Outputs of the decoder [<strong>o</strong>] are the raw predicted values which are then fed to the next step together with a timestamp embedding for that step.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7"><strong>Attention</strong></h4></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*GwW6yRbIymkprbd2gstJtA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*GwW6yRbIymkprbd2gstJtA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*GwW6yRbIymkprbd2gstJtA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*GwW6yRbIymkprbd2gstJtA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*GwW6yRbIymkprbd2gstJtA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*GwW6yRbIymkprbd2gstJtA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GwW6yRbIymkprbd2gstJtA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*GwW6yRbIymkprbd2gstJtA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*GwW6yRbIymkprbd2gstJtA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*GwW6yRbIymkprbd2gstJtA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*GwW6yRbIymkprbd2gstJtA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*GwW6yRbIymkprbd2gstJtA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*GwW6yRbIymkprbd2gstJtA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*GwW6yRbIymkprbd2gstJtA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*GwW6yRbIymkprbd2gstJtA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Fig. 4. — Attention</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Attention allows the decoder to selectively access encoder information during decoding. It does so by learning a weighting function that takes previous cell state [<strong>q</strong>] and a list of encoder outputs [<strong>h</strong>] as an input and outputs a scalar weight for each of the encoder outputs. It then takes a weighted sum of encoder outputs, concatenates it with the query and takes a nonlinear projection as a next cell state. Mathematically this can be formulated as follows:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:41%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 319px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*hBN1F5VmiE8nMcLcWXZ2dw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*hBN1F5VmiE8nMcLcWXZ2dw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*hBN1F5VmiE8nMcLcWXZ2dw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*hBN1F5VmiE8nMcLcWXZ2dw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*hBN1F5VmiE8nMcLcWXZ2dw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*hBN1F5VmiE8nMcLcWXZ2dw.png 1100w, https://miro.medium.com/v2/resize:fit:638/format:webp/1*hBN1F5VmiE8nMcLcWXZ2dw.png 638w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 319px" srcset="https://miro.medium.com/v2/resize:fit:640/1*hBN1F5VmiE8nMcLcWXZ2dw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*hBN1F5VmiE8nMcLcWXZ2dw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*hBN1F5VmiE8nMcLcWXZ2dw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*hBN1F5VmiE8nMcLcWXZ2dw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*hBN1F5VmiE8nMcLcWXZ2dw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*hBN1F5VmiE8nMcLcWXZ2dw.png 1100w, https://miro.medium.com/v2/resize:fit:638/1*hBN1F5VmiE8nMcLcWXZ2dw.png 638w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/319/1*hBN1F5VmiE8nMcLcWXZ2dw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Eqn. 1. — Attention function</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Data preparation</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">I won’t do a step by step tutorial on how to prepare data for a sequence to sequence learning problem in this article but I’ll try to give you an overview of the steps needed to get the model working.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">First you want to make sure that the span of your time series features doesn’t overlap with the span of your targets and that the latest features timestamp is right before first targets timestamp. Also, if you have any static features (aggregate statistics for example) they need to be aggregated up to the last features timestamp. I know this sounds obvious but sometimes it’s really easy to overlook and get excited by how great your model performs just to find out that you leaked future information into your training dataset.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The data, both features and targets, need to be normalized into a suitable range for a neural network model. This usually means somewhere between <strong>-1</strong> and <strong>1</strong>. Normalization scheme I decided to go with was to first take a <strong>log </strong>to remove any potential skew and then compute a <strong>mean</strong> and <strong>standard deviation</strong>. Input to the network is then a <strong>z-score</strong> of the log.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:38%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 294px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*naIb6GHEg3QIHlq3tqSkNw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*naIb6GHEg3QIHlq3tqSkNw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*naIb6GHEg3QIHlq3tqSkNw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*naIb6GHEg3QIHlq3tqSkNw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*naIb6GHEg3QIHlq3tqSkNw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*naIb6GHEg3QIHlq3tqSkNw.png 1100w, https://miro.medium.com/v2/resize:fit:588/format:webp/1*naIb6GHEg3QIHlq3tqSkNw.png 588w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 294px" srcset="https://miro.medium.com/v2/resize:fit:640/1*naIb6GHEg3QIHlq3tqSkNw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*naIb6GHEg3QIHlq3tqSkNw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*naIb6GHEg3QIHlq3tqSkNw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*naIb6GHEg3QIHlq3tqSkNw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*naIb6GHEg3QIHlq3tqSkNw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*naIb6GHEg3QIHlq3tqSkNw.png 1100w, https://miro.medium.com/v2/resize:fit:588/1*naIb6GHEg3QIHlq3tqSkNw.png 588w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/294/1*naIb6GHEg3QIHlq3tqSkNw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Eqn. 2. — Features normalization</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For the target value there are multiple normalization options. One could for example forecast a relative change from the latest input value (can be an issue in case it’s 0) or normalized absolute values using a similar approach I described above for the features.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Results</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As an example for this article I used the model described above to predict closing price of Shopify stock for next five trading days given data from last sixty trading days. <mark>An input sequence convolution layer with kernel/stride = 5 was used to reduce the encoder RNN input size from 60 to 12 steps.</mark></p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*hHMa20hiWvWlw6E-mk4Z8g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*hHMa20hiWvWlw6E-mk4Z8g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*hHMa20hiWvWlw6E-mk4Z8g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*hHMa20hiWvWlw6E-mk4Z8g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*hHMa20hiWvWlw6E-mk4Z8g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*hHMa20hiWvWlw6E-mk4Z8g.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hHMa20hiWvWlw6E-mk4Z8g.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*hHMa20hiWvWlw6E-mk4Z8g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*hHMa20hiWvWlw6E-mk4Z8g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*hHMa20hiWvWlw6E-mk4Z8g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*hHMa20hiWvWlw6E-mk4Z8g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*hHMa20hiWvWlw6E-mk4Z8g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*hHMa20hiWvWlw6E-mk4Z8g.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*hHMa20hiWvWlw6E-mk4Z8g.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*hHMa20hiWvWlw6E-mk4Z8g.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Chart 1. — Shopify closing price</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">One could argue that the stock price is unpredictable without taking other factors such as news into consideration (even then it’s very hard). That is why I decided to use another six tickers (Apple, Amazon, Google, Facebook, Microsoft and IBM) as inputs to the model so that it can learn possible correlations between them. The features used were daily Open, High, Low, Close Price (OHLC) and Volume. I augmented the time series features with “spread” (<code>abs(high-low)</code>) and a past 60 days mean of each feature as a static input.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*hSw-oOXNU75npoiu3aBOAQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*hSw-oOXNU75npoiu3aBOAQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*hSw-oOXNU75npoiu3aBOAQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*hSw-oOXNU75npoiu3aBOAQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*hSw-oOXNU75npoiu3aBOAQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*hSw-oOXNU75npoiu3aBOAQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hSw-oOXNU75npoiu3aBOAQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*hSw-oOXNU75npoiu3aBOAQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*hSw-oOXNU75npoiu3aBOAQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*hSw-oOXNU75npoiu3aBOAQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*hSw-oOXNU75npoiu3aBOAQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*hSw-oOXNU75npoiu3aBOAQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*hSw-oOXNU75npoiu3aBOAQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*hSw-oOXNU75npoiu3aBOAQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*hSw-oOXNU75npoiu3aBOAQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Chart 2. — MAE by day</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><em>Chart 2.</em> shows a mean absolute error per day. We can see that the further we go into the future the worse our predictions become. Intuitively this makes sense as the model has a better chance of making a good prediction for the very next trading day than five days from now.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As with every machine learning model there are successes where the model makes a very good prediction and failures where the prediction is not so great. The following are some examples of such cases.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*bxggvI0MNlEOPKTOzN6M_g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*bxggvI0MNlEOPKTOzN6M_g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*bxggvI0MNlEOPKTOzN6M_g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*bxggvI0MNlEOPKTOzN6M_g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*bxggvI0MNlEOPKTOzN6M_g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*bxggvI0MNlEOPKTOzN6M_g.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bxggvI0MNlEOPKTOzN6M_g.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*bxggvI0MNlEOPKTOzN6M_g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*bxggvI0MNlEOPKTOzN6M_g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*bxggvI0MNlEOPKTOzN6M_g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*bxggvI0MNlEOPKTOzN6M_g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*bxggvI0MNlEOPKTOzN6M_g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*bxggvI0MNlEOPKTOzN6M_g.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*bxggvI0MNlEOPKTOzN6M_g.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*bxggvI0MNlEOPKTOzN6M_g.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Chart 3. — Successes</p><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*CsxBLD0Gy9APICWSoXCRVg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*CsxBLD0Gy9APICWSoXCRVg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*CsxBLD0Gy9APICWSoXCRVg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*CsxBLD0Gy9APICWSoXCRVg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*CsxBLD0Gy9APICWSoXCRVg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*CsxBLD0Gy9APICWSoXCRVg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CsxBLD0Gy9APICWSoXCRVg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*CsxBLD0Gy9APICWSoXCRVg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*CsxBLD0Gy9APICWSoXCRVg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*CsxBLD0Gy9APICWSoXCRVg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*CsxBLD0Gy9APICWSoXCRVg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*CsxBLD0Gy9APICWSoXCRVg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*CsxBLD0Gy9APICWSoXCRVg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*CsxBLD0Gy9APICWSoXCRVg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*CsxBLD0Gy9APICWSoXCRVg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Chart 4. — Failures</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Conclusion</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Recurrent neural networks are a powerful tool for modeling sequential data. The model described in this article can be applied to many problems ranging from sales forecasting to energy consumption forecasting. It can condition its predictions on multivariate input series together with scalar inputs which makes it flexible enough to incorporate multiple data sources. Tensorflow implementation of the model can be found <a href="https://github.com/marekgalovic/articles/tree/master/darn" target="_self">here</a>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><em>If you liked this article please recommend it to others. Also, if you have any suggestions feel free to leave a comment below.</em></p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>