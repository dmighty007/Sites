<!DOCTYPE html>
                <html>
                <head>
                    <title>Machine Learning is Fun Part 5: Language Translation with Deep Learning and the Magic of Sequences</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@ageitgey?source=post_page-----2ace0acca0aa--------------------------------">Author : Adam Geitgey</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Machine Learning is Fun Part 5: Language Translation with Deep Learning and the Magic of Sequences</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Update:</strong><em> This article is part of a series. Check out the full series: </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471" target="_self">Part 1</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3" target="_self">Part 2</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721" target="_self">Part 3</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78" target="_self">Part 4</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa" target="_self">Part 5</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a" target="_self">Part 6</a><em>, </em><a href="https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7" target="_self">Part 7</a><em> and </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-8-how-to-intentionally-trick-neural-networks-b55da32b7196" target="_self">Part 8</a><em>! You can also read this article in </em><a href="https://zhuanlan.zhihu.com/p/24590838" target="_self">普通话</a><em>,</em><a href="http://algotravelling.com/ru/%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D1%8D%D1%82%D0%BE-%D0%B2%D0%B5%D1%81%D0%B5%D0%BB%D0%BE-5/" target="_self"> Русский</a><em>, </em><a href="https://medium.com/@jongdae.lim/기계-학습-machine-learning-은-즐겁다-part-5-83b7a44b797a" target="_self">한국어</a><em>, </em><a href="https://viblo.asia/p/machine-learning-that-thu-vi-5-dich-ngon-ngu-va-mo-ta-anh-Eb85oJnml2G" target="_self">Tiếng Việt</a><em>, </em><a href="https://shahaab-co.ir/mag/edu/ml/machine-learning-is-fun-part-5" target="_self">فارسی</a><em> or </em><a href="https://medium.com/botsupply/il-machine-learning-è-divertente-parte-5-5e9083caf8f3" target="_self">Italiano</a><em>.</em></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Giant update:</strong><em> </em><a href="https://www.machinelearningisfun.com/get-the-book/" target="_self">I’ve written a new book based on these articles</a><em>! It not only expands and updates all my articles, but it has tons of brand new content and lots of hands-on coding projects. </em><a href="https://www.machinelearningisfun.com/get-the-book/" target="_self">Check it out now</a><em>!</em></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We all know and love <a href="https://translate.google.com/" target="_self">Google Translate</a>, the website that can instantly translate between 100 different human languages as if by magic. It is even available on our phones and smartwatches:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:47%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 360px" srcset="https://miro.medium.com/v2/resize:fit:640/1*q_xg5WYxXL2HCHY5k8xVGg.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*q_xg5WYxXL2HCHY5k8xVGg.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*q_xg5WYxXL2HCHY5k8xVGg.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*q_xg5WYxXL2HCHY5k8xVGg.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*q_xg5WYxXL2HCHY5k8xVGg.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*q_xg5WYxXL2HCHY5k8xVGg.gif 1100w, https://miro.medium.com/v2/resize:fit:720/1*q_xg5WYxXL2HCHY5k8xVGg.gif 720w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 360px" srcset="https://miro.medium.com/v2/resize:fit:640/1*q_xg5WYxXL2HCHY5k8xVGg.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*q_xg5WYxXL2HCHY5k8xVGg.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*q_xg5WYxXL2HCHY5k8xVGg.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*q_xg5WYxXL2HCHY5k8xVGg.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*q_xg5WYxXL2HCHY5k8xVGg.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*q_xg5WYxXL2HCHY5k8xVGg.gif 1100w, https://miro.medium.com/v2/resize:fit:720/1*q_xg5WYxXL2HCHY5k8xVGg.gif 720w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/360/1*q_xg5WYxXL2HCHY5k8xVGg.gif"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The technology behind Google Translate is called Machine Translation. It has changed the world by allowing people to communicate when it wouldn’t otherwise be possible.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But we all know that high school students have been using Google Translate to… umm… <em>assist</em> with their Spanish homework for 15 years. Isn’t this old news?</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*zaK7KBzFtPFodu4CyauDYw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*zaK7KBzFtPFodu4CyauDYw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*zaK7KBzFtPFodu4CyauDYw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*zaK7KBzFtPFodu4CyauDYw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*zaK7KBzFtPFodu4CyauDYw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*zaK7KBzFtPFodu4CyauDYw.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*zaK7KBzFtPFodu4CyauDYw.gif 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*zaK7KBzFtPFodu4CyauDYw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*zaK7KBzFtPFodu4CyauDYw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*zaK7KBzFtPFodu4CyauDYw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*zaK7KBzFtPFodu4CyauDYw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*zaK7KBzFtPFodu4CyauDYw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*zaK7KBzFtPFodu4CyauDYw.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*zaK7KBzFtPFodu4CyauDYw.gif 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*zaK7KBzFtPFodu4CyauDYw.gif"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">It turns out that over the past two years, deep learning has totally rewritten our approach to machine translation. Deep learning researchers who know almost nothing about language translation are throwing together relatively simple machine learning solutions that are beating the best expert-built language translation systems in the world.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The technology behind this breakthrough is called <strong>sequence-to-sequence learning</strong>. It’s very powerful technique that be used to solve many kinds problems. After we see how it is used for translation, we’ll also learn how the exact same algorithm can be used to write AI chat bots and describe pictures.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s go!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Making Computers Translate</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So how do we program a computer to translate human language?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The simplest approach is to replace every word in a sentence with the translated word in the target language. Here’s a simple example of translating from Spanish to English word-by-word:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*aQn40w6gpzK53YZLSIfNoQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*aQn40w6gpzK53YZLSIfNoQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*aQn40w6gpzK53YZLSIfNoQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*aQn40w6gpzK53YZLSIfNoQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*aQn40w6gpzK53YZLSIfNoQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*aQn40w6gpzK53YZLSIfNoQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aQn40w6gpzK53YZLSIfNoQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*aQn40w6gpzK53YZLSIfNoQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*aQn40w6gpzK53YZLSIfNoQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*aQn40w6gpzK53YZLSIfNoQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*aQn40w6gpzK53YZLSIfNoQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*aQn40w6gpzK53YZLSIfNoQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*aQn40w6gpzK53YZLSIfNoQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*aQn40w6gpzK53YZLSIfNoQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*aQn40w6gpzK53YZLSIfNoQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">We just replace each Spanish word with the matching English word.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is easy to implement because all you need is a dictionary to look up each word’s translation. But the results are bad because it ignores grammar and context.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So the next thing you might do is start adding language-specific rules to improve the results. For example, you might translate common two-word phrases as a single group. And you might swap the order nouns and adjectives since they usually appear in reverse order in Spanish from how they appear in English:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*GkdstlNoHkAO--aLw0_ZAA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*GkdstlNoHkAO--aLw0_ZAA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*GkdstlNoHkAO--aLw0_ZAA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*GkdstlNoHkAO--aLw0_ZAA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*GkdstlNoHkAO--aLw0_ZAA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*GkdstlNoHkAO--aLw0_ZAA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GkdstlNoHkAO--aLw0_ZAA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*GkdstlNoHkAO--aLw0_ZAA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*GkdstlNoHkAO--aLw0_ZAA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*GkdstlNoHkAO--aLw0_ZAA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*GkdstlNoHkAO--aLw0_ZAA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*GkdstlNoHkAO--aLw0_ZAA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*GkdstlNoHkAO--aLw0_ZAA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*GkdstlNoHkAO--aLw0_ZAA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*GkdstlNoHkAO--aLw0_ZAA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">That worked! If we just keep adding more rules until we can handle every part of grammar, our program should be able to translate any sentence, right?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is how the earliest machine translation systems worked. Linguists came up with complicated rules and programmed them in one-by-one. Some of the smartest linguists in the world labored for years during the Cold War to <a href="https://en.wikipedia.org/wiki/Georgetown%E2%80%93IBM_experiment" target="_self">create translation systems as a way to interpret Russian communications more easily.</a></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Unfortunately this only worked for simple, plainly-structured documents like weather reports. It didn’t work reliably for real-world documents.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The problem is that human language doesn’t follow a fixed set of rules. Human languages are full of special cases, regional variations, and just flat out rule-breaking. The way we speak English more influenced by <a href="https://en.wikipedia.org/wiki/History_of_English#Middle_English" target="_self">who invaded who hundreds of years ago</a> than it is by someone sitting down and defining grammar rules.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Making Computers Translate Better Using Statistics</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">After the failure of rule-based systems, new translation approaches were developed using models based on probability and statistics instead of grammar rules.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Building a statistics-based translation system requires lots of training data where the exact same text is translated into at least two languages. This double-translated text is called <em>parallel corpora</em>. In the same way that the <a href="https://en.wikipedia.org/wiki/Rosetta_Stone" target="_self">Rosetta Stone</a> was used by scientists in the 1800s to figure out Egyptian hieroglyphs from Greek, computers can use parallel corpora to guess how to convert text from one language to another.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Luckily, there’s lots of double-translated text already sitting around in strange places. For example, the European Parliament translates their proceedings into 21 languages. So researchers often use <a href="http://www.statmt.org/europarl/" target="_self">that data</a> to help build translation systems.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*GTArMUvb-aZARXxIiXuBXw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*GTArMUvb-aZARXxIiXuBXw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*GTArMUvb-aZARXxIiXuBXw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*GTArMUvb-aZARXxIiXuBXw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*GTArMUvb-aZARXxIiXuBXw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*GTArMUvb-aZARXxIiXuBXw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GTArMUvb-aZARXxIiXuBXw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*GTArMUvb-aZARXxIiXuBXw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*GTArMUvb-aZARXxIiXuBXw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*GTArMUvb-aZARXxIiXuBXw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*GTArMUvb-aZARXxIiXuBXw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*GTArMUvb-aZARXxIiXuBXw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*GTArMUvb-aZARXxIiXuBXw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*GTArMUvb-aZARXxIiXuBXw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*GTArMUvb-aZARXxIiXuBXw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Training data is usually exciting! But this is just millions and millions of lines of dry government documents…</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Thinking in Probabilities</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The fundamental difference with statistical translation systems is that they don’t try to generate one exact translation. Instead, they generate thousands of possible translations and then they rank those translations by likely each is to be correct. They estimate how “correct” something is by how similar it is to the training data. Here’s how it works:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Step 1: Break original sentence into chunks</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">First, we break up our sentence into simple chunks that can each be easily translated:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*zYf5RGSI4nlpm_yUUqbgjg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*zYf5RGSI4nlpm_yUUqbgjg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*zYf5RGSI4nlpm_yUUqbgjg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*zYf5RGSI4nlpm_yUUqbgjg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*zYf5RGSI4nlpm_yUUqbgjg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*zYf5RGSI4nlpm_yUUqbgjg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zYf5RGSI4nlpm_yUUqbgjg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*zYf5RGSI4nlpm_yUUqbgjg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*zYf5RGSI4nlpm_yUUqbgjg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*zYf5RGSI4nlpm_yUUqbgjg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*zYf5RGSI4nlpm_yUUqbgjg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*zYf5RGSI4nlpm_yUUqbgjg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*zYf5RGSI4nlpm_yUUqbgjg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*zYf5RGSI4nlpm_yUUqbgjg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*zYf5RGSI4nlpm_yUUqbgjg.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Step 2: Find all possible translations for each chunk</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Next, we will translate each of these chunks by finding all the ways humans have translated those same chunks of words in our training data.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">It’s important to note that we are not just looking up these chunks in a simple translation dictionary. Instead, we are seeing how actual people translated these same chunks of words in real-world sentences. This helps us capture all of the different ways they can be used in different contexts:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*LNfHvNRdSTD4xCRvgI9t7A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*LNfHvNRdSTD4xCRvgI9t7A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*LNfHvNRdSTD4xCRvgI9t7A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*LNfHvNRdSTD4xCRvgI9t7A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*LNfHvNRdSTD4xCRvgI9t7A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*LNfHvNRdSTD4xCRvgI9t7A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LNfHvNRdSTD4xCRvgI9t7A.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*LNfHvNRdSTD4xCRvgI9t7A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*LNfHvNRdSTD4xCRvgI9t7A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*LNfHvNRdSTD4xCRvgI9t7A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*LNfHvNRdSTD4xCRvgI9t7A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*LNfHvNRdSTD4xCRvgI9t7A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*LNfHvNRdSTD4xCRvgI9t7A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*LNfHvNRdSTD4xCRvgI9t7A.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*LNfHvNRdSTD4xCRvgI9t7A.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Even the most common phrases have lots of possible translations.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Some of these possible translations are used more frequently than others. Based on how frequently each translation appears in our training data, we can give it a score.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For example, it’s much more common for someone to say “Quiero” to mean “I want” than to mean “I try.” So we can use how frequently “Quiero” was translated to “I want” in our training data to give that translation more weight than a less frequent translation.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Step 3: Generate all possible sentences and find the most likely one</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Next, we will use every possible combination of these chunks to generate a bunch of possible sentences.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Just from the chunk translations we listed in Step 2, we can already generate nearly 2,500 different variations of our sentence by combining the chunks in different ways. Here are some examples:</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">I love | to leave | at | the seaside | more tidy.<br></br>I mean | to be on | to | the open space | most lovely.<br></br>I like | to be |on | per the seaside | more lovely.<br></br>I mean | to go | to | the open space | most tidy.</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But in a real-world system, there will be even more possible chunk combinations because we’ll also try different orderings of words and different ways of chunking the sentence:</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">I try | to run | at | the prettiest | open space.<br></br>I want | to run | per | the more tidy | open space.<br></br>I mean | to forget | at | the tidiest | beach.<br></br>I try | to go | per | the more tidy | seaside.</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now need to scan through all of these generated sentences to find the one that is that sounds the “most human.”</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To do this, we compare each generated sentence to millions of real sentences from books and news stories written in English. The more English text we can get our hands on, the better.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Take this possible translation:</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">I try | to leave | per | the most lovely | open space.</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">It’s likely that no one has ever written a sentence like this in English, so it would not be very similar to any sentences in our data set. We’ll give this possible translation a low probability score.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But look at this possible translation:</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">I want | to go | to | the prettiest | beach.</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This sentence will be similar to something in our training set, so it will get a high probability score.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">After trying all possible sentences, we’ll pick the sentence that has the most likely chunk translations while also being the most similar overall to real English sentences.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Our final translation would be “I want to go to the prettiest beach.” Not bad!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Statistical Machine Translation was a Huge Milestone</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Statistical machine translation systems perform much better than rule-based systems if you give them enough training data. <a href="https://en.wikipedia.org/wiki/Franz_Josef_Och" target="_self">Franz Josef Och</a> improved on these ideas and used them to build Google Translate in the early 2000s. Machine Translation was finally available to the world.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the early days, it was surprising to everyone that the “dumb” approach to translating based on probability worked better than rule-based systems designed by linguists. This led to a (somewhat mean) saying among researchers in the 80s:</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">“Every time I fire a linguist, my accuracy goes up.”— <a href="https://en.wikipedia.org/wiki/Frederick_Jelinek" target="_self">Frederick Jelinek</a></p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">The Limitations of Statistical Machine Translation</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Statistical machine translation systems work well, but they are complicated to build and maintain. Every new pair of languages you want to translate requires experts to tweak and tune a new multi-step translation pipeline.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Because it is so much work to build these different pipelines, trade-offs have to be made. If you are asking Google to translate Georgian to Telegu, it has to internally translate it into English as an intermediate step because there’s not enough Georgain-to-Telegu translations happening to justify investing heavily in that language pair. And it might do that translation using a less advanced translation pipeline than if you had asked it for the more common choice of French-to-English.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Wouldn’t it be cool if we could have the computer do all that annoying development work for us?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Making Computers Translate Better — Without all those Expensive People</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The holy grail of machine translation is a black box system that learns how to translate by itself— just by looking at training data. With Statistical Machine Translation, humans are still needed to build and tweak the multi-step statistical models.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In 2014, <a href="http://arxiv.org/abs/1406.1078" target="_self">KyungHyun Cho’s team made a breakthrough</a>. They found a way to apply deep learning to build this black box system. Their deep learning model takes in a <em>parallel corpora</em> and and uses it to learn how to translate between those two languages without any human intervention.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Two big ideas make this possible — <em>recurrent neural networks</em> and <em>encodings</em>. By combining these two ideas in a clever way, we can build a self-learning translation system.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Recurrent Neural Networks</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We’ve already <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3" target="_self">talked about recurrent neural networks in Part 2</a>, but let’s quickly review.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A regular (non-recurrent) neural network is a generic machine learning algorithm that takes in a list of numbers and calculates a result (based on previous training). Neural networks can be used as a black box to solve lots of problems. For example, we can use a neural network to calculate the approximate value of a house based on attributes of that house:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*xvHk7SBUPBpvgnYIeljAzQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*xvHk7SBUPBpvgnYIeljAzQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*xvHk7SBUPBpvgnYIeljAzQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*xvHk7SBUPBpvgnYIeljAzQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*xvHk7SBUPBpvgnYIeljAzQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*xvHk7SBUPBpvgnYIeljAzQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xvHk7SBUPBpvgnYIeljAzQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*xvHk7SBUPBpvgnYIeljAzQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*xvHk7SBUPBpvgnYIeljAzQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*xvHk7SBUPBpvgnYIeljAzQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*xvHk7SBUPBpvgnYIeljAzQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*xvHk7SBUPBpvgnYIeljAzQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*xvHk7SBUPBpvgnYIeljAzQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*xvHk7SBUPBpvgnYIeljAzQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*xvHk7SBUPBpvgnYIeljAzQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But like most machine learning algorithms, neural networks are <em>stateless</em>. You pass in a list of numbers and the neural network calculates a result. If you pass in those same numbers again, it will always calculate the same result. It has no memory of past calculations. In other words, 2 + 2 always equals 4.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A <em>recurrent</em> <em>neural network</em> (or <em>RNN</em> for short) is a slightly tweaked version of a neural network where the previous state of the neural network is one of the inputs to the next calculation. This means that previous calculations change the results of future calculations!</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*9AfNUvfHmftLmdWydt_79w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*9AfNUvfHmftLmdWydt_79w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*9AfNUvfHmftLmdWydt_79w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*9AfNUvfHmftLmdWydt_79w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*9AfNUvfHmftLmdWydt_79w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*9AfNUvfHmftLmdWydt_79w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9AfNUvfHmftLmdWydt_79w.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*9AfNUvfHmftLmdWydt_79w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*9AfNUvfHmftLmdWydt_79w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*9AfNUvfHmftLmdWydt_79w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*9AfNUvfHmftLmdWydt_79w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*9AfNUvfHmftLmdWydt_79w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*9AfNUvfHmftLmdWydt_79w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*9AfNUvfHmftLmdWydt_79w.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*9AfNUvfHmftLmdWydt_79w.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Humans hate him: 1 weird trick that makes machines smarter!</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Why in the world would we want to do this? Shouldn’t 2 + 2 always equal 4 no matter what we last calculated?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This trick allows neural networks to learn patterns in a sequence of data. For example, you can use it to predict the next most likely word in a sentence based on the first few words:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*YkxweTzgt4axMnaTH0nHHg.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*YkxweTzgt4axMnaTH0nHHg.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*YkxweTzgt4axMnaTH0nHHg.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*YkxweTzgt4axMnaTH0nHHg.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*YkxweTzgt4axMnaTH0nHHg.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*YkxweTzgt4axMnaTH0nHHg.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*YkxweTzgt4axMnaTH0nHHg.gif 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*YkxweTzgt4axMnaTH0nHHg.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*YkxweTzgt4axMnaTH0nHHg.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*YkxweTzgt4axMnaTH0nHHg.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*YkxweTzgt4axMnaTH0nHHg.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*YkxweTzgt4axMnaTH0nHHg.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*YkxweTzgt4axMnaTH0nHHg.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*YkxweTzgt4axMnaTH0nHHg.gif 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*YkxweTzgt4axMnaTH0nHHg.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">This is one way you could implement “autocorrect” for a smart phone’s keyboard app</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><mark>RNNs are useful any time you want to learn patterns in data. Because human language is just one big, complicated pattern, RNNs are increasingly used in many areas of natural language processing.</mark></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you want to learn more about RNNs, <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3" target="_self">you can read Part 2 </a>where we used one to generate a fake Ernest Hemingway book and then used another one to generate fake Super Mario Brothers levels.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Encodings</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The other idea we need to review is <em>Encodings</em>. We <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78" target="_self">talked about encodings in Part 4</a> as part of face recognition. To explain encodings, let’s take a slight detour into how we can tell two different people apart with a computer.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">When you are trying to tell two faces apart with a computer, you collect different measurements from each face and use those measurements to compare faces. For example, we might measure the size of each ear or the spacing between the eyes and compare those measurements from two pictures to see if they are the same person.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You’re probably already familiar with this idea from watching any primetime detective show like CSI:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*_GNyjR3JlPoS9grtIVmKFQ.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*_GNyjR3JlPoS9grtIVmKFQ.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*_GNyjR3JlPoS9grtIVmKFQ.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*_GNyjR3JlPoS9grtIVmKFQ.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*_GNyjR3JlPoS9grtIVmKFQ.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*_GNyjR3JlPoS9grtIVmKFQ.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*_GNyjR3JlPoS9grtIVmKFQ.gif 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*_GNyjR3JlPoS9grtIVmKFQ.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*_GNyjR3JlPoS9grtIVmKFQ.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*_GNyjR3JlPoS9grtIVmKFQ.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*_GNyjR3JlPoS9grtIVmKFQ.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*_GNyjR3JlPoS9grtIVmKFQ.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*_GNyjR3JlPoS9grtIVmKFQ.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*_GNyjR3JlPoS9grtIVmKFQ.gif 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*_GNyjR3JlPoS9grtIVmKFQ.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">I love this dumb gif from CSI so much that I’ll use it again — because it is somehow manages to demonstrate this idea clearly while also being total nonsense.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The idea of turning a face into a list of measurements is an example of an <em>encoding</em>. We are taking raw data (a picture of a face) and turning it into a list of measurements that represent it (the encoding).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But like we saw in <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78" target="_self">Part 4</a>, we don’t have to come up with a specific list of facial features to measure ourselves. Instead, we can use a neural network to generate measurements from a face. The computer can do a better job than us in figuring out which measurements are best able to differentiate two similar people:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*6kMMqLt4UBCrN7HtqNHMKw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*6kMMqLt4UBCrN7HtqNHMKw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*6kMMqLt4UBCrN7HtqNHMKw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*6kMMqLt4UBCrN7HtqNHMKw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*6kMMqLt4UBCrN7HtqNHMKw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*6kMMqLt4UBCrN7HtqNHMKw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6kMMqLt4UBCrN7HtqNHMKw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*6kMMqLt4UBCrN7HtqNHMKw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*6kMMqLt4UBCrN7HtqNHMKw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*6kMMqLt4UBCrN7HtqNHMKw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*6kMMqLt4UBCrN7HtqNHMKw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*6kMMqLt4UBCrN7HtqNHMKw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*6kMMqLt4UBCrN7HtqNHMKw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*6kMMqLt4UBCrN7HtqNHMKw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*6kMMqLt4UBCrN7HtqNHMKw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">These facial feature measurements are generated by a neural net that was trained to make sure different people’s faces resulted in different numbers.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is our <em>encoding</em>. It lets us represent something very complicated (a picture of a face) with something simple (128 numbers). Now comparing two different faces is much easier because we only have to compare these 128 numbers for each face instead of comparing full images.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Guess what? We can do the same thing with sentences! We can come up with an encoding that represents every possible different sentence as a series of unique numbers:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*oA4MrbJwmGmcSEVWupG7jQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*oA4MrbJwmGmcSEVWupG7jQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*oA4MrbJwmGmcSEVWupG7jQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*oA4MrbJwmGmcSEVWupG7jQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*oA4MrbJwmGmcSEVWupG7jQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*oA4MrbJwmGmcSEVWupG7jQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oA4MrbJwmGmcSEVWupG7jQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*oA4MrbJwmGmcSEVWupG7jQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*oA4MrbJwmGmcSEVWupG7jQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*oA4MrbJwmGmcSEVWupG7jQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*oA4MrbJwmGmcSEVWupG7jQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*oA4MrbJwmGmcSEVWupG7jQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*oA4MrbJwmGmcSEVWupG7jQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*oA4MrbJwmGmcSEVWupG7jQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*oA4MrbJwmGmcSEVWupG7jQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">This list of numbers represents the English sentence “Machine Learning is Fun!”. A different sentence would be represented by a different set of numbers.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To generate this encoding, we’ll feed the sentence into the RNN, one word at time. The final result after the last word is processed will be the values that represent the entire sentence:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*hbpW6FRw7mrc607fwM9rKw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*hbpW6FRw7mrc607fwM9rKw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*hbpW6FRw7mrc607fwM9rKw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*hbpW6FRw7mrc607fwM9rKw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*hbpW6FRw7mrc607fwM9rKw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*hbpW6FRw7mrc607fwM9rKw.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*hbpW6FRw7mrc607fwM9rKw.gif 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*hbpW6FRw7mrc607fwM9rKw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*hbpW6FRw7mrc607fwM9rKw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*hbpW6FRw7mrc607fwM9rKw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*hbpW6FRw7mrc607fwM9rKw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*hbpW6FRw7mrc607fwM9rKw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*hbpW6FRw7mrc607fwM9rKw.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*hbpW6FRw7mrc607fwM9rKw.gif 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*hbpW6FRw7mrc607fwM9rKw.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Because the RNN has a “memory” of each word that passed through it, the final encoding it calculates represents all the words in the sentence.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Great, so now we have a way to represent an entire sentence as a set of unique numbers! We don’t know what each number in the encoding means, but it doesn’t really matter. As long as each sentence is uniquely identified by it’s own set of numbers, we don’t need to know exactly how those numbers were generated.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Let’s Translate!</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Ok, so we know how to use an RNN to encode a sentence into a set of unique numbers. How does that help us? Here’s where things get really cool!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">What if we took two RNNs and hooked them up end-to-end? The first RNN could generate the encoding that represents a sentence. Then the second RNN could take that encoding and just do the same logic in reverse to decode the original sentence again:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*B24hDD3nGjfI4y3eNLNOgw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*B24hDD3nGjfI4y3eNLNOgw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*B24hDD3nGjfI4y3eNLNOgw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*B24hDD3nGjfI4y3eNLNOgw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*B24hDD3nGjfI4y3eNLNOgw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*B24hDD3nGjfI4y3eNLNOgw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B24hDD3nGjfI4y3eNLNOgw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*B24hDD3nGjfI4y3eNLNOgw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*B24hDD3nGjfI4y3eNLNOgw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*B24hDD3nGjfI4y3eNLNOgw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*B24hDD3nGjfI4y3eNLNOgw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*B24hDD3nGjfI4y3eNLNOgw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*B24hDD3nGjfI4y3eNLNOgw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*B24hDD3nGjfI4y3eNLNOgw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*B24hDD3nGjfI4y3eNLNOgw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Of course being able to encode and then decode the original sentence again isn’t very useful. But what if (<em>and here’s the big idea!</em>) we could train the second RNN to decode the sentence into Spanish instead of English? We could use our <em>parallel corpora</em> training data to train it to do that:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*fGzLsEwnEwFo2Wo9kzIvBw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*fGzLsEwnEwFo2Wo9kzIvBw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*fGzLsEwnEwFo2Wo9kzIvBw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*fGzLsEwnEwFo2Wo9kzIvBw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*fGzLsEwnEwFo2Wo9kzIvBw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fGzLsEwnEwFo2Wo9kzIvBw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fGzLsEwnEwFo2Wo9kzIvBw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*fGzLsEwnEwFo2Wo9kzIvBw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*fGzLsEwnEwFo2Wo9kzIvBw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*fGzLsEwnEwFo2Wo9kzIvBw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*fGzLsEwnEwFo2Wo9kzIvBw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*fGzLsEwnEwFo2Wo9kzIvBw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*fGzLsEwnEwFo2Wo9kzIvBw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*fGzLsEwnEwFo2Wo9kzIvBw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*fGzLsEwnEwFo2Wo9kzIvBw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">And just like that, we have a generic way of converting a sequence of English words into an equivalent sequence of Spanish words!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is a powerful idea:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">This approach is mostly limited by the amount of training data you have and the amount of computer power you can throw at it. Machine learning researchers only invented this <strong>two years ago</strong>, but it’s already performing as well as statistical machine translation systems that took<strong> 20 years</strong> to develop.</li><li class="ff3" style="font-size:22px;">This doesn’t depend on knowing any rules about human language. The algorithm figures out those rules itself. This means you don’t need experts to tune every step of your translation pipeline. The computer does that for you.</li><li class="ff3" style="font-size:22px;"><strong>This approach works for almost any kind of sequence-to-sequence problem! </strong>And it turns out that lots of interesting problems are sequence-to-sequence problems. Read on for other cool things you can do!</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Note that we glossed over some things that are required to make this work with real-world data. For example, there’s additional work you have to do to deal with different lengths of input and output sentences (see <a href="https://www.tensorflow.org/versions/r0.10/tutorials/seq2seq/index.html#bucketing-and-padding" target="_self">bucketing and padding</a>). There’s also issues with <a href="https://cs224d.stanford.edu/papers/addressing.pdf" target="_self">translating rare words correctly</a>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Building your own Sequence-to-Sequence Translation System</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you want to build your own language translation system, <a href="https://www.tensorflow.org/versions/r0.10/tutorials/seq2seq/index.html" target="_self">there’s a working demo included with TensorFlow that will translate between English and French</a>. However, this is not for the faint of heart or for those with limited budgets. This technology is still new and very resource intensive. Even if you have a fast computer with a high-end video card, it might take <a href="https://github.com/tensorflow/tensorflow/issues/600#issuecomment-226333266" target="_self">about a month</a> of continuous processing time to train your own language translation system.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Also, Sequence-to-sequence language translation techniques are improving so rapidly that it’s hard to keep up. Many recent improvements (like adding an <a href="http://stanford.edu/~lmthang/data/papers/emnlp15_attn.pdf" target="_self">attention mechanism</a> or <a href="http://arxiv.org/abs/1607.00578" target="_self">tracking context</a>) are significantly improving results but these developments are so new that there aren’t even wikipedia pages for them yet. If you want to do anything serious with sequence-to-sequence learning, you’ll need to keep with new developments as they occur.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">The Ridiculous Power of Sequence-to-Sequence Models</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So what else can we do with sequence-to-sequence models?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">About a year ago, <a href="https://arxiv.org/pdf/1506.05869.pdf" target="_self">researchers at Google showed</a> that you can use sequence-to-sequence models to build AI bots. The idea is so simple that it’s amazing it works at all.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">First, they captured chat logs between Google employees and Google’s Tech Support team. Then they trained a sequence-to-sequence model where the employee’s question was the input sentence and the Tech Support team’s response was the “translation” of that sentence.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*y7Ub13JXXmMh-EuiA7q7Wg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*y7Ub13JXXmMh-EuiA7q7Wg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*y7Ub13JXXmMh-EuiA7q7Wg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*y7Ub13JXXmMh-EuiA7q7Wg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*y7Ub13JXXmMh-EuiA7q7Wg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*y7Ub13JXXmMh-EuiA7q7Wg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y7Ub13JXXmMh-EuiA7q7Wg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*y7Ub13JXXmMh-EuiA7q7Wg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*y7Ub13JXXmMh-EuiA7q7Wg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*y7Ub13JXXmMh-EuiA7q7Wg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*y7Ub13JXXmMh-EuiA7q7Wg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*y7Ub13JXXmMh-EuiA7q7Wg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*y7Ub13JXXmMh-EuiA7q7Wg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*y7Ub13JXXmMh-EuiA7q7Wg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*y7Ub13JXXmMh-EuiA7q7Wg.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">When a user interacted with the bot, they would “translate” each of the user’s messages with this system to get the bot’s response.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The end result was a semi-intelligent bot that could (sometimes) answer real tech support questions. Here’s part of a sample conversation between a user and the bot <a href="https://arxiv.org/pdf/1506.05869.pdf" target="_self">from their paper</a>:</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4"><strong>Human: </strong>connection refused or something like that<br></br><strong>Machine:</strong> may i know the version of network connect you connect?<br></br><strong>Human:</strong> i am not sure i know that<br></br><strong>Machine:</strong> is the network connect prompting for any user certificate?<br></br><strong>Human:</strong> yes<br></br><strong>Machine: </strong>are you at home or at work at the moment? office?<br></br><strong>Human:</strong> i am at home<br></br><strong>Machine:</strong> try this. goto &lt;URL redacted&gt; page and enter your name and password<br></br><strong>Human:</strong> done<br></br><strong>Machine:</strong> try logging in with &lt;NAME redacted&gt; and check if its working fine now<br></br><strong>Human:</strong> yes, now it works!<br></br><strong>Machine:</strong> great. anything else that i can help?</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">They also tried building a chat bot based on millions of movie subtitles. The idea was to use conversations between movie characters as a way to train a bot to talk like a human. The input sentence is a line of dialog said by one character and the “translation” is what the next character said in response:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*_mF74evW0SrnxE0omhmEVA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*_mF74evW0SrnxE0omhmEVA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*_mF74evW0SrnxE0omhmEVA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*_mF74evW0SrnxE0omhmEVA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*_mF74evW0SrnxE0omhmEVA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*_mF74evW0SrnxE0omhmEVA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_mF74evW0SrnxE0omhmEVA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*_mF74evW0SrnxE0omhmEVA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*_mF74evW0SrnxE0omhmEVA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*_mF74evW0SrnxE0omhmEVA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*_mF74evW0SrnxE0omhmEVA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*_mF74evW0SrnxE0omhmEVA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*_mF74evW0SrnxE0omhmEVA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*_mF74evW0SrnxE0omhmEVA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*_mF74evW0SrnxE0omhmEVA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This produced really interesting results. Not only did the bot converse like a human, but it displayed a small bit of intelligence:</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4"><strong>Human: </strong>my name is david. what is my name?<br></br><strong>Machine:</strong> david.<br></br><strong>Human:</strong> my name is john. what is my name?<br></br><strong>Machine:</strong> john.<br></br><strong>Human:</strong> are you a leader or a follower?<br></br><strong>Machine:</strong> i’m a leader.<br></br><strong>Human:</strong> are you a follower or a leader?<br></br><strong>Machine:</strong> i’m a leader.</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is only the beginning of the possibilities. We aren’t limited to converting one sentence into another sentence. It’s also possible to make an image-to-sequence model that can turn an image into text!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Vinyals_Show_and_Tell_2015_CVPR_paper.pdf" target="_self">A different team at Google</a> did this by replacing the first RNN with a Convolutional Neural Network (<a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721#.yzzx24elr" target="_self">like we learned about in Part 3)</a>. This allows the input to be a picture instead of a sentence. The rest works basically the same way:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*e-VLdp_dGnii7wBIVEM05A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*e-VLdp_dGnii7wBIVEM05A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*e-VLdp_dGnii7wBIVEM05A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*e-VLdp_dGnii7wBIVEM05A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*e-VLdp_dGnii7wBIVEM05A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*e-VLdp_dGnii7wBIVEM05A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e-VLdp_dGnii7wBIVEM05A.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*e-VLdp_dGnii7wBIVEM05A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*e-VLdp_dGnii7wBIVEM05A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*e-VLdp_dGnii7wBIVEM05A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*e-VLdp_dGnii7wBIVEM05A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*e-VLdp_dGnii7wBIVEM05A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*e-VLdp_dGnii7wBIVEM05A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*e-VLdp_dGnii7wBIVEM05A.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*e-VLdp_dGnii7wBIVEM05A.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">And just like that, we can turn pictures into words (as long as we have lots and lots of training data)!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="http://cs.stanford.edu/people/karpathy/" target="_self">Andrej Karpathy</a> <a href="http://cs.stanford.edu/people/karpathy/cvpr2015.pdf" target="_self">expanded on these ideas</a> to build a system capable of describing images in great detail by processing multiple regions of an image separately:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*1XaplPNlLfzzLxm1rxT19A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*1XaplPNlLfzzLxm1rxT19A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*1XaplPNlLfzzLxm1rxT19A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*1XaplPNlLfzzLxm1rxT19A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*1XaplPNlLfzzLxm1rxT19A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*1XaplPNlLfzzLxm1rxT19A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1XaplPNlLfzzLxm1rxT19A.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*1XaplPNlLfzzLxm1rxT19A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*1XaplPNlLfzzLxm1rxT19A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*1XaplPNlLfzzLxm1rxT19A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*1XaplPNlLfzzLxm1rxT19A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*1XaplPNlLfzzLxm1rxT19A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*1XaplPNlLfzzLxm1rxT19A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*1XaplPNlLfzzLxm1rxT19A.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*1XaplPNlLfzzLxm1rxT19A.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image from <a href="http://cs.stanford.edu/people/karpathy/cvpr2015.pdf" target="_self">this paper</a> by <a href="http://cs.stanford.edu/people/karpathy/" target="_self">Andrej Karpathy</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This makes it possible to build <a href="http://cs.stanford.edu/people/karpathy/deepimagesent/rankingdemo/" target="_self">image search engines</a> that are capable of finding images that match oddly specific search queries:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:59%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 444px" srcset="https://miro.medium.com/v2/resize:fit:640/1*SxrTNR7BUQrqQYOpke21kw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*SxrTNR7BUQrqQYOpke21kw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*SxrTNR7BUQrqQYOpke21kw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*SxrTNR7BUQrqQYOpke21kw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*SxrTNR7BUQrqQYOpke21kw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*SxrTNR7BUQrqQYOpke21kw.gif 1100w, https://miro.medium.com/v2/resize:fit:888/1*SxrTNR7BUQrqQYOpke21kw.gif 888w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 444px" srcset="https://miro.medium.com/v2/resize:fit:640/1*SxrTNR7BUQrqQYOpke21kw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*SxrTNR7BUQrqQYOpke21kw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*SxrTNR7BUQrqQYOpke21kw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*SxrTNR7BUQrqQYOpke21kw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*SxrTNR7BUQrqQYOpke21kw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*SxrTNR7BUQrqQYOpke21kw.gif 1100w, https://miro.medium.com/v2/resize:fit:888/1*SxrTNR7BUQrqQYOpke21kw.gif 888w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/444/1*SxrTNR7BUQrqQYOpke21kw.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Example from <a href="http://cs.stanford.edu/people/karpathy/deepimagesent/rankingdemo/" target="_self">http://cs.stanford.edu/people/karpathy/deepimagesent/rankingdemo/</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">There’s even <a href="http://arxiv.org/pdf/1506.03500.pdf" target="_self">researchers working on the reverse problem</a>, generating an entire picture based on just a text description!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Just from these examples, you can start to imagine the possibilities. So far, there have been sequence-to-sequence <a href="https://github.com/kjw0612/awesome-rnn#applications" target="_self">applications in everything from speech recognition to computer vision</a>. I bet there will be a lot more over the next year.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you want to learn more in depth about sequence-to-sequence models and translation, here’s some recommended resources:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><a href="https://www.youtube.com/watch?v=qGlmW2n4s1w" target="_self">Richard Socher’s CS224D Lecture— Fancy Recurrent Neural Networks for Machine Translation</a> (video)</li><li class="ff3" style="font-size:22px;"><a href="http://cs224d.stanford.edu/lectures/CS224d-Lecture15.pdf" target="_self">Thang Luong’s CS224D Lecture — Neural Machine Transation</a> (PDF)</li><li class="ff3" style="font-size:22px;"><a href="https://www.tensorflow.org/versions/r0.10/tutorials/seq2seq/index.html" target="_self">TensorFlow’s description of Seq2Seq modeling</a></li><li class="ff3" style="font-size:22px;"><a href="http://www.deeplearningbook.org/contents/rnn.html" target="_self">The Deep Learning Book’s chapter on Sequence to Sequence Learning</a> (PDF)</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you liked this article, please consider <a href="http://eepurl.com/b9fg2T" target="_self">signing up for my Machine Learning is Fun! email list</a>. I’ll only email you when I have something new and awesome to share. It’s the best way to find out when I write more articles like this.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You can also follow me on Twitter at <a href="https://twitter.com/ageitgey" target="_self">@ageitgey</a>, <a href="mailto:ageitgey@gmail.com" target="_self">email me directly</a> or <a href="https://www.linkedin.com/in/ageitgey" target="_self">find me on linkedin</a>. I’d love to hear from you if I can help you or your team with machine learning.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><em>Now continue on to </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a" target="_self">Machine Learning is Fun! Part 6</a><em>!</em></p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>