<!DOCTYPE html>
                <html>
                <head>
                    <title>A Technical Guide on RNN/LSTM/GRU for Stock Price Prediction</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/swlh/a-technical-guide-on-rnn-lstm-gru-for-stock-price-prediction-bce2f7f30346"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@dataman-ai?source=post_page-----bce2f7f30346--------------------------------">Author : Chris Kuo/Dr. Dataman</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>A Technical Guide on RNN/LSTM/GRU for Stock Price Prediction</h3></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*rccWEaiUt4p6uozWg0Kfbw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*rccWEaiUt4p6uozWg0Kfbw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*rccWEaiUt4p6uozWg0Kfbw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*rccWEaiUt4p6uozWg0Kfbw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*rccWEaiUt4p6uozWg0Kfbw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*rccWEaiUt4p6uozWg0Kfbw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rccWEaiUt4p6uozWg0Kfbw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*rccWEaiUt4p6uozWg0Kfbw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*rccWEaiUt4p6uozWg0Kfbw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*rccWEaiUt4p6uozWg0Kfbw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*rccWEaiUt4p6uozWg0Kfbw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*rccWEaiUt4p6uozWg0Kfbw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*rccWEaiUt4p6uozWg0Kfbw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*rccWEaiUt4p6uozWg0Kfbw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*rccWEaiUt4p6uozWg0Kfbw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Sequential data prevail in our lives. Voice data, song data, or language data are examples of sequential data, and univariate time series data are special cases. In sequential data, data arrive sequentially, and the new data should not be abrupt from the previous data. For example, a sentence can be:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">“I am going to feed the dog then do my homework,” or</li><li class="ff3" style="font-size:22px;">“After dinner, they went out for a walk.”</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The next word should follow certain grammar rules to its previous word. The serial connectivity is an important property of sequential data. When someone raises an unfinished sentence like “I am going to …”, the hearer expects to hear certain words that can complete the sentence and making grammar sense. For example, it would be obscure if I hear “I am going to I make a ball”, in which the underlined words should not be there. Similarly, a song is a sequential data type. It would be abhorrent if the next musical notes do not follow coherently with the previous notes.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In sequential data, we are interested in forecasting multiple periods in the future. For example, in the sentence “I am going to …”, we are interested in knowing the multiple words after the existing words “I am going to”. We are not just interested in a one-word or one-period forecast.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">While modeling sequential data, we need to capture the property on serial connectivity. Serial connectivity between data points implies the influence of a previous data point may appear in a much latter period. Neural Networks have made tremendous contributions in modeling sequential data. They can provide multi-period forecasting capability into the future. Many commercial language translation tools are powered by neural network models that can understand the meaning of a word in certain context and translate instantaneously from one language to another. Such neural networks are powerful in dealing with univariate time series. They can forecast not just one-period ahead but multiple periods in the future.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In explaining the basics of the neural networks in time series, I do not assume that readers should already possess strong knowledge in neural networks. This allows the book to go over the concepts gently. In this and next two chapters, I will explain the Recurrent Neural Networks (RNN), the Long Short-Term Memory network (LSTM), and the Gated Recurrent Units (GRU) models. These three variants of models have wide applications in any sequence-to-sequence data such as language translation modeling or speech-to-text modeling. The Transformer-based models such as [1] or [2] are outside the scope of this article.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">It is not as easy to learn RNN, LSTM, and GRU as we learn regression. In my class, I often feel there is a knowledge gap between regression and deep learning. The variation in terminology also creates a knowledge gap. It takes a lot of preparation to jump too deep learning, and those students jumping successfully may not regress to regression easily (you may like the pun). That’s the motive for me to write “<a href="https://medium.com/swlh/a-tutorial-to-build-from-regression-to-deep-learning-b7354240d2d5" target="_self">Explaining Deep Learning in a Regression-Friendly Way</a>” to bridge regression and the standard feedforward neural network. In learning RNN/LSTM, you may have seen RNN or LSTM abstract diagrams like Figure (A) but still, feel lost. Part of the obstacle is labeling. I wish these diagrams can label the time series data exactly where they are. In an ARIMA model, we see how Y<em>t, Yt-1, Yt-2, …, </em>produce <em>Yt+1</em> in a mathematical formula. But how are they represented in an RNN diagram?</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:52%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 398px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*nj6nc_HGyT2u9BA3N3zktg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*nj6nc_HGyT2u9BA3N3zktg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*nj6nc_HGyT2u9BA3N3zktg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*nj6nc_HGyT2u9BA3N3zktg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*nj6nc_HGyT2u9BA3N3zktg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*nj6nc_HGyT2u9BA3N3zktg.png 1100w, https://miro.medium.com/v2/resize:fit:796/format:webp/1*nj6nc_HGyT2u9BA3N3zktg.png 796w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 398px" srcset="https://miro.medium.com/v2/resize:fit:640/1*nj6nc_HGyT2u9BA3N3zktg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*nj6nc_HGyT2u9BA3N3zktg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*nj6nc_HGyT2u9BA3N3zktg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*nj6nc_HGyT2u9BA3N3zktg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*nj6nc_HGyT2u9BA3N3zktg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*nj6nc_HGyT2u9BA3N3zktg.png 1100w, https://miro.medium.com/v2/resize:fit:796/1*nj6nc_HGyT2u9BA3N3zktg.png 796w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/398/1*nj6nc_HGyT2u9BA3N3zktg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure (A) A baffled look for RNN and LSTM</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">I will cover RNN, LSTM, and GRU. After reading this sequence of articles, you will have an in-depth understanding of RNN/LSTM/GRU, and be able to use them to predict stock prices. Do you think it is worth reading? Then grab a cup of coffee and start!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let me start with some leading questions:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">How univariate time series can be re-organized to fit in a neural network framework.</li><li class="ff3" style="font-size:22px;">The differences between the standard feedforward neural network and an RNN.</li><li class="ff3" style="font-size:22px;">The graph representation of an RNN</li><li class="ff3" style="font-size:22px;">The data requirement for an RNN model</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We will uses stock market data to help readers understand the property of serial connectivity. First, the stock price of today should be highly influenced by those of recent days. Second, the price of same day last year may still influence today’s price. The time series seems to have a long memory throughout all its past. Stock price time series deserve continual research effort and innovation. For readers who have just started your research on stock price movement, you may be interested in my articles “<a href="https://medium.com/analytics-vidhya/algorithmic-trading-with-technical-indicators-in-r-6883b07cd067" target="_self">Algorithmic Trading with Technical Indicators in R</a>”, <a href="https://towardsdatascience.com/stock-market-anomalies-and-stock-market-anomaly-detection-are-two-different-things-624331c7b65a" target="_self">“Stock Market Anomalies” and “Stock Market Anomaly Detection” Are Two Different Things</a>, and “<a href="https://dataman-ai.medium.com/kalman-filter-explained-4d65b47916bf" target="_self">Kalman Filter Explained!</a>”. Also, you are likely to develop a web service for your stock price prediction service. You may be thinking of Flask or Django as your web-service frameworks. I highly recommend <strong>Streamlit</strong>. as I explain in “<a href="https://dataman-ai.medium.com/building-a-stock-market-app-with-python-streamlit-in-20-minutes-2765467870ee" target="_self">Building a Stock Market App with Python Streamlit in 20 Minutes</a>” and “<a href="https://dataman-ai.medium.com/lets-talk-about-the-taylor-rule-for-monetary-policy-3503ccd50172" target="_self">Let’s Talk About the Taylor Rule for Monetary Policy</a>”.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let me mention several data types and how deep learning deals with each data type. Data can be categorized broadly as (1) Multivariate data (In contrast with serial data), (2) Serial data (including text and voice stream data), and (3) Image data. <strong>Deep learning has three basic variations to address each data category: </strong>(1) the standard feedforward neural network, (2) RNN/LSTM, and (3) Convolutional NN (CNN). For readers who are looking for tutorials for each type, you are recommended to check “<a href="https://medium.com/swlh/a-tutorial-to-build-from-regression-to-deep-learning-b7354240d2d5" target="_self">Explaining Deep Learning in a Regression-Friendly Way</a>” for (1), the current article “A Technical Guide for RNN/LSTM/GRU on Stock Price Prediction” for (2), and “<a href="https://medium.com/analytics-vidhya/not-torturing-in-learning-pytorch-b2f7f169923a" target="_self">Deep Learning with PyTorch Is Not Torturing</a>”, “<a href="https://towardsdatascience.com/module-6-image-recognition-for-insurance-claim-handling-part-i-a338d16c9de0" target="_self">What Is Image Recognition?</a>“, “<a href="https://towardsdatascience.com/anomaly-detection-with-autoencoder-b4cdce4866a6" target="_self">Anomaly Detection with Autoencoders Made Easy</a>”, and “<a href="https://towardsdatascience.com/convolutional-autoencoders-for-image-noise-reduction-32fce9fc1763" target="_self">Convolutional Autoencoders for Image Noise Reduction</a>“ for (3). You can bookmark the summary article “<a href="https://medium.com/analytics-vidhya/dataman-learning-paths-build-your-skills-drive-your-career-e1aee030ff6e" target="_self">Dataman Learning Paths — Build Your Skills, Drive Your Career</a>”.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The entire notebook is available through <a href="https://github.com/dataman-git/codes_for_articles/blob/master/From%20regression%20to%20RNN.ipynb" target="_self">this Github link</a>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://dataman-ai.medium.com/membership"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">Join Medium with my referral link - Chris Kuo/Dr. Dataman</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">Read every story from Chris Kuo/Dr. Dataman. Your membership fee directly supports Chris Kuo/Dr. Dataman and other…</h3><p>dataman-ai.medium.com</p></a></div></div></div></div></section><br><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(A) A Short Recap of the ARIMA Model</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The recursive nature in ARIMA helps readers to understand the recursive nature of RNN. The <strong>ARIMA</strong> (<strong>A</strong>uto <strong>R</strong>egressive <strong>I</strong>ntegrated <strong>M</strong>oving <strong>A</strong>verage) models the recursive nature based on (a) a linear combination of its lags and (b) a linear combination of lagged forecast errors, to forecast the future. ARIMA model includes the <strong>AR</strong> term, the <strong>I</strong> term, and the <strong>MA</strong> term. An ARIMA(<em>p,d,q</em>) model is characterized by three terms:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><em>p</em> is the order of the AR term</li><li class="ff3" style="font-size:22px;"><em>d</em> is the number of differencing to make the time series stationary</li><li class="ff3" style="font-size:22px;"><em>q</em> is the order of the MA term</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Below are two examples:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:77%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 571px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ndNuxa3oihovvTfRAV0E0w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ndNuxa3oihovvTfRAV0E0w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ndNuxa3oihovvTfRAV0E0w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ndNuxa3oihovvTfRAV0E0w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ndNuxa3oihovvTfRAV0E0w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ndNuxa3oihovvTfRAV0E0w.png 1100w, https://miro.medium.com/v2/resize:fit:1142/format:webp/1*ndNuxa3oihovvTfRAV0E0w.png 1142w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 571px" srcset="https://miro.medium.com/v2/resize:fit:640/1*ndNuxa3oihovvTfRAV0E0w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ndNuxa3oihovvTfRAV0E0w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ndNuxa3oihovvTfRAV0E0w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ndNuxa3oihovvTfRAV0E0w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ndNuxa3oihovvTfRAV0E0w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ndNuxa3oihovvTfRAV0E0w.png 1100w, https://miro.medium.com/v2/resize:fit:1142/1*ndNuxa3oihovvTfRAV0E0w.png 1142w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/571/1*ndNuxa3oihovvTfRAV0E0w.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We can consider the AR term as a partial difference. The absolute value of the coefficient on the AR term tells you the percent of a difference you need to take. The above AR(1) tells us <em>Yt</em> is obtained from knowing the value of <em>Yt−1</em>. But <em>Yt−1 </em>is obtained from <em>Yt-2</em> and so on. Or in other words, data are not uncorrelated. <em>Yt</em> cannot be obtained just by <em>Yt-1</em> and not by <em>Yt-2</em>. The solution for <em>Yt</em> can be found through <em>recursive</em> substitution:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:52%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 397px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*hgaGptTiVW3DEVa3K0A9_Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*hgaGptTiVW3DEVa3K0A9_Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*hgaGptTiVW3DEVa3K0A9_Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*hgaGptTiVW3DEVa3K0A9_Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*hgaGptTiVW3DEVa3K0A9_Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*hgaGptTiVW3DEVa3K0A9_Q.png 1100w, https://miro.medium.com/v2/resize:fit:794/format:webp/1*hgaGptTiVW3DEVa3K0A9_Q.png 794w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 397px" srcset="https://miro.medium.com/v2/resize:fit:640/1*hgaGptTiVW3DEVa3K0A9_Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*hgaGptTiVW3DEVa3K0A9_Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*hgaGptTiVW3DEVa3K0A9_Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*hgaGptTiVW3DEVa3K0A9_Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*hgaGptTiVW3DEVa3K0A9_Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*hgaGptTiVW3DEVa3K0A9_Q.png 1100w, https://miro.medium.com/v2/resize:fit:794/1*hgaGptTiVW3DEVa3K0A9_Q.png 794w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/397/1*hgaGptTiVW3DEVa3K0A9_Q.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">There are many ARIMA tutorials available online such as <a href="https://people.duke.edu/~rnau/411arim.htm" target="_self">this one</a> or <a href="https://people.duke.edu/~rnau/411arim3.htm" target="_self">this</a>. I suggest that interested readers search for relevant tutorials. Below I simulate an ARIMA(2,0,0) for <em>Yt = 0.8 Yt-1–0.2 Yt-2</em>.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre>from statsmodels.graphics.tsaplots import plot_pacf, plot_acf
from statsmodels.tsa.arima_process import ArmaProcess
from statsmodels.tsa.stattools import pacf
from statsmodels.regression.linear_model import yule_walker
#from statsmodels.tsa.stattools import adfuller
import matplotlib.pyplot as plt
import numpy as np
%matplotlib inline

# Generate the data
import numpy as np
ar = np.array([1, -0.8, 0.2])
ma = np.array([1])
my_simulation = ArmaProcess(ar, ma).generate_sample(nsample=100)

plt.figure(figsize=[10, 5]); # Set dimensions for figure
plt.plot(my_simulation, linestyle='-', marker='o', color='b')
plt.title("Simulated Process")
plt.show()</pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*iY6hyIMeqBpA5oKzqrX5og.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*iY6hyIMeqBpA5oKzqrX5og.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*iY6hyIMeqBpA5oKzqrX5og.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*iY6hyIMeqBpA5oKzqrX5og.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*iY6hyIMeqBpA5oKzqrX5og.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*iY6hyIMeqBpA5oKzqrX5og.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iY6hyIMeqBpA5oKzqrX5og.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*iY6hyIMeqBpA5oKzqrX5og.png 640w, https://miro.medium.com/v2/resize:fit:720/1*iY6hyIMeqBpA5oKzqrX5og.png 720w, https://miro.medium.com/v2/resize:fit:750/1*iY6hyIMeqBpA5oKzqrX5og.png 750w, https://miro.medium.com/v2/resize:fit:786/1*iY6hyIMeqBpA5oKzqrX5og.png 786w, https://miro.medium.com/v2/resize:fit:828/1*iY6hyIMeqBpA5oKzqrX5og.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*iY6hyIMeqBpA5oKzqrX5og.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*iY6hyIMeqBpA5oKzqrX5og.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*iY6hyIMeqBpA5oKzqrX5og.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">ARIMA models use the<strong> autocorrelation function (ACF)</strong> and <strong>partial autocorrelation (PACF)</strong> plots to determine the numbers of AR and/or MA terms. Figure (A.1) shows the ACF gradually tapers to zero, while PACF has two significant spikes. With this suggestion, we can test an AR2 model specification. (For the rules of ACF and PACF, click <a href="https://people.duke.edu/~rnau/411arim3.htm" target="_self">here</a> for more detail.) Figure (A.2) presents the estimated model coefficients, which are close to those we have specified.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre>from matplotlib import pyplot
from pandas.plotting import autocorrelation_plot
plot_acf(my_simulation)  # ACF
plot_pacf(my_simulation) # PACF</pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*unMDlWoBsBy1CQJrQzUbig.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*unMDlWoBsBy1CQJrQzUbig.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*unMDlWoBsBy1CQJrQzUbig.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*unMDlWoBsBy1CQJrQzUbig.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*unMDlWoBsBy1CQJrQzUbig.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*unMDlWoBsBy1CQJrQzUbig.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*unMDlWoBsBy1CQJrQzUbig.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*unMDlWoBsBy1CQJrQzUbig.png 640w, https://miro.medium.com/v2/resize:fit:720/1*unMDlWoBsBy1CQJrQzUbig.png 720w, https://miro.medium.com/v2/resize:fit:750/1*unMDlWoBsBy1CQJrQzUbig.png 750w, https://miro.medium.com/v2/resize:fit:786/1*unMDlWoBsBy1CQJrQzUbig.png 786w, https://miro.medium.com/v2/resize:fit:828/1*unMDlWoBsBy1CQJrQzUbig.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*unMDlWoBsBy1CQJrQzUbig.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*unMDlWoBsBy1CQJrQzUbig.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*unMDlWoBsBy1CQJrQzUbig.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure (A.1) ACF and PACF</p><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre>import warnings
import statsmodels.api as sm
from statsmodels.tsa.arima_model import ARMA

mod = sm.tsa.arima.ARIMA(my_simulation, order=(2, 0, 0))
mod_fit = mod.fit()
print(mod_fit.summary())</pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*rcnzo3BAjPnE6ER6bthsOA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*rcnzo3BAjPnE6ER6bthsOA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*rcnzo3BAjPnE6ER6bthsOA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*rcnzo3BAjPnE6ER6bthsOA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*rcnzo3BAjPnE6ER6bthsOA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*rcnzo3BAjPnE6ER6bthsOA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rcnzo3BAjPnE6ER6bthsOA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*rcnzo3BAjPnE6ER6bthsOA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*rcnzo3BAjPnE6ER6bthsOA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*rcnzo3BAjPnE6ER6bthsOA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*rcnzo3BAjPnE6ER6bthsOA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*rcnzo3BAjPnE6ER6bthsOA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*rcnzo3BAjPnE6ER6bthsOA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*rcnzo3BAjPnE6ER6bthsOA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*rcnzo3BAjPnE6ER6bthsOA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure (A.2): AR(2,0,0) Model Results</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(B) Why Can’t the Feedforward NN Characterize Sequential Data Effectively?</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Figure (B.1) shows a standard feed-forward neural network. It has the input layer, the hidden layers, and the output layer. Every neuron is a weighted average of the neurons in the previous layer. The weights are the parameters to be estimated. A neural network is a supervised learning model in which the input layer contains <em>N</em> input values and the output layer has the target value y. Notice that the input values are not connected. They can be uncorrelated. The standard feedforward neural network takes the input data points as independent, without considering the correlations between the input data. This limitation makes the feedforward NN not suitable for modeling sequential data.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:60%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 454px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*n3TUbpHoRFWRKOWaTlFJCw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*n3TUbpHoRFWRKOWaTlFJCw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*n3TUbpHoRFWRKOWaTlFJCw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*n3TUbpHoRFWRKOWaTlFJCw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*n3TUbpHoRFWRKOWaTlFJCw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*n3TUbpHoRFWRKOWaTlFJCw.png 1100w, https://miro.medium.com/v2/resize:fit:908/format:webp/1*n3TUbpHoRFWRKOWaTlFJCw.png 908w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 454px" srcset="https://miro.medium.com/v2/resize:fit:640/1*n3TUbpHoRFWRKOWaTlFJCw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*n3TUbpHoRFWRKOWaTlFJCw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*n3TUbpHoRFWRKOWaTlFJCw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*n3TUbpHoRFWRKOWaTlFJCw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*n3TUbpHoRFWRKOWaTlFJCw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*n3TUbpHoRFWRKOWaTlFJCw.png 1100w, https://miro.medium.com/v2/resize:fit:908/1*n3TUbpHoRFWRKOWaTlFJCw.png 908w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/454/1*n3TUbpHoRFWRKOWaTlFJCw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure (B.1) Feedforward Neural Network</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Assume we want to predict the next two periods of a time series. If a standard feed-forward neural network is used, we can let x1, x2, x3, x4 be the past data points, and the target y1, y2 be the values of next two periods. Figure (B.2) shows the structure.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:53%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 404px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*I-bX3GwHanzSj9sowcmgDw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*I-bX3GwHanzSj9sowcmgDw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*I-bX3GwHanzSj9sowcmgDw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*I-bX3GwHanzSj9sowcmgDw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*I-bX3GwHanzSj9sowcmgDw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*I-bX3GwHanzSj9sowcmgDw.png 1100w, https://miro.medium.com/v2/resize:fit:808/format:webp/1*I-bX3GwHanzSj9sowcmgDw.png 808w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 404px" srcset="https://miro.medium.com/v2/resize:fit:640/1*I-bX3GwHanzSj9sowcmgDw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*I-bX3GwHanzSj9sowcmgDw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*I-bX3GwHanzSj9sowcmgDw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*I-bX3GwHanzSj9sowcmgDw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*I-bX3GwHanzSj9sowcmgDw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*I-bX3GwHanzSj9sowcmgDw.png 1100w, https://miro.medium.com/v2/resize:fit:808/1*I-bX3GwHanzSj9sowcmgDw.png 808w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/404/1*I-bX3GwHanzSj9sowcmgDw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure (B.2) Feedforward Neural Network</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">However, the serial connectivity in sequential data posts a special challenge that a standard feedforward NN not able to solve. First, it can only model the current period but cannot handle the serial correlation property in sequential data. In other words, x1, x2, x3, x4 are not serial correlated. Second, it does not have the capacity to memorize previous inputs.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(C) A Recursive Neural Network (RNN)</strong></p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:67%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 500px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*nT_xZ4WnHLVZY02OC1yjJA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*nT_xZ4WnHLVZY02OC1yjJA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*nT_xZ4WnHLVZY02OC1yjJA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*nT_xZ4WnHLVZY02OC1yjJA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*nT_xZ4WnHLVZY02OC1yjJA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*nT_xZ4WnHLVZY02OC1yjJA.png 1100w, https://miro.medium.com/v2/resize:fit:1000/format:webp/1*nT_xZ4WnHLVZY02OC1yjJA.png 1000w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 500px" srcset="https://miro.medium.com/v2/resize:fit:640/1*nT_xZ4WnHLVZY02OC1yjJA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*nT_xZ4WnHLVZY02OC1yjJA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*nT_xZ4WnHLVZY02OC1yjJA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*nT_xZ4WnHLVZY02OC1yjJA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*nT_xZ4WnHLVZY02OC1yjJA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*nT_xZ4WnHLVZY02OC1yjJA.png 1100w, https://miro.medium.com/v2/resize:fit:1000/1*nT_xZ4WnHLVZY02OC1yjJA.png 1000w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/500/1*nT_xZ4WnHLVZY02OC1yjJA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure (C): A Recursive Neural Network (RNN)</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In order to retain the memory of previous inputs, the Recursive Neural Network (RNN) should be specially designed. The outputs of the previous periods should somewhat become the inputs of the current periods. And the hidden layers will recursively take the inputs of previous periods. In the right-hand side of Figure (C) is a simple graph representation of an RNN. The hidden layer receives the inputs from the input layer, and there is a line to connect a hidden layer back to itself to represent the recursive nature. For now, you just need to know there is a recursive nature in the simplified RNN graph. In latter sections, I will explain every element in an RNN graph explicitly.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(D) Load the Stock Price Data</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We are going to use daily prices from 2013 to 2018 as the training data, and 2019 as the test data.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre>import pandas as pd
import yfinance as yf
from yahoofinancials import YahooFinancials
AMZN = yf.download('AMZN', 
                      start='2013-01-01', 
                      end='2019-12-31', 
                      progress=False)
# AMZN = yf.download('AMZN') for all 
all_data = AMZN[['Adj Close','Open', 'High', 'Low', 'Close', 'Volume']].round(2)
all_data.head(10)
print("There are "+ str(all_data[:'2018'].shape[0]) + " observations in the training data")
print("There are "+ str(all_data['2019':].shape[0]) + " observations in the test data")
all_data['Adj Close'].plot()
# There are 1,510 and 251 observations in the training and test data respectively.
</pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:51%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 388px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*PHaP5KWaFnxORAcBfHDl_Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*PHaP5KWaFnxORAcBfHDl_Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*PHaP5KWaFnxORAcBfHDl_Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*PHaP5KWaFnxORAcBfHDl_Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*PHaP5KWaFnxORAcBfHDl_Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*PHaP5KWaFnxORAcBfHDl_Q.png 1100w, https://miro.medium.com/v2/resize:fit:776/format:webp/1*PHaP5KWaFnxORAcBfHDl_Q.png 776w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 388px" srcset="https://miro.medium.com/v2/resize:fit:640/1*PHaP5KWaFnxORAcBfHDl_Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*PHaP5KWaFnxORAcBfHDl_Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*PHaP5KWaFnxORAcBfHDl_Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*PHaP5KWaFnxORAcBfHDl_Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*PHaP5KWaFnxORAcBfHDl_Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*PHaP5KWaFnxORAcBfHDl_Q.png 1100w, https://miro.medium.com/v2/resize:fit:776/1*PHaP5KWaFnxORAcBfHDl_Q.png 776w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/388/1*PHaP5KWaFnxORAcBfHDl_Q.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(E) Re-Organize Data for RNN/LSTM/GRU</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">RNNs are supervised deep learning techniques. We will create inputs and targets from a univariate time series for model training. Let me describe the ultimate data structure will be, then I will describe how we get there. The data frames in Figure (E.3) are what we are heading to. There are X_train and Y_train for modeling training, and X_test for predictions. This data structure is unique in modeling a time series in Deep Learning.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In order to get there, there are two popular data structures: <strong>many-to-many</strong> and <strong>many-to-one</strong>. The many-to-many uses the values of multiple periods to forecast the values of multiple periods in the future. The many-to-one uses the values of multiple periods to forecast the value of only period in the future.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(E.1) Many-to-many</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We are interested in using the prices of the past X days to forecast those of the future Y days. For the sake of illustration, let me use the prices of only 5 days to forecast the prices for the next 2 days. There are multiple inputs (5 data points) and multiple outputs (2 data points). This data structure is called <strong>many-to-many</strong>. Figure (E.1) creates <strong>samples </strong>from the univariate time series as the red window moves along the series. Each sample has 5 inputs and 2 outputs. Each input of a sample is called the <strong>time step</strong>, and each time step has one number, called a <strong>feature</strong>. The number of features can be multiple. For example, if we model both the “Adj. Close” and “Open” prices together in a time step, there are two features. Here we just model “Adj. Close” so the number of features is one.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*4TKZd1DKp5xAaHKCnaSRrQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*4TKZd1DKp5xAaHKCnaSRrQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*4TKZd1DKp5xAaHKCnaSRrQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*4TKZd1DKp5xAaHKCnaSRrQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*4TKZd1DKp5xAaHKCnaSRrQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*4TKZd1DKp5xAaHKCnaSRrQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4TKZd1DKp5xAaHKCnaSRrQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*4TKZd1DKp5xAaHKCnaSRrQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*4TKZd1DKp5xAaHKCnaSRrQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*4TKZd1DKp5xAaHKCnaSRrQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*4TKZd1DKp5xAaHKCnaSRrQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*4TKZd1DKp5xAaHKCnaSRrQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*4TKZd1DKp5xAaHKCnaSRrQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*4TKZd1DKp5xAaHKCnaSRrQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*4TKZd1DKp5xAaHKCnaSRrQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">FIGURE (E.1) Many-to-many</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(E.2) Many-to-one</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Figure (E.2) shows the case when there is only one output. This is called many-to-one.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:95%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 696px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*rupTSb5TcFZ62V6s-LjERQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*rupTSb5TcFZ62V6s-LjERQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*rupTSb5TcFZ62V6s-LjERQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*rupTSb5TcFZ62V6s-LjERQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*rupTSb5TcFZ62V6s-LjERQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*rupTSb5TcFZ62V6s-LjERQ.png 1100w, https://miro.medium.com/v2/resize:fit:1392/format:webp/1*rupTSb5TcFZ62V6s-LjERQ.png 1392w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 696px" srcset="https://miro.medium.com/v2/resize:fit:640/1*rupTSb5TcFZ62V6s-LjERQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*rupTSb5TcFZ62V6s-LjERQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*rupTSb5TcFZ62V6s-LjERQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*rupTSb5TcFZ62V6s-LjERQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*rupTSb5TcFZ62V6s-LjERQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*rupTSb5TcFZ62V6s-LjERQ.png 1100w, https://miro.medium.com/v2/resize:fit:1392/1*rupTSb5TcFZ62V6s-LjERQ.png 1392w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/696/1*rupTSb5TcFZ62V6s-LjERQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure (E.2) Many-to-one</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(E.3) RNN/LSTM/GRU Requires a 3-D Array as the Inputs</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The three dimensions are:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><strong>Tensor:</strong> One tensor is a vector that enters the model</li><li class="ff3" style="font-size:22px;"><strong>Time Step:</strong> One-time step is one observation in the tensor.</li><li class="ff3" style="font-size:22px;"><strong>Feature:</strong> One feature is one observation at a time step.</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The 1-D array above should be converted to a 3-D array =</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><code>[# of samples, # of time steps, # of features]</code>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This can be done by using <code>np.reshape(samples, time steps, features)</code>. I provide more exercises in the Jupyter notebook through <a href="https://github.com/dataman-git/codes_for_articles/blob/master/From%20regression%20to%20RNN.ipynb" target="_self">this Github link</a>. You are advised to print out the 3-D arrays in the Notebook available.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(E.3) The Code for Input and Output Data</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Below is the code to generate the input and output data in Figures (E.3). There are 1,504 rows or samples in the training data. There are 249 samples in the test data.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre>def ts_train_test(all_data,time_steps,for_periods):
    '''
    input: 
      data: dataframe with dates and price data
    output:
      X_train, y_train: data from 2013/1/1-2018/12/31
      X_test:  data from 2019 -
    time_steps: # of the input time steps
    for_periods: # of the output time steps
    '''
    # create training and test set
    ts_train = all_data[:'2018'].iloc[:,0:1].values
    ts_test  = all_data['2019':].iloc[:,0:1].values
    ts_train_len = len(ts_train)
    ts_test_len = len(ts_test)

    # create training data of s samples and t time steps
    X_train = []
    y_train = []
    y_train_stacked = []
    for i in range(time_steps,ts_train_len-1): 
        X_train.append(ts_train[i-time_steps:i,0])
        y_train.append(ts_train[i:i+for_periods,0])
    X_train, y_train = np.array(X_train), np.array(y_train)

    # Reshaping X_train for efficient modelling
    X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))

    # Preparing to create X_test
    inputs = pd.concat((all_data["Adj Close"][:'2018'], all_data["Adj Close"]['2019':]),axis=0).values
    inputs = inputs[len(inputs)-len(ts_test) - time_steps:]
    inputs = inputs.reshape(-1,1)

    X_test = []
    for i in range(time_steps,ts_test_len+time_steps-for_periods):
        X_test.append(inputs[i-time_steps:i,0])
        
    X_test = np.array(X_test)
    X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))

    return X_train, y_train , X_test

X_train, y_train, X_test = ts_train_test(all_data,5,2)
X_train.shape[0],X_train.shape[1]</pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">I convert the X_train, Y_train, and X_test to data frames and printed them below.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre># Convert the 3-D shape of X_train to a data frame so we can see: 
X_train_see = pd.DataFrame(np.reshape(X_train, (X_train.shape[0],X_train.shape[1])))
y_train_see = pd.DataFrame(y_train)
pd.concat([X_train_see,y_train_see],axis=1)

# Convert the 3-D shape of X_test to a data frame so we can see: 
X_test_see = pd.DataFrame(np.reshape(X_test, (X_test.shape[0],X_test.shape[1])))
pd.DataFrame(X_test_see)

print("There are " + str(X_train.shape[0]) + " samples in the training data")
print("There are " + str(X_test.shape[0]) + " samples in the test data")</pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*A4VKJwsWMLrW61KnA1Enmg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*A4VKJwsWMLrW61KnA1Enmg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*A4VKJwsWMLrW61KnA1Enmg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*A4VKJwsWMLrW61KnA1Enmg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*A4VKJwsWMLrW61KnA1Enmg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*A4VKJwsWMLrW61KnA1Enmg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A4VKJwsWMLrW61KnA1Enmg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*A4VKJwsWMLrW61KnA1Enmg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*A4VKJwsWMLrW61KnA1Enmg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*A4VKJwsWMLrW61KnA1Enmg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*A4VKJwsWMLrW61KnA1Enmg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*A4VKJwsWMLrW61KnA1Enmg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*A4VKJwsWMLrW61KnA1Enmg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*A4VKJwsWMLrW61KnA1Enmg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*A4VKJwsWMLrW61KnA1Enmg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure (E.3) X_train, Y_train, X_test</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(F) How Does RNN Work?</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Figure (F.1) shows an RNN and unrolls it to a full neural network. Do you notice it is very different from the feedforward neural network in Figure (B)? RNNs are called <em>recurrent</em> because they perform the same task for every sample, given the outcome from the previous computations. We also can consider RNNs to have a “memory” that passes information from one time step to the next time step. In theory, RNNs can handle a long sample of many time steps. This is suitable for stock prices because the information is passed down from one price point to the next price point. This means the price information of many days ago, or the same day last year still has its residual information to today’s price. However, a long sample makes the computations very time-consuming and may not be necessary. In our case, each sample (row) in X_train has 5 inputs and 2 outputs. So the diagram has 5 steps <em>xt-4, xt-3, xt-2, xt-1, xt,</em> and two output time steps <em>yt+1</em> and <em>yt+2</em>. The network has 5 hidden layers because there are 5 input time steps.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*NJopIXtl_t2NTpCtOZf8qw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*NJopIXtl_t2NTpCtOZf8qw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*NJopIXtl_t2NTpCtOZf8qw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*NJopIXtl_t2NTpCtOZf8qw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*NJopIXtl_t2NTpCtOZf8qw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*NJopIXtl_t2NTpCtOZf8qw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NJopIXtl_t2NTpCtOZf8qw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*NJopIXtl_t2NTpCtOZf8qw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*NJopIXtl_t2NTpCtOZf8qw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*NJopIXtl_t2NTpCtOZf8qw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*NJopIXtl_t2NTpCtOZf8qw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*NJopIXtl_t2NTpCtOZf8qw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*NJopIXtl_t2NTpCtOZf8qw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*NJopIXtl_t2NTpCtOZf8qw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*NJopIXtl_t2NTpCtOZf8qw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure (F.1): Many too many</p><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ygSt_cEaA3Zh49T5bCsEBw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ygSt_cEaA3Zh49T5bCsEBw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ygSt_cEaA3Zh49T5bCsEBw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ygSt_cEaA3Zh49T5bCsEBw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ygSt_cEaA3Zh49T5bCsEBw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ygSt_cEaA3Zh49T5bCsEBw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ygSt_cEaA3Zh49T5bCsEBw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*ygSt_cEaA3Zh49T5bCsEBw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ygSt_cEaA3Zh49T5bCsEBw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ygSt_cEaA3Zh49T5bCsEBw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ygSt_cEaA3Zh49T5bCsEBw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ygSt_cEaA3Zh49T5bCsEBw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ygSt_cEaA3Zh49T5bCsEBw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*ygSt_cEaA3Zh49T5bCsEBw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*ygSt_cEaA3Zh49T5bCsEBw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure (F.2): Many-to-one</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Step-by-step explanations:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><strong>Xt-4 to Xt:</strong> the time steps of a sample, e.g., 257.31, 258.48, 259.15, 268.46, 266.38 in Figure (C.3). Each time step is a vector of the number of features. Our case has one feature, so the dimension for each of xt-4 to <em>xt</em> is 1.</li><li class="ff3" style="font-size:22px;"><strong>ht-4 to ht:</strong> The hidden state of time step <em>t-1</em> to <em>t</em>. It’s the “memory” of the network. Each is calculated based on the previous hidden state and the input at the current step:</li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:37%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 291px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*LG9xBv4eG_EXh59g4fEBiA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*LG9xBv4eG_EXh59g4fEBiA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*LG9xBv4eG_EXh59g4fEBiA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*LG9xBv4eG_EXh59g4fEBiA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*LG9xBv4eG_EXh59g4fEBiA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*LG9xBv4eG_EXh59g4fEBiA.png 1100w, https://miro.medium.com/v2/resize:fit:582/format:webp/1*LG9xBv4eG_EXh59g4fEBiA.png 582w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 291px" srcset="https://miro.medium.com/v2/resize:fit:640/1*LG9xBv4eG_EXh59g4fEBiA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*LG9xBv4eG_EXh59g4fEBiA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*LG9xBv4eG_EXh59g4fEBiA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*LG9xBv4eG_EXh59g4fEBiA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*LG9xBv4eG_EXh59g4fEBiA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*LG9xBv4eG_EXh59g4fEBiA.png 1100w, https://miro.medium.com/v2/resize:fit:582/1*LG9xBv4eG_EXh59g4fEBiA.png 582w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/291/1*LG9xBv4eG_EXh59g4fEBiA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">The first hidden state <em>h0</em> is typically initialized to zeros.</li><li class="ff3" style="font-size:22px;">The <strong>activation function f(.)</strong> is tanh or ReLU (Rectified Linear Unit). The idea is similar to the logit function in logistic regression. Why does a logistic regression need the logit function? In a linear regression Y = XB + e, the independent variables X and the predicted Y can take any values from negative to positive infinity. Because logistic regression is about probability, we need to transform the output to be between 0 and 1. Otherwise, the output values may explode to negative or positive infinity. To prevent this from happening, here the tanh or ReLU function is applied to transform the output to be between 0 and 1.</li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:66%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 491px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*rTVwXpJqKKOAQCv6rNNWVA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*rTVwXpJqKKOAQCv6rNNWVA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*rTVwXpJqKKOAQCv6rNNWVA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*rTVwXpJqKKOAQCv6rNNWVA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*rTVwXpJqKKOAQCv6rNNWVA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*rTVwXpJqKKOAQCv6rNNWVA.png 1100w, https://miro.medium.com/v2/resize:fit:982/format:webp/1*rTVwXpJqKKOAQCv6rNNWVA.png 982w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 491px" srcset="https://miro.medium.com/v2/resize:fit:640/1*rTVwXpJqKKOAQCv6rNNWVA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*rTVwXpJqKKOAQCv6rNNWVA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*rTVwXpJqKKOAQCv6rNNWVA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*rTVwXpJqKKOAQCv6rNNWVA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*rTVwXpJqKKOAQCv6rNNWVA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*rTVwXpJqKKOAQCv6rNNWVA.png 1100w, https://miro.medium.com/v2/resize:fit:982/1*rTVwXpJqKKOAQCv6rNNWVA.png 982w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/491/1*rTVwXpJqKKOAQCv6rNNWVA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><strong>bt:</strong> the noise term</li><li class="ff3" style="font-size:22px;"><strong>yt+1, yt+2:</strong> are the outputs. They are the matrix product of the hidden neurons and the activation function tanh,</li><li class="ff3" style="font-size:22px;"><strong>U, W, and V:</strong> are the parameter matrix. The same matrix is used repeatedly across all steps. This reflects the fact that we are performing the same task but just with different inputs. What is the dimensionality of the matrix? This is not a trivial question. Let me explain in (D.1).</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(G) What Is the Dimensionality in the RNN/LSTM/GRU Layer of Keras?</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is probably the most confusing question. The official Keras’ description for “units” is “dimensionality of the output space”. I still think it is not easy to understand. (Some online sources confuse it with the number of time steps in a sample.) I feel it may be better to name the “units” as “latent dimension” or “latent_dim” (as used in <a href="https://keras.io/guides/making_new_layers_and_models_via_subclassing/" target="_self">this Keras code</a>). This renaming at least implies that the dimensionality is internal and has nothing to do with the outside parameters.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>The dimension of the hidden layer is the “units”</strong>. Since there are hidden layers, we need to specify the number of neurons for the hidden layers. The hidden dimension can be any number. The hidden dimensionality determines the capability of RNN to retain the memory for all the past information. It is usually not a small number and is conventionally the multiple of 32, such as 32, 64, or 128.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:63%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 475px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*6GLDabb7dfWgQjgQz2PXyg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*6GLDabb7dfWgQjgQz2PXyg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*6GLDabb7dfWgQjgQz2PXyg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*6GLDabb7dfWgQjgQz2PXyg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*6GLDabb7dfWgQjgQz2PXyg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*6GLDabb7dfWgQjgQz2PXyg.png 1100w, https://miro.medium.com/v2/resize:fit:950/format:webp/1*6GLDabb7dfWgQjgQz2PXyg.png 950w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 475px" srcset="https://miro.medium.com/v2/resize:fit:640/1*6GLDabb7dfWgQjgQz2PXyg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*6GLDabb7dfWgQjgQz2PXyg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*6GLDabb7dfWgQjgQz2PXyg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*6GLDabb7dfWgQjgQz2PXyg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*6GLDabb7dfWgQjgQz2PXyg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*6GLDabb7dfWgQjgQz2PXyg.png 1100w, https://miro.medium.com/v2/resize:fit:950/1*6GLDabb7dfWgQjgQz2PXyg.png 950w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/475/1*6GLDabb7dfWgQjgQz2PXyg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure (G): The latent dimension</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Figure (G) explains the hidden dimensionality. Each time step <em>xt-4</em> to <em>xt</em> is a vector of the number of features. Our case has one feature, so the dimension for each of xt-4 to <em>xt</em> is 1, i.e., N<em>x</em> = 1. N<em>h</em> is the dimension of the hidden layer. If N<em>h</em>=32, then the parameter matrix U is (32 x 1). The dot product of U and <em>xt</em> has the dimension (32 x 1) x (1 x 1) = (32 x 1). Likewise, the parameter matrix W is (32 x 32), the dot product of W and <em>ht-1</em> is (32 x 32) x (32 x 1) = (32 x 1). The noise vector therefore should be a (32 x 1) vector.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(H) Build a Simple RNN Model</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Tensorflow and Keras are the two most popular platforms for modeling neural networks. TensorFlow is an open-source platform for machine learning. It has many libraries and community resources. It enables ML developers to build and deploy ML applications easily. Keras is an open-source deep-learning API written in Python. It supports Tensorflow or Theano. Big companies such as Microsoft, NVIDIA, Google, and Amazon have contributed actively to Keras’ growth.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The procedure to build the transfer learning model is the same as building any neural network. It involves three steps in Keras: (1) .sequential() to build the model architecture, (2) .compile () to compile the model with the loss function and optimization method, and (3) .fit() to train the model. The function .sequential() defines the structure of a neural network. It is the pipeline to add any layers to a model. Once a model is defined, the compiling step defines the evaluation metric and the optimizer. The last step executes the actual model training.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(H.1) Declare the Model</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This step gives the model specification for a simple RNN model.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(H.2) Compile the Model</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The second step of building a neural network is the compiling step. This step defines the evaluation metric and the optimizer.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">An evaluation metric is the loss function that is used to judge the performance of a model. Keras includes almost all the evaluation metrics. The evaluation metrics belong to three categories: (a) the regression-related metrics, (b) the probabilistic metrics, and © the accuracy metrics. The regression-related metrics include mean squared error (MSE), root mean squared error (RMSE), mean absolute error (MAE), mean absolute percentage error (MAPE), and so on. When your target variable is continuous and you would like to pursue the minimum deviation in terms of percentage errors or absolute errors, you should consider the regression-related metrics.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The probabilistic metrics are considered when your prediction is a probability. They include binary cross-entropy and categorical cross-entropy. If your target is binary, you can use binary cross-entropy. If your target is multi-class, categorical cross-entropy.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The accuracy metrics calculate how often predictions equal labels. The frequently-used metrics are the accuracy class, binary accuracy class, and categorical accuracy class. As the name suggests, the binary accuracy class calculates how often predictions match binary labels, and the categorical accuracy class calculates how often predictions match multiple labels.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The optimizer is a function that optimizes a model. Optimizers use the above loss function to calculate the loss of the model and then try to minimize the loss. Without an optimizer, a machine learning model can’t do anything.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The popular optimizers include the Stochastic Gradient Decent (SGD), RMSprop, Resilient Back Propagation (RProp), the Adaptive Moment (Adam), and the Ada family. The SGD is probably the most widely used optimizer. The RMSprop maintain a moving average of the gradients and uses that average to estimate the variance. The RProp is widely used in multi-layered feed-forward networks. The Adam is considered more efficient and requires less memory when working with a large amount of data and parameters. It requires less memory and is efficient. I use rmsprop as the optimizer.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(H.3) Fit the Model</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The third step is the training step. This is a time-consuming step. You will see “epoch 1”, and “epoch 2” appearing on your screen.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this step, we deal with a unique concept in a neural network called “<strong>epoch</strong>”. <em>In an epoch, the model goes through all data exactly once.</em> The model parameters are updated in each epoch until they reach optimal values.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you specify too many epochs, the model will commit overfitting. It will learn the training data too well but predict poorly for a new dataset. How do we determine the optimal number of epochs? The answers are the loss and accuracy metrics. When a model is trained with more epochs, the loss will decrease, and the accuracy will increase. After a certain number of epochs, the loss will stop decreasing but increase, and the accuracy decreases. It indicates the model training should end with that epoch.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre>def simple_rnn_model(X_train, y_train, X_test):
    '''
    create single layer rnn model trained on X_train and y_train
    and make predictions on the X_test data
    '''
    # create a model
    from keras.models import Sequential
    from keras.layers import Dense, SimpleRNN
    
    my_rnn_model = Sequential()
    my_rnn_model.add(SimpleRNN(32, return_sequences=True))
    #my_rnn_model.add(SimpleRNN(32, return_sequences=True))
    #my_rnn_model.add(SimpleRNN(32, return_sequences=True))
    my_rnn_model.add(SimpleRNN(32))
    my_rnn_model.add(Dense(2)) # The time step of the output

    my_rnn_model.compile(optimizer='rmsprop', loss='mean_squared_error')

    # fit the RNN model
    my_rnn_model.fit(X_train, y_train, epochs=100, batch_size=150, verbose=0)

    # Finalizing predictions
    rnn_predictions = my_rnn_model.predict(X_test)

    return my_rnn_model, rnn_predictions

my_rnn_model, rnn_predictions = simple_rnn_model(X_train, y_train, X_test)
rnn_predictions[1:10]

def actual_pred_plot(preds):
    ''
    Plot the actual vs. prediction
    ''
    actual_pred = pd.DataFrame(columns = ['Adj. Close', 'prediction'])
    actual_pred['Adj. Close'] = all_data.loc['2019':,'Adj Close'][0:len(preds)]
    actual_pred['prediction'] = preds[:,0]

    from keras.metrics import MeanSquaredError
    m = MeanSquaredError()
    m.update_state(np.array(actual_pred['Adj. Close']),np.array(actual_pred['prediction']))
    
    return (m.result().numpy(), actual_pred.plot() )
    
actual_pred_plot(rnn_predictions)  </pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The model prediction is terrible! Do you know why? This is because the input data were not normalized. In (D.2) we will normalize the input data. <strong>The key takeaway is: that normalization is necessary for RNN/LSTM/GRU.</strong> The function <code>actual_pred_plot()</code> also calculates the mean square error. The result is 3,072,268.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:51%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 389px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*GOC2g2ReKG3p30goZoeM6w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*GOC2g2ReKG3p30goZoeM6w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*GOC2g2ReKG3p30goZoeM6w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*GOC2g2ReKG3p30goZoeM6w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*GOC2g2ReKG3p30goZoeM6w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*GOC2g2ReKG3p30goZoeM6w.png 1100w, https://miro.medium.com/v2/resize:fit:778/format:webp/1*GOC2g2ReKG3p30goZoeM6w.png 778w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 389px" srcset="https://miro.medium.com/v2/resize:fit:640/1*GOC2g2ReKG3p30goZoeM6w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*GOC2g2ReKG3p30goZoeM6w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*GOC2g2ReKG3p30goZoeM6w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*GOC2g2ReKG3p30goZoeM6w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*GOC2g2ReKG3p30goZoeM6w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*GOC2g2ReKG3p30goZoeM6w.png 1100w, https://miro.medium.com/v2/resize:fit:778/1*GOC2g2ReKG3p30goZoeM6w.png 778w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/389/1*GOC2g2ReKG3p30goZoeM6w.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Notice that you can add several simpleRNN layers as shown but commented out in the code. You can test their performances.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(I) Normalized Data Are Needed for RNN/LSTM/GRU</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The code below (Line 16–19) normalizes the input data. When you standardize data to train your model, remember that only the training data are used to fit the scaler transformation, then the scalar is used to transform the test input data. Do not scale x_train and x_test independently, as I documented in “<a href="https://towardsdatascience.com/avoid-these-deadly-modeling-mistakes-that-may-cost-you-a-career-b9b686d89f2c" target="_self">Avoid These Deadly Modeling Mistakes that May Cost You a Career</a>”. Line 72 applies the scalar to convert the scaled predictions to the original scale. The prediction performance is much better as shown in the graph. The MSE is 3,852.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre>def ts_train_test_normalize(all_data,time_steps,for_periods):
    '''
    input: 
      data: dataframe with dates and price data
    output:
      X_train, y_train: data from 2013/1/1-2018/12/31
      X_test:  data from 2019 -
      sc:      insantiated MinMaxScaler object fit to the training data
    '''
    # create training and test set
    ts_train = all_data[:'2018'].iloc[:,0:1].values
    ts_test  = all_data['2019':].iloc[:,0:1].values
    ts_train_len = len(ts_train)
    ts_test_len = len(ts_test)

    # scale the data
    from sklearn.preprocessing import MinMaxScaler
    sc = MinMaxScaler(feature_range=(0,1))
    ts_train_scaled = sc.fit_transform(ts_train)

    # create training data of s samples and t time steps
    X_train = []
    y_train = []
    y_train_stacked = []
    for i in range(time_steps,ts_train_len-1): 
        X_train.append(ts_train_scaled[i-time_steps:i,0])
        y_train.append(ts_train_scaled[i:i+for_periods,0])
    X_train, y_train = np.array(X_train), np.array(y_train)

    # Reshaping X_train for efficient modelling
    X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))

    inputs = pd.concat((all_data["Adj Close"][:'2018'], all_data["Adj Close"]['2019':]),axis=0).values
    inputs = inputs[len(inputs)-len(ts_test) - time_steps:]
    inputs = inputs.reshape(-1,1)
    inputs  = sc.transform(inputs)

    # Preparing X_test
    X_test = []
    for i in range(time_steps,ts_test_len+time_steps-for_periods):
        X_test.append(inputs[i-time_steps:i,0])
        
    X_test = np.array(X_test)
    X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))

    return X_train, y_train , X_test, sc

def simple_rnn_model(X_train, y_train, X_test, sc):
    '''
    create single layer rnn model trained on X_train and y_train
    and make predictions on the X_test data
    '''
    # create a model
    from keras.models import Sequential
    from keras.layers import Dense, SimpleRNN
    
    my_rnn_model = Sequential()
    my_rnn_model.add(SimpleRNN(32, return_sequences=True))
    #my_rnn_model.add(SimpleRNN(32, return_sequences=True))
    #my_rnn_model.add(SimpleRNN(32, return_sequences=True))
    my_rnn_model.add(SimpleRNN(32))
    my_rnn_model.add(Dense(2)) # The time step of the output

    my_rnn_model.compile(optimizer='rmsprop', loss='mean_squared_error')

    # fit the RNN model
    my_rnn_model.fit(X_train, y_train, epochs=100, batch_size=150, verbose=0)

    # Finalizing predictions
    rnn_predictions = my_rnn_model.predict(X_test)
    from sklearn.preprocessing import MinMaxScaler
    rnn_predictions = sc.inverse_transform(rnn_predictions)

    return my_rnn_model, rnn_predictions


X_train, y_train, X_test, sc = ts_train_test_normalize(all_data,5,2)
my_rnn_model, rnn_predictions_2 = simple_rnn_model(X_train, y_train, X_test, sc)
rnn_predictions_2[1:10]
actual_pred_plot(rnn_predictions_2)   </pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:51%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 391px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*GaCYAh02ODZGkubu16vXjQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*GaCYAh02ODZGkubu16vXjQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*GaCYAh02ODZGkubu16vXjQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*GaCYAh02ODZGkubu16vXjQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*GaCYAh02ODZGkubu16vXjQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*GaCYAh02ODZGkubu16vXjQ.png 1100w, https://miro.medium.com/v2/resize:fit:782/format:webp/1*GaCYAh02ODZGkubu16vXjQ.png 782w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 391px" srcset="https://miro.medium.com/v2/resize:fit:640/1*GaCYAh02ODZGkubu16vXjQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*GaCYAh02ODZGkubu16vXjQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*GaCYAh02ODZGkubu16vXjQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*GaCYAh02ODZGkubu16vXjQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*GaCYAh02ODZGkubu16vXjQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*GaCYAh02ODZGkubu16vXjQ.png 1100w, https://miro.medium.com/v2/resize:fit:782/1*GaCYAh02ODZGkubu16vXjQ.png 782w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/391/1*GaCYAh02ODZGkubu16vXjQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(J) Why Do We Need LSTM/GRU?</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The optimizer of RNN gets the first-order derivative of the loss function to search for the optimal values. Because RNN is recursive, the first-order derivation process will make a number smaller and smaller, then eventually vanish. This is called <em>gradient vanishing</em>. This certain mathematical process makes RNN not a good choice to retain memories. <strong>We need a recursive structure so that the information does not vanish quickly. This is the motive for LSTM and GRU.</strong> (For readers who may not be familiar with the optimization process: A loss function is a metric that measures the errors between the actual and the predicted values. An optimizer is an algorithm that changes the weights of the neurons to pursue the minimum error. A popular optimizer is the Stochastic Gradient Descent (SGD). The article “<a href="https://medium.com/analytics-vidhya/a-lecture-note-on-random-forest-gradient-boosting-and-regularization-834fc9a7fa52" target="_self">My Lecture Notes on Random Forest, Gradient Boosting, Regularization, and H2O.ai</a>” gives a detailed description of SGD. The above code specifies <code>RMSprop</code>, Root Mean Square Propagation, as the optimizer.)</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(K) Why LSTM (Long Short-Term Memory)?</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="http://www.bioinf.jku.at/publications/older/2604.pdf" target="_self">Hochreiter and Schmidhuber (1997)</a> proposed the LSTM structure to retain memory for RNNs over longer periods. It solves the problem of gradient vanishing (or gradient explosion) by introducing <strong>additional gates, input, and forget gates</strong>. These additional gates can control better over the gradient, enabling what information to preserve and what to forget. These gates are sigmoid functions with output in [0,1] to pass limited information or all information. A value of zero means filtering out the information completely, while a value of one means passing the information completely. The structure is called Long Short-Term Memory because it uses the short-term memory processes to create longer memory. (So do not mislabel “Long <strong>Short-Term</strong> Memory” as “Long-Short Term Memory”.)</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">How does LSTM retain the memory of a long time ago? <strong>LSTM has its layers called the cell state, often labeled Ct, in addition to the hidden layers</strong> to prevent the old information from vanishing too soon. In our stock price example, the price of this Friday may be influenced by the prices of previous Fridays, or even the price of the same day last year. RNNs may not be able to retain the price information of the same day last year, while LSTM in theory is designed to retain it.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(K.1) Math Explanation for the Issue of Vanishing Gradients</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Feel free to skip the mathematical explanation and jump to (F.2) if you already get the idea. Assume we have a hidden state ℎ𝑡 at time step 𝑡 to make the math simple, we remove the bias <em>bt</em> and the input <em>xt</em> terms:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:18%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 157px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*vlAiuHl6WX50L8aq858LKA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*vlAiuHl6WX50L8aq858LKA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*vlAiuHl6WX50L8aq858LKA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*vlAiuHl6WX50L8aq858LKA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*vlAiuHl6WX50L8aq858LKA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*vlAiuHl6WX50L8aq858LKA.png 1100w, https://miro.medium.com/v2/resize:fit:314/format:webp/1*vlAiuHl6WX50L8aq858LKA.png 314w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 157px" srcset="https://miro.medium.com/v2/resize:fit:640/1*vlAiuHl6WX50L8aq858LKA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*vlAiuHl6WX50L8aq858LKA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*vlAiuHl6WX50L8aq858LKA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*vlAiuHl6WX50L8aq858LKA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*vlAiuHl6WX50L8aq858LKA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*vlAiuHl6WX50L8aq858LKA.png 1100w, https://miro.medium.com/v2/resize:fit:314/1*vlAiuHl6WX50L8aq858LKA.png 314w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/157/1*vlAiuHl6WX50L8aq858LKA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Taking the first-order derivatives we get the following equations. The circled coefficient vector is the key. It will vanish exponentially to zero, or explode exponentially to infinity.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:49%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 373px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*eh8aQBxaR3FF_KCVBj6y5A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*eh8aQBxaR3FF_KCVBj6y5A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*eh8aQBxaR3FF_KCVBj6y5A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*eh8aQBxaR3FF_KCVBj6y5A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*eh8aQBxaR3FF_KCVBj6y5A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*eh8aQBxaR3FF_KCVBj6y5A.png 1100w, https://miro.medium.com/v2/resize:fit:746/format:webp/1*eh8aQBxaR3FF_KCVBj6y5A.png 746w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 373px" srcset="https://miro.medium.com/v2/resize:fit:640/1*eh8aQBxaR3FF_KCVBj6y5A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*eh8aQBxaR3FF_KCVBj6y5A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*eh8aQBxaR3FF_KCVBj6y5A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*eh8aQBxaR3FF_KCVBj6y5A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*eh8aQBxaR3FF_KCVBj6y5A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*eh8aQBxaR3FF_KCVBj6y5A.png 1100w, https://miro.medium.com/v2/resize:fit:746/1*eh8aQBxaR3FF_KCVBj6y5A.png 746w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/373/1*eh8aQBxaR3FF_KCVBj6y5A.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To overcome the problem, LSTM adds the cell state 𝑠𝑡. The derivative equation is:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:36%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 284px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Jx39U2JmNpxKn-07Df4l5g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Jx39U2JmNpxKn-07Df4l5g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Jx39U2JmNpxKn-07Df4l5g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Jx39U2JmNpxKn-07Df4l5g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Jx39U2JmNpxKn-07Df4l5g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Jx39U2JmNpxKn-07Df4l5g.png 1100w, https://miro.medium.com/v2/resize:fit:568/format:webp/1*Jx39U2JmNpxKn-07Df4l5g.png 568w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 284px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Jx39U2JmNpxKn-07Df4l5g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Jx39U2JmNpxKn-07Df4l5g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Jx39U2JmNpxKn-07Df4l5g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Jx39U2JmNpxKn-07Df4l5g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Jx39U2JmNpxKn-07Df4l5g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Jx39U2JmNpxKn-07Df4l5g.png 1100w, https://miro.medium.com/v2/resize:fit:568/1*Jx39U2JmNpxKn-07Df4l5g.png 568w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/284/1*Jx39U2JmNpxKn-07Df4l5g.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here 𝑣𝑡 is the input to the forget gate. Because there is no decaying factor <em>w</em>, it does not vanish so fast. However, you may ask that Eq. (2) also has the sigmoid function, so the matrix multiplication also will make the values vanish. You are correct. LSTM still will suffer the problem of vanishing gradients, but not as fast as Eq. (1).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(K.2) The Structure of LSTM</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Many papers demonstrate only the internal structure of LSTM — this may still leave you confused about how the system works. Thus I draw a complete diagram of LSTM in Figure (F.2), similar to that of RNN in Figure (D.2), to show you the whole system.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*z60TCmpRvywI5DWiInPlDg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*z60TCmpRvywI5DWiInPlDg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*z60TCmpRvywI5DWiInPlDg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*z60TCmpRvywI5DWiInPlDg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*z60TCmpRvywI5DWiInPlDg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*z60TCmpRvywI5DWiInPlDg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z60TCmpRvywI5DWiInPlDg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*z60TCmpRvywI5DWiInPlDg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*z60TCmpRvywI5DWiInPlDg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*z60TCmpRvywI5DWiInPlDg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*z60TCmpRvywI5DWiInPlDg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*z60TCmpRvywI5DWiInPlDg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*z60TCmpRvywI5DWiInPlDg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*z60TCmpRvywI5DWiInPlDg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*z60TCmpRvywI5DWiInPlDg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Figure (F.2): LSTM Structure</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The LSTM has four components: input gates, forget gates, cell state, and output gates.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><strong>Input Gate:</strong> the goal is to take in new information <em>xt</em>. There are two functions to take in new information: <em>rt</em> and <em>dt</em>. The <em>rt</em> concatenates the previous hidden vector <em>ht-1</em> with the new information <em>xt</em>., i.e., [<em>ht-1, xt</em>], then multiplies with the weight matrix <em>Wr,</em> plus a noise vector <em>br</em>. The dt does something similar. Then <em>rt</em> and <em>dt</em> are multiplied element-wise to get the cell state <em>ct</em>.</li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*IEa9FbsZZZvmvefsGvhq8Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*IEa9FbsZZZvmvefsGvhq8Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*IEa9FbsZZZvmvefsGvhq8Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*IEa9FbsZZZvmvefsGvhq8Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*IEa9FbsZZZvmvefsGvhq8Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*IEa9FbsZZZvmvefsGvhq8Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IEa9FbsZZZvmvefsGvhq8Q.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*IEa9FbsZZZvmvefsGvhq8Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*IEa9FbsZZZvmvefsGvhq8Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*IEa9FbsZZZvmvefsGvhq8Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*IEa9FbsZZZvmvefsGvhq8Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*IEa9FbsZZZvmvefsGvhq8Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*IEa9FbsZZZvmvefsGvhq8Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*IEa9FbsZZZvmvefsGvhq8Q.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*IEa9FbsZZZvmvefsGvhq8Q.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><strong>Forget Gate:</strong> The forget gate <em>ft</em> looks very similar to <em>rt</em> in the input gate. It controls the limit up to which a value is retailed in the memory.</li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*xvCpVK8Wn8bmPOIDl0_cLA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*xvCpVK8Wn8bmPOIDl0_cLA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*xvCpVK8Wn8bmPOIDl0_cLA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*xvCpVK8Wn8bmPOIDl0_cLA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*xvCpVK8Wn8bmPOIDl0_cLA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*xvCpVK8Wn8bmPOIDl0_cLA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xvCpVK8Wn8bmPOIDl0_cLA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*xvCpVK8Wn8bmPOIDl0_cLA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*xvCpVK8Wn8bmPOIDl0_cLA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*xvCpVK8Wn8bmPOIDl0_cLA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*xvCpVK8Wn8bmPOIDl0_cLA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*xvCpVK8Wn8bmPOIDl0_cLA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*xvCpVK8Wn8bmPOIDl0_cLA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*xvCpVK8Wn8bmPOIDl0_cLA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*xvCpVK8Wn8bmPOIDl0_cLA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><strong>Cell State:</strong> it calculates an element-wise multiplication between the previous cell state <em>Ct-1</em> and forget gate <em>ft</em>. It then adds the results from the input gate <em>rt</em> times <em>dt</em>.</li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*pHy58zKFuHtDxzED8GcVLA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*pHy58zKFuHtDxzED8GcVLA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*pHy58zKFuHtDxzED8GcVLA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*pHy58zKFuHtDxzED8GcVLA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*pHy58zKFuHtDxzED8GcVLA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*pHy58zKFuHtDxzED8GcVLA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pHy58zKFuHtDxzED8GcVLA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*pHy58zKFuHtDxzED8GcVLA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*pHy58zKFuHtDxzED8GcVLA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*pHy58zKFuHtDxzED8GcVLA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*pHy58zKFuHtDxzED8GcVLA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*pHy58zKFuHtDxzED8GcVLA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*pHy58zKFuHtDxzED8GcVLA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*pHy58zKFuHtDxzED8GcVLA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*pHy58zKFuHtDxzED8GcVLA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><strong>Output gate</strong>: Here <em>ot </em>is the output gate at time step <em>t</em>, and <em>Wo </em>and <em>bo </em>are the weights and bias for the output gate. The hidden layer <em>ht</em> either goes to the next time step or goes up to output as <em>yt</em>. In the following code Line 12, yt is obtained by applying another tanh to <em>ht</em>. Note that the output gate <em>ot</em> is not the output <em>yt</em>, it simply is the “gate” to control the output.</li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*2IbEDGqg4WVyn4VtZsI8QA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*2IbEDGqg4WVyn4VtZsI8QA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*2IbEDGqg4WVyn4VtZsI8QA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*2IbEDGqg4WVyn4VtZsI8QA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*2IbEDGqg4WVyn4VtZsI8QA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*2IbEDGqg4WVyn4VtZsI8QA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2IbEDGqg4WVyn4VtZsI8QA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*2IbEDGqg4WVyn4VtZsI8QA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*2IbEDGqg4WVyn4VtZsI8QA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*2IbEDGqg4WVyn4VtZsI8QA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*2IbEDGqg4WVyn4VtZsI8QA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*2IbEDGqg4WVyn4VtZsI8QA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*2IbEDGqg4WVyn4VtZsI8QA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*2IbEDGqg4WVyn4VtZsI8QA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*2IbEDGqg4WVyn4VtZsI8QA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(K.3) LSTM Code</strong></p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre>def LSTM_model(X_train, y_train, X_test, sc):
    # create a model
    from keras.models import Sequential
    from keras.layers import Dense, SimpleRNN, GRU, LSTM
    from keras.optimizers import SGD
    
    # The LSTM architecture
    my_LSTM_model = Sequential()
    my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))
    #my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))
    #my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))
    my_LSTM_model.add(LSTM(units=50, activation='tanh'))
    my_LSTM_model.add(Dense(units=2))

    # Compiling
    my_LSTM_model.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')
    # Fitting to the training set
    my_LSTM_model.fit(X_train,y_train,epochs=50,batch_size=150, verbose=0)

    LSTM_prediction = my_LSTM_model.predict(X_test)
    LSTM_prediction = sc.inverse_transform(LSTM_prediction)

    return my_LSTM_model, LSTM_prediction

my_LSTM_model, LSTM_prediction = LSTM_model(X_train, y_train, X_test, sc)
LSTM_prediction[1:10]
actual_pred_plot(LSTM_prediction)   </pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:51%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 387px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*qR2nUsGw7JEG-7MEsFmv_A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*qR2nUsGw7JEG-7MEsFmv_A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*qR2nUsGw7JEG-7MEsFmv_A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*qR2nUsGw7JEG-7MEsFmv_A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*qR2nUsGw7JEG-7MEsFmv_A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*qR2nUsGw7JEG-7MEsFmv_A.png 1100w, https://miro.medium.com/v2/resize:fit:774/format:webp/1*qR2nUsGw7JEG-7MEsFmv_A.png 774w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 387px" srcset="https://miro.medium.com/v2/resize:fit:640/1*qR2nUsGw7JEG-7MEsFmv_A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*qR2nUsGw7JEG-7MEsFmv_A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*qR2nUsGw7JEG-7MEsFmv_A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*qR2nUsGw7JEG-7MEsFmv_A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*qR2nUsGw7JEG-7MEsFmv_A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*qR2nUsGw7JEG-7MEsFmv_A.png 1100w, https://miro.medium.com/v2/resize:fit:774/1*qR2nUsGw7JEG-7MEsFmv_A.png 774w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/387/1*qR2nUsGw7JEG-7MEsFmv_A.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(K.4) LSTM With Regularization</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Overfitting is a serious sin in machine learning.</strong> When you train a model on your training data and apply it to the test data, the accuracy of the test data usually is less than that of the training data. We know this is because the model has fitted the training data too well, including the noises in the training data. However, if overfitting just makes your prediction for the test data less effective, what’s the big deal? Why do academia and practitioners devote decades of work to prevent overfitting?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The real issue is that overfitting not only makes your model inefficient, but it could also make your prediction very wrong. Suppose your final model has ten variables, eight of which capture the real patterns and the other two variables, noises. In other words, the two variables overfit noises and are useless. Suppose you are going to predict new data with your ten-variable model, and suppose the new values for the two variables are large. Guess what will happen? Your prediction will be very wrong due to the two variables and the large values in the new data. So overfitting does not just make your model ineffective, it can make your prediction very wrong.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Deep learning uses the <strong>dropout technique</strong> to control overfitting. The dropout technique randomly drops or deactivates some neurons for a layer during each iteration. It is like some weights are set to zero. So in each iteration, the model looks at a slightly different structure of itself to optimize the model. See “<a href="https://levelup.gitconnected.com/a-tutorial-to-build-from-regression-to-deep-learning-b7354240d2d5" target="_self">Explaining Deep Learning in a Regression-Friendly Way</a>” for more detail.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Handling dropout in RNN/LSTM/GRU is also a research topic. In a feedforward neural network, dropping neurons is easier because there is no connectivity between neurons of the same layer. However, in RNN/LSTM/GRU, dropping time steps harms the ability to carry informative signals across time. What are the remedies? <a href="https://arxiv.org/abs/1312.4569" target="_self">Pham et al. (2013)</a> suggest applying dropout only between layers in deep-RNNs and not between sequence positions. <a href="https://arxiv.org/abs/1512.05287" target="_self">Gal and Ghahramani (2015)</a> suggest applying dropout to all the components of the RNN (both recurrent and non-recurrent) but retaining the same dropout mask across time steps. <a href="https://arxiv.org/pdf/1409.2329.pdf" target="_self">This paper</a> provides a good review.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre>def LSTM_model_regularization(X_train, y_train, X_test, sc):
    # create a model
    from keras.models import Sequential
    from keras.layers import Dense, SimpleRNN, GRU, LSTM, Dropout
    from keras.optimizers import SGD
    
    # The LSTM architecture
    my_LSTM_model = Sequential()
    my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))
    #my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))
    #my_LSTM_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))
    my_LSTM_model.add(LSTM(units=50, activation='tanh'))
    my_LSTM_model.add(Dropout(0.2))
    my_LSTM_model.add(Dense(units=2))

    # Compiling
    my_LSTM_model.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')
    # Fitting to the training set
    my_LSTM_model.fit(X_train,y_train,epochs=50,batch_size=150, verbose=0)

    LSTM_prediction = my_LSTM_model.predict(X_test)
    LSTM_prediction = sc.inverse_transform(LSTM_prediction)

    return my_LSTM_model, LSTM_prediction

my_LSTM_model, LSTM_prediction = LSTM_model_regularization(X_train, y_train, X_test, sc)
LSTM_prediction[1:10]
actual_pred_plot(LSTM_prediction)  </pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The MSE is 2,152.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:51%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 385px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Sn5WnCfCQPlUFNe63ziQiw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Sn5WnCfCQPlUFNe63ziQiw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Sn5WnCfCQPlUFNe63ziQiw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Sn5WnCfCQPlUFNe63ziQiw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Sn5WnCfCQPlUFNe63ziQiw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Sn5WnCfCQPlUFNe63ziQiw.png 1100w, https://miro.medium.com/v2/resize:fit:770/format:webp/1*Sn5WnCfCQPlUFNe63ziQiw.png 770w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 385px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Sn5WnCfCQPlUFNe63ziQiw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Sn5WnCfCQPlUFNe63ziQiw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Sn5WnCfCQPlUFNe63ziQiw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Sn5WnCfCQPlUFNe63ziQiw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Sn5WnCfCQPlUFNe63ziQiw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Sn5WnCfCQPlUFNe63ziQiw.png 1100w, https://miro.medium.com/v2/resize:fit:770/1*Sn5WnCfCQPlUFNe63ziQiw.png 770w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/385/1*Sn5WnCfCQPlUFNe63ziQiw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(L) GRU (Gated Recurrent Units)</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The GRU was invented by <a href="https://arxiv.org/abs/1406.1078" target="_self">Cho et al. (2014)</a> in a company with RNN and LSTM. It is expected more variations of the recursive network will continue to emerge. GRU also aims to solve the <strong>vanishing gradient problem</strong>. GRU does not have the cell state and the output gate like those in LSTM. It, therefore, has fewer parameters than LSTM. GRU uses the hidden layers to transfer information. GRU calls its two gates the <strong>reset gate</strong> and the <strong>update gate</strong>. Let me explain them one by one.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(L.1) The Structure of GRU</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The parameters of GRU include Wr, Wz, and W. The reset signal <em>rt</em> determines if the previous hidden state should be ignored while the update signal <em>zt</em> determines if the hidden state <em>ht</em> should be updated with the new hidden state <em>hat(ht)</em>.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:94%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 691px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*JgFC5EQQLFsim30TSeXkBA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*JgFC5EQQLFsim30TSeXkBA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*JgFC5EQQLFsim30TSeXkBA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*JgFC5EQQLFsim30TSeXkBA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*JgFC5EQQLFsim30TSeXkBA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*JgFC5EQQLFsim30TSeXkBA.png 1100w, https://miro.medium.com/v2/resize:fit:1382/format:webp/1*JgFC5EQQLFsim30TSeXkBA.png 1382w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 691px" srcset="https://miro.medium.com/v2/resize:fit:640/1*JgFC5EQQLFsim30TSeXkBA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*JgFC5EQQLFsim30TSeXkBA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*JgFC5EQQLFsim30TSeXkBA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*JgFC5EQQLFsim30TSeXkBA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*JgFC5EQQLFsim30TSeXkBA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*JgFC5EQQLFsim30TSeXkBA.png 1100w, https://miro.medium.com/v2/resize:fit:1382/1*JgFC5EQQLFsim30TSeXkBA.png 1382w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/691/1*JgFC5EQQLFsim30TSeXkBA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><strong>Reset Gate:</strong> This achieves what the input gate and forget gate of LSTM achieve. The gate <em>rt</em> determines if the previous hidden state should be ignored. The gate <em>zt</em> is generated for the update gate with <em>hat(ht)</em>. <em>Wz</em> and <em>Wr</em> are the weight parameters to be trained, <em>bz</em> and <em>br</em> are the noise vectors.</li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:87%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 637px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*g2SpGBfMnseHbMhs9f6kRQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*g2SpGBfMnseHbMhs9f6kRQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*g2SpGBfMnseHbMhs9f6kRQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*g2SpGBfMnseHbMhs9f6kRQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*g2SpGBfMnseHbMhs9f6kRQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*g2SpGBfMnseHbMhs9f6kRQ.png 1100w, https://miro.medium.com/v2/resize:fit:1274/format:webp/1*g2SpGBfMnseHbMhs9f6kRQ.png 1274w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 637px" srcset="https://miro.medium.com/v2/resize:fit:640/1*g2SpGBfMnseHbMhs9f6kRQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*g2SpGBfMnseHbMhs9f6kRQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*g2SpGBfMnseHbMhs9f6kRQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*g2SpGBfMnseHbMhs9f6kRQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*g2SpGBfMnseHbMhs9f6kRQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*g2SpGBfMnseHbMhs9f6kRQ.png 1100w, https://miro.medium.com/v2/resize:fit:1274/1*g2SpGBfMnseHbMhs9f6kRQ.png 1274w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/637/1*g2SpGBfMnseHbMhs9f6kRQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><strong>Update Gate: (Part 1) </strong>This part multiplies <em>rt</em> and <em>ht-1</em>. The multiplication means how much of ht-1 will be retained or ignored. This creates a temporal <em>hat(ht)</em> to be used for the update of <em>ht</em>. <em>Wh</em> and <em>bh</em> are weight parameters and the noise vectors.</li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:93%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 684px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*azAwOLpyqY16sA094T1YCA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*azAwOLpyqY16sA094T1YCA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*azAwOLpyqY16sA094T1YCA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*azAwOLpyqY16sA094T1YCA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*azAwOLpyqY16sA094T1YCA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*azAwOLpyqY16sA094T1YCA.png 1100w, https://miro.medium.com/v2/resize:fit:1368/format:webp/1*azAwOLpyqY16sA094T1YCA.png 1368w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 684px" srcset="https://miro.medium.com/v2/resize:fit:640/1*azAwOLpyqY16sA094T1YCA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*azAwOLpyqY16sA094T1YCA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*azAwOLpyqY16sA094T1YCA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*azAwOLpyqY16sA094T1YCA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*azAwOLpyqY16sA094T1YCA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*azAwOLpyqY16sA094T1YCA.png 1100w, https://miro.medium.com/v2/resize:fit:1368/1*azAwOLpyqY16sA094T1YCA.png 1368w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/684/1*azAwOLpyqY16sA094T1YCA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><strong>Update Grade: (Part II) </strong>This part computes the weighted average between <em>ht-1</em> and <em>hat(ht)</em>, according to the weight <em>zt</em>. If <em>zt</em> is close to zero, the past information contributes little and new information contributes more.</li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:91%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 668px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*3RDSLoEBhP1qsA9jlWjC6w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*3RDSLoEBhP1qsA9jlWjC6w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*3RDSLoEBhP1qsA9jlWjC6w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*3RDSLoEBhP1qsA9jlWjC6w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*3RDSLoEBhP1qsA9jlWjC6w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*3RDSLoEBhP1qsA9jlWjC6w.png 1100w, https://miro.medium.com/v2/resize:fit:1336/format:webp/1*3RDSLoEBhP1qsA9jlWjC6w.png 1336w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 668px" srcset="https://miro.medium.com/v2/resize:fit:640/1*3RDSLoEBhP1qsA9jlWjC6w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*3RDSLoEBhP1qsA9jlWjC6w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*3RDSLoEBhP1qsA9jlWjC6w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*3RDSLoEBhP1qsA9jlWjC6w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*3RDSLoEBhP1qsA9jlWjC6w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*3RDSLoEBhP1qsA9jlWjC6w.png 1100w, https://miro.medium.com/v2/resize:fit:1336/1*3RDSLoEBhP1qsA9jlWjC6w.png 1336w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/668/1*3RDSLoEBhP1qsA9jlWjC6w.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(L.2) GRU Code</strong></p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre>def GRU_model(X_train, y_train, X_test, sc):
    # create a model
    from keras.models import Sequential
    from keras.layers import Dense, SimpleRNN, GRU
    from keras.optimizers import SGD
    
    # The GRU architecture
    my_GRU_model = Sequential()
    # First GRU layer with Dropout regularisation
    my_GRU_model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))
    #my_GRU_model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))
    #my_GRU_model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))
    my_GRU_model.add(GRU(units=50, activation='tanh'))
    my_GRU_model.add(Dense(units=2))

    # Compiling the RNN
    my_GRU_model.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')
    # Fitting to the training set
    my_GRU_model.fit(X_train,y_train,epochs=50,batch_size=150, verbose=0)

    GRU_prediction = my_GRU_model.predict(X_test)
    GRU_prediction = sc.inverse_transform(GRU_prediction)

    return my_GRU_model, GRU_prediction

my_GRU_model, GRU_prediction = GRU_model(X_train, y_train, X_test, sc)
GRU_prediction[1:10]
actual_pred_plot(GRU_prediction) </pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:51%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 389px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*80oLrGJvo3Fe9a_UV_KFCQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*80oLrGJvo3Fe9a_UV_KFCQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*80oLrGJvo3Fe9a_UV_KFCQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*80oLrGJvo3Fe9a_UV_KFCQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*80oLrGJvo3Fe9a_UV_KFCQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*80oLrGJvo3Fe9a_UV_KFCQ.png 1100w, https://miro.medium.com/v2/resize:fit:778/format:webp/1*80oLrGJvo3Fe9a_UV_KFCQ.png 778w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 389px" srcset="https://miro.medium.com/v2/resize:fit:640/1*80oLrGJvo3Fe9a_UV_KFCQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*80oLrGJvo3Fe9a_UV_KFCQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*80oLrGJvo3Fe9a_UV_KFCQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*80oLrGJvo3Fe9a_UV_KFCQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*80oLrGJvo3Fe9a_UV_KFCQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*80oLrGJvo3Fe9a_UV_KFCQ.png 1100w, https://miro.medium.com/v2/resize:fit:778/1*80oLrGJvo3Fe9a_UV_KFCQ.png 778w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/389/1*80oLrGJvo3Fe9a_UV_KFCQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>(L.3) GRU with Regularization</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The following code applies the dropout technique to GRU. Because it is very similar to the above, I am not going to describe it too much. The MSE is 1,232.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre>def GRU_model_regularization(X_train, y_train, X_test, sc):
    '''
    create GRU model trained on X_train and y_train
    and make predictions on the X_test data
    '''
    # create a model
    from keras.models import Sequential
    from keras.layers import Dense, SimpleRNN, GRU
    from keras.optimizers import SGD
    from keras.layers import Dropout
    
    # The GRU architecture
    my_GRU_model = Sequential()
    # First GRU layer with Dropout regularisation
    my_GRU_model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1],1), activation='tanh'))
    my_GRU_model.add(Dropout(0.2))
    # Second GRU layer
    my_GRU_model.add(GRU(units=50, return_sequences=True, activation='tanh'))
    my_GRU_model.add(Dropout(0.2))
    
    # Third GRU layer
    my_GRU_model.add(GRU(units=50, return_sequences=True, activation='tanh'))
    my_GRU_model.add(Dropout(0.2))
    # Fourth GRU layer
    my_GRU_model.add(GRU(units=50, activation='tanh'))
    my_GRU_model.add(Dropout(0.2))
    # The output layer
    my_GRU_model.add(Dense(units=2))
    # Compiling the RNN
    my_GRU_model.compile(optimizer=SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False),loss='mean_squared_error')
    # Fitting to the training set
    my_GRU_model.fit(X_train,y_train,epochs=50,batch_size=150, verbose=0)

    GRU_predictions = my_GRU_model.predict(X_test)
    GRU_predictions = sc.inverse_transform(GRU_predictions)

    return my_GRU_model, GRU_predictions

my_GRU_model, GRU_predictions = GRU_model_regularization(X_train, y_train, X_test, sc)
GRU_predictions[1:10]
actual_pred_plot(GRU_prediction)  </pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:50%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 384px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*z22T7fUrHdioQROFYtv0xw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*z22T7fUrHdioQROFYtv0xw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*z22T7fUrHdioQROFYtv0xw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*z22T7fUrHdioQROFYtv0xw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*z22T7fUrHdioQROFYtv0xw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*z22T7fUrHdioQROFYtv0xw.png 1100w, https://miro.medium.com/v2/resize:fit:768/format:webp/1*z22T7fUrHdioQROFYtv0xw.png 768w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 384px" srcset="https://miro.medium.com/v2/resize:fit:640/1*z22T7fUrHdioQROFYtv0xw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*z22T7fUrHdioQROFYtv0xw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*z22T7fUrHdioQROFYtv0xw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*z22T7fUrHdioQROFYtv0xw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*z22T7fUrHdioQROFYtv0xw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*z22T7fUrHdioQROFYtv0xw.png 1100w, https://miro.medium.com/v2/resize:fit:768/1*z22T7fUrHdioQROFYtv0xw.png 768w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/384/1*z22T7fUrHdioQROFYtv0xw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>References</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">[1] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł. & Polosukhin, I. (2017). Attention is all you need. Advances in Neural Information Processing Systems (p./pp. 5998–6008)</li><li class="ff3" style="font-size:22px;">[2] Chien, C., & Chen, K.Y. (2022). A BERT-based Language Modeling Framework. <em>INTERSPEECH</em>.</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://dataman-ai.medium.com/membership"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">Join Medium with my referral link - Chris Kuo/Dr. Dataman</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">Read every story from Chris Kuo/Dr. Dataman. Your membership fee directly supports Chris Kuo/Dr. Dataman and other…</h3><p>dataman-ai.medium.com</p></a></div></div></div></div></section><br><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Readers are recommended to purchase books by Chris Kuo:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:74%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 548px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*UTx-k1Chh7jWG4Em.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*UTx-k1Chh7jWG4Em.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*UTx-k1Chh7jWG4Em.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*UTx-k1Chh7jWG4Em.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*UTx-k1Chh7jWG4Em.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*UTx-k1Chh7jWG4Em.png 1100w, https://miro.medium.com/v2/resize:fit:1096/format:webp/0*UTx-k1Chh7jWG4Em.png 1096w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 548px" srcset="https://miro.medium.com/v2/resize:fit:640/0*UTx-k1Chh7jWG4Em.png 640w, https://miro.medium.com/v2/resize:fit:720/0*UTx-k1Chh7jWG4Em.png 720w, https://miro.medium.com/v2/resize:fit:750/0*UTx-k1Chh7jWG4Em.png 750w, https://miro.medium.com/v2/resize:fit:786/0*UTx-k1Chh7jWG4Em.png 786w, https://miro.medium.com/v2/resize:fit:828/0*UTx-k1Chh7jWG4Em.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*UTx-k1Chh7jWG4Em.png 1100w, https://miro.medium.com/v2/resize:fit:1096/0*UTx-k1Chh7jWG4Em.png 1096w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/548/0*UTx-k1Chh7jWG4Em.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">The explainable AI: <a href="https://a.co/d/cNL8Hu4" target="_self">https://a.co/d/cNL8Hu4</a></li><li class="ff3" style="font-size:22px;">Transfer learning for image classification: <a href="https://a.co/d/hLdCkMH" target="_self">https://a.co/d/hLdCkMH</a></li><li class="ff3" style="font-size:22px;">Modern time series anomaly detection: <a href="https://a.co/d/ieIbAxM" target="_self">https://a.co/d/ieIbAxM</a></li><li class="ff3" style="font-size:22px;">Handbook of Anomaly Detection: <a href="https://a.co/d/5sKS8bI" target="_self">https://a.co/d/5sKS8bI</a></li></ul></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>