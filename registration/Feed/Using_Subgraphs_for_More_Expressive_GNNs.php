<!DOCTYPE html>
                <html>
                <head>
                    <title>Using Subgraphs for More Expressive GNNs</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://towardsdatascience.com/using-subgraphs-for-more-expressive-gnns-8d06418d5ab"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://michael-bronstein.medium.com/?source=post_page-----8d06418d5ab--------------------------------">Author : Michael Bronstein</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Improving GNNs</h4></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Using Subgraphs for More Expressive GNNs</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5 text-muted">The expressive power of Message-Passing Graph Neural Networks is inherently limited due to their equivalence to the Weisfeiler-Lehman graph isomorphism test. Several concurrent recent works show that this limitation can be overcome by applying a GNN on a collection of subgraphs obtained by removing nodes or edges from the input graph. In this post, we review the common themes and nuances of these different approaches.</h4></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*qUjmv71JpJ4EOhg2zg-IcQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*qUjmv71JpJ4EOhg2zg-IcQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*qUjmv71JpJ4EOhg2zg-IcQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*qUjmv71JpJ4EOhg2zg-IcQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*qUjmv71JpJ4EOhg2zg-IcQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*qUjmv71JpJ4EOhg2zg-IcQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qUjmv71JpJ4EOhg2zg-IcQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*qUjmv71JpJ4EOhg2zg-IcQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*qUjmv71JpJ4EOhg2zg-IcQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*qUjmv71JpJ4EOhg2zg-IcQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*qUjmv71JpJ4EOhg2zg-IcQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*qUjmv71JpJ4EOhg2zg-IcQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*qUjmv71JpJ4EOhg2zg-IcQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*qUjmv71JpJ4EOhg2zg-IcQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*qUjmv71JpJ4EOhg2zg-IcQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><em>This post was co-authored with Leonardo Cotta, Fabrizio Frasca, Haggai Maron, Christopher Morris, and Lingxiao Zhao. See also an </em><a href="https://medium.com/expressive-power-of-graph-neural-networks-and-the-weisefeiler-lehman-test-b883db3c7c49?sk=5c2a28ccd38db3a7b6f80f161e825a5a" target="_self">introduction to the Weisfeiler-Lehman test</a><em> and </em><a href="https://medium.com/beyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3?sk=bc0d14c28a380b4d51debc4935345b73" target="_self">structural encoding</a><em>.</em></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><span>M</span>essage-passing Graph Neural Networks (MPNNs) [1] consist of several layers performing node-wise aggregation of information from neighbour nodes. The appealing characteristic of such architectures is their <em>locality</em> (i.e., every computation requires only the immediate neighbours of a node) and <em>linear complexity</em> in the number of edges [2]. The drawback is however in their limited expressive power: it was shown in [3‚Äì4] that MPNNs are at most as expressive as the<a href="https://medium.com/expressive-power-of-graph-neural-networks-and-the-weisefeiler-lehman-test-b883db3c7c49?sk=5c2a28ccd38db3a7b6f80f161e825a5a" target="_self"> Weisfeiler-Lehman (WL) graph isomorphism test</a> [5], a classical method attempting to determine whether two graphs are structurally equivalent (‚Äúisomorphic‚Äù) by means of iterative colour refinement [6].</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The Weisfeiler-Lehman test is a <em>necessary</em> but <em>insufficient</em> condition: in fact, some non-isomorphic graphs might be indistinguishable [7]. One such example is shown in the following Figure:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*80lNqtywVhC_evI9l8TWZQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*80lNqtywVhC_evI9l8TWZQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*80lNqtywVhC_evI9l8TWZQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*80lNqtywVhC_evI9l8TWZQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*80lNqtywVhC_evI9l8TWZQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*80lNqtywVhC_evI9l8TWZQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*80lNqtywVhC_evI9l8TWZQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*80lNqtywVhC_evI9l8TWZQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*80lNqtywVhC_evI9l8TWZQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*80lNqtywVhC_evI9l8TWZQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*80lNqtywVhC_evI9l8TWZQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*80lNqtywVhC_evI9l8TWZQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*80lNqtywVhC_evI9l8TWZQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*80lNqtywVhC_evI9l8TWZQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*80lNqtywVhC_evI9l8TWZQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><em>The Weisfeiler-Lehman test is an iterative local colour refinement procedure attempting to determine whether two graphs are isomorphic. It outputs a histogram of colours providing a necessary but not sufficient condition for isomorphism: if the colour histograms are different, the graphs are not isomorphic, but the test can fail to distinguish non-isomorphic graphs, like the ones shown here, producing the same histogram.</em></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><span>In</span> graph theory, the graph isomorphism test originally introduced by <a href="https://en.wikipedia.org/wiki/Boris_Weisfeiler" target="_self">Boris Weisfeiler</a> and Andrei Lehman in the 1960s was extended in the late 1970s [8] to a hierarchy of increasingly more powerful higher-dimensional <em>k</em>-WL tests that operate on <em>k</em>-tuples of nodes. The authors of this post, Christopher Morris and Haggai Maron ‚Äî along with their coauthors ‚Äî showed different designs of higher-dimensional GNN architectures equivalent to <em>k</em>-WL tests [4, 9‚Äì10]; however, such models lose the advantage of locality and linear complexity of the standard message-passing GNN [11].</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">An alternative approach to increase the expressive power of GNNs is using positional encoding, which ‚Äúpre-colours‚Äù different nodes of the graph. Positional encoding is a key architectural feature of Transformers [12] and can be seen as a ‚Äúsymmetry-breaking‚Äù mechanism allowing Transformers to express permutation-sensitive functions. This is a necessary property e.g. in language modelling where such architectures have been particularly successful. However, this property is no longer desirable for graph-structured data, and permutation-sensitive positional encodings usually suffer from poor generalisation [13].</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><span>L</span>ooking for a permutation-invariant symmetry breaking mechanism, Giorgos Bouritsas and Fabrizio Frasca (Michael‚Äôs PhD students) introduced <a href="https://medium.com/beyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3?sk=bc0d14c28a380b4d51debc4935345b73" target="_self">Graph Substructure Networks</a> (GSN) based on local counts of small pre-defined substructures (triangles, cliques, cycles, etc) [14]. Appropriate structure choice makes such ‚Äústructural encoding‚Äù more expressive than the basic Weisfeiler-Lehman test or even higher-order <em>k</em>-WL tests [15].</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ZM0TDVAARNWbfm91MkhrZg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ZM0TDVAARNWbfm91MkhrZg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ZM0TDVAARNWbfm91MkhrZg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ZM0TDVAARNWbfm91MkhrZg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ZM0TDVAARNWbfm91MkhrZg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ZM0TDVAARNWbfm91MkhrZg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZM0TDVAARNWbfm91MkhrZg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*ZM0TDVAARNWbfm91MkhrZg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ZM0TDVAARNWbfm91MkhrZg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ZM0TDVAARNWbfm91MkhrZg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ZM0TDVAARNWbfm91MkhrZg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ZM0TDVAARNWbfm91MkhrZg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ZM0TDVAARNWbfm91MkhrZg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*ZM0TDVAARNWbfm91MkhrZg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*ZM0TDVAARNWbfm91MkhrZg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><em>GSNs employing structural encoding with triangle counting allows to disambiguate between the graphs in the above example (nodes belonging to one triangle are coloured in orange; triangles are shown in green).</em></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The advantage of the GSN model is that it is essentially the standard MPNN, augmented with additional node- or edge features (counts of the respective structures), and thus benefits from the locality and linear complexity of the message passing scheme. The higher complexity of detecting the local subgraphs is incurred as a pre-processing stage, which is often tolerable in some applications. While the worst-case cost of finding substructures of size <em>k</em> in a graph of <em>n</em> nodes is ùí™(<em>n·µè</em>), the practical runtime is significantly more optimistic.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Structural encoding highlights a simple idea underlying a class of methods discussed in this post, namely that <em>using a subgraph of the input graph may increase the expressive power of Graph Neural Networks</em>. Consider again our recurring example of a pair of WL-equivalent non-isomorphic graphs: it is possible to perturb these graphs (even minimally, e.g. by deleting a single edge, as shown in the following Figure) to make them distinguishable by the WL test.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*8hH1sBSX6CGfXrohEROqNg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*8hH1sBSX6CGfXrohEROqNg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*8hH1sBSX6CGfXrohEROqNg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*8hH1sBSX6CGfXrohEROqNg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*8hH1sBSX6CGfXrohEROqNg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*8hH1sBSX6CGfXrohEROqNg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8hH1sBSX6CGfXrohEROqNg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*8hH1sBSX6CGfXrohEROqNg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*8hH1sBSX6CGfXrohEROqNg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*8hH1sBSX6CGfXrohEROqNg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*8hH1sBSX6CGfXrohEROqNg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*8hH1sBSX6CGfXrohEROqNg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*8hH1sBSX6CGfXrohEROqNg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*8hH1sBSX6CGfXrohEROqNg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*8hH1sBSX6CGfXrohEROqNg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><em>Two graphs from the previous example become distinguishable by the Weisfeiler-Lehman test by an edge removal (dotted red). This observation serves as the rationale for several expressive GNN architectures working on collections of subgraphs.</em></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><span>S</span>everal concurrent recent works used this approach to design efficient expressive Graph Neural Network architectures. These models, to which we collectively refer as ‚ÄúSubgraph GNNs‚Äù mainly differ in their rationale, the manner in which subgraphs are produced, and the method of aggregating the outputs from different subgraphs. We review some of these works in this post.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Dropout GNNs </strong>[16]<strong> </strong>introduced by the ETH Zurich<a href="https://disco.ethz.ch/" target="_self"> Distributed Computing group</a> take this idea literally by applying <em>node dropout</em> to the graph (a node is removed with probability <em>p </em>independently of other nodes) and then running a standard multi-layer GNN. Repeating the process multiple times, different subgraph embeddings are obtained; they are then aggregated in a permutation-invariant manner. In so doing, every node ‚Äúsees‚Äù a slightly different neighbourhood, often resolving ambiguities leading to the failure of the Weisfeiler-Lehman test. This might also explain why dropout-type regularisation techniques for graphs such as DropEdge [17] tend to work well.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*56G1EmEM-Hk7SNwbwbEqaQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*56G1EmEM-Hk7SNwbwbEqaQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*56G1EmEM-Hk7SNwbwbEqaQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*56G1EmEM-Hk7SNwbwbEqaQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*56G1EmEM-Hk7SNwbwbEqaQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*56G1EmEM-Hk7SNwbwbEqaQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*56G1EmEM-Hk7SNwbwbEqaQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*56G1EmEM-Hk7SNwbwbEqaQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*56G1EmEM-Hk7SNwbwbEqaQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*56G1EmEM-Hk7SNwbwbEqaQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*56G1EmEM-Hk7SNwbwbEqaQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*56G1EmEM-Hk7SNwbwbEqaQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*56G1EmEM-Hk7SNwbwbEqaQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*56G1EmEM-Hk7SNwbwbEqaQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*56G1EmEM-Hk7SNwbwbEqaQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><em>Example of node dropout in a graph (dropped nodes are marked in red and do not participate in message passing). The fact that every node sees a set of slightly perturbed versions of its neighbourhood over multiple runs leads to a greater expressive power of Dropout GNNs compared to the WL test.</em></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Reconstruction GNNs </strong>[18] is a recent work by authors of this post Leonardo Cotta and Christopher Morris with Bruno Ribeiro, proposing a new architecture based on the<a href="https://en.wikipedia.org/wiki/Reconstruction_conjecture" target="_self"> Graph Reconstruction Conjecture</a>. The Reconstruction Conjecture is a set of results in graph theory dating back to the 1940s work of<a href="https://en.wikipedia.org/wiki/Paul_Kelly_%28mathematician%29" target="_self"> Paul Joseph Kelly</a> and<a href="https://en.wikipedia.org/wiki/Stanislaw_Ulam" target="_self"> Stanis≈Çaw Ulam</a><strong> </strong>[19] postulating the possibility of recovering a graph from the collection of all its node-deleted subgraphs [20]. While reconstructability can be shown for certain families of graphs, the general result was verified by exhaustive search only for graphs of size <em>n‚â§</em>11 nodes [21], and whether it holds for larger <em>n</em> is currently an open question.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*LcRuzZHk8HUtmQEbg4BLdA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*LcRuzZHk8HUtmQEbg4BLdA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*LcRuzZHk8HUtmQEbg4BLdA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*LcRuzZHk8HUtmQEbg4BLdA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*LcRuzZHk8HUtmQEbg4BLdA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*LcRuzZHk8HUtmQEbg4BLdA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LcRuzZHk8HUtmQEbg4BLdA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*LcRuzZHk8HUtmQEbg4BLdA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*LcRuzZHk8HUtmQEbg4BLdA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*LcRuzZHk8HUtmQEbg4BLdA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*LcRuzZHk8HUtmQEbg4BLdA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*LcRuzZHk8HUtmQEbg4BLdA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*LcRuzZHk8HUtmQEbg4BLdA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*LcRuzZHk8HUtmQEbg4BLdA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*LcRuzZHk8HUtmQEbg4BLdA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><em>A graph and the collection of its node-removed subgraphs. Subgraphs 1,3,4,6 and 2,5 are isomorphic.</em></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In follow-up work published a decade later, Kelly considered a more general setting of reconstructing from k-size subgraphs[22]<em>. </em>Unfortunately, there is not much we can say about reconstruction for a fixed size k. Instead, typical results on <em>k</em>-reconstruction try to express the smallest necessary subgraph size <em>k</em> as a function of its number of nodes <em>n</em>;<em> k</em>-reconstructability was shown for certain families of graphs such as trees and multipartite graphs [23].</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>k-Reconstruction GNNs </strong>proposed in [18] apply a standard MPNN to each of the induced subgraphs of size <em>k</em> and sum the resulting embeddings (which is a permutation-invariant function used in DeepSets [24]). Since there might be too many such subgraphs [25], sampling must be used (which occurs in the same procedure of Dropout GNNs). It is worth noting that in 1990 <a href="https://en.wikipedia.org/wiki/B%C3%A9la_Bollob%C3%A1s" target="_self">B√©la Bollob√°s</a> proved how almost every graph can be reconstructed only with three (<em>n</em><strong>‚àí</strong>1)-size subgraphs [26]. This result provides insights into why randomly subsampling subgraphs does not seem to harm <em>k-</em>Reconstruction GNNs empirical results [27].</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The <em>k</em>-Reconstruction GNN with <em>k</em>=<em>n</em><strong>‚àí</strong>1 can distinguish families of non-isomorphic graphs that standard GNNs cannot, like the Circular Skip Link graphs shown in the following figure:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*nbbqp981fvSc1je9 640w, https://miro.medium.com/v2/resize:fit:720/0*nbbqp981fvSc1je9 720w, https://miro.medium.com/v2/resize:fit:750/0*nbbqp981fvSc1je9 750w, https://miro.medium.com/v2/resize:fit:786/0*nbbqp981fvSc1je9 786w, https://miro.medium.com/v2/resize:fit:828/0*nbbqp981fvSc1je9 828w, https://miro.medium.com/v2/resize:fit:1100/0*nbbqp981fvSc1je9 1100w, https://miro.medium.com/v2/resize:fit:1400/0*nbbqp981fvSc1je9 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*nbbqp981fvSc1je9 640w, https://miro.medium.com/v2/resize:fit:720/0*nbbqp981fvSc1je9 720w, https://miro.medium.com/v2/resize:fit:750/0*nbbqp981fvSc1je9 750w, https://miro.medium.com/v2/resize:fit:786/0*nbbqp981fvSc1je9 786w, https://miro.medium.com/v2/resize:fit:828/0*nbbqp981fvSc1je9 828w, https://miro.medium.com/v2/resize:fit:1100/0*nbbqp981fvSc1je9 1100w, https://miro.medium.com/v2/resize:fit:1400/0*nbbqp981fvSc1je9 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*nbbqp981fvSc1je9"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><em>Circular Skip Link graphs are an example of non-isomorphic regular graphs indistinguishable by the WL test (and thus standard Message-Passing GNNs) yet distinguishable by k-Reconstruction GNNs.</em></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">At the same time, for sufficiently small <em>k‚Äô</em>s [28], there exist graphs distinguishable by GNNs but not by <em>k</em>-Reconstruction GNNs. Conversely, an (<em>n</em><strong>‚àí</strong>2)-Reconstruction GNN can distinguish strongly regular graphs that neither (<em>n</em><strong>‚àí</strong>1)-Reconstruction GNN nor standard MPNN (‚Äú<em>n</em>-Reconstruction GNNs‚Äù) can. This is a somewhat disappointing conclusion: while by analogy to the <em>k</em>-WL tests one might expect a hierarchy of expressive power between GNNs, (<em>n</em><strong>‚àí</strong>1)-Reconstruction GNNs, (<em>n</em>‚àí2)-Reconstruction GNNs and so on, there is no such hierarchy.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><mark>From Stars to Subgraphs </mark><mark>proposed in</mark><mark> </mark><mark>[29] is another recent work co-authored by Lingxiao Zhao that uses </mark><mark>rooted subgraphs</mark><mark> to improve the expressive power of GNNs.</mark> A way to look at the WL test is as a local colour refinement via a star pattern (relabeling a node based on its neighbours‚Äô colours and its own colour, which uniquely characterises a rooted star). An extension of the star pattern to general rooted subgraphs such as egonets [30] leads to a new subgraph-based variant of the Weisfeiler-Lehman algorithm, dubbed ‚ÄúSubgraph-1-WL‚Äù. Since the number of rooted subgraphs is the same as the number of nodes in the graph, for a constant <em>k</em> this method scales linearly with the size of the graph.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*9BUnrKcMJ5pTQ1av 640w, https://miro.medium.com/v2/resize:fit:720/0*9BUnrKcMJ5pTQ1av 720w, https://miro.medium.com/v2/resize:fit:750/0*9BUnrKcMJ5pTQ1av 750w, https://miro.medium.com/v2/resize:fit:786/0*9BUnrKcMJ5pTQ1av 786w, https://miro.medium.com/v2/resize:fit:828/0*9BUnrKcMJ5pTQ1av 828w, https://miro.medium.com/v2/resize:fit:1100/0*9BUnrKcMJ5pTQ1av 1100w, https://miro.medium.com/v2/resize:fit:1400/0*9BUnrKcMJ5pTQ1av 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*9BUnrKcMJ5pTQ1av 640w, https://miro.medium.com/v2/resize:fit:720/0*9BUnrKcMJ5pTQ1av 720w, https://miro.medium.com/v2/resize:fit:750/0*9BUnrKcMJ5pTQ1av 750w, https://miro.medium.com/v2/resize:fit:786/0*9BUnrKcMJ5pTQ1av 786w, https://miro.medium.com/v2/resize:fit:828/0*9BUnrKcMJ5pTQ1av 828w, https://miro.medium.com/v2/resize:fit:1100/0*9BUnrKcMJ5pTQ1av 1100w, https://miro.medium.com/v2/resize:fit:1400/0*9BUnrKcMJ5pTQ1av 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*9BUnrKcMJ5pTQ1av"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><em>Star (left) and 1-ego subgraph (right) rooted at the red node.</em></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Subgraph-1-WL is strictly more powerful than WL and not less powerful than 3-WL (in the sense that there exist non-isomorphic graphs that 3-WL cannot distinguish but Subgraph-1-WL can). When using too small rooted subgraphs (<em>k</em>-egonet of size <em>k</em>‚â§4), Subgraph-1-WL cannot distinguish a family of CFI(<em>m</em>) graphs [31] for any m‚â•3, which is also known to be indistinguishable by <em>m</em>-WL.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*TWrXBTLhrqasTkVy 640w, https://miro.medium.com/v2/resize:fit:720/0*TWrXBTLhrqasTkVy 720w, https://miro.medium.com/v2/resize:fit:750/0*TWrXBTLhrqasTkVy 750w, https://miro.medium.com/v2/resize:fit:786/0*TWrXBTLhrqasTkVy 786w, https://miro.medium.com/v2/resize:fit:828/0*TWrXBTLhrqasTkVy 828w, https://miro.medium.com/v2/resize:fit:1100/0*TWrXBTLhrqasTkVy 1100w, https://miro.medium.com/v2/resize:fit:1400/0*TWrXBTLhrqasTkVy 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*TWrXBTLhrqasTkVy 640w, https://miro.medium.com/v2/resize:fit:720/0*TWrXBTLhrqasTkVy 720w, https://miro.medium.com/v2/resize:fit:750/0*TWrXBTLhrqasTkVy 750w, https://miro.medium.com/v2/resize:fit:786/0*TWrXBTLhrqasTkVy 786w, https://miro.medium.com/v2/resize:fit:828/0*TWrXBTLhrqasTkVy 828w, https://miro.medium.com/v2/resize:fit:1100/0*TWrXBTLhrqasTkVy 1100w, https://miro.medium.com/v2/resize:fit:1400/0*TWrXBTLhrqasTkVy 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*TWrXBTLhrqasTkVy"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><em>Example of two non-isomorphic strongly regular graphs that cannot be distinguished by 3-WL but can be distinguished by Subgraph-1-WL</em> <em>(two subgraphs allowing to make this distinction are highlighted).</em></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A neural version of the Subgraph-1-WL algorithm encodes each rooted subgraph with a standard MPNN; the resulting node-wise representations are then aggregated. An important difference compared to Dropout GNNs [16] and Reconstruction GNNs [18] is the use of <em>cross-subgraph aggregation</em>, which pools together node representations for the same node from multiple subgraphs by leveraging subgraph alignment (we will see that this pooling mechanism can be derived from first principles when considering a more precise definition of symmetry group for a set of subgraphs). Additionally, a subgraph dropout method is used to reduce the scalability overhead without sacrificing performance by randomly dropping some subgraphs during training while keeping all subgraphs during testing.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Equivariant Subgraph Aggregation Networks (ESAN) </strong>[32] is an architecture equivariant to the symmetry structure of the multiset of subgraphs, proposed in a recent paper by Fabrizio Frasca, Michael Bronstein, Haggai Maron, and their coauthors. Multisets of subgraphs are highly-structured objects whose symmetry arises from both the structure of each constituent subgraph as well as the multiset as the whole. The principle of equivariance requires that changing the order of <em>m</em> subgraphs in the multiset (permutation group Œ£<em>‚Çò</em>) and the order of the nodes in the subgraphs (permutation group Œ£<em>‚Çô</em>) yields an equivalent representation, or in other words, the architecture is equivariant w.r.t. the <em>product group</em> Œ£=Œ£<em>‚Çò</em>√óŒ£<em>‚Çô</em>. Differently from [16,18], this symmetry group formulation takes into account the fact that the subgraphs are <em>aligned</em>, such that the same permutation acts on the nodes of all the subgraphs (as opposed to individual node permutations acting on each subgraph separately).</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*eiQ7f84bz2KYdzHZ 640w, https://miro.medium.com/v2/resize:fit:720/0*eiQ7f84bz2KYdzHZ 720w, https://miro.medium.com/v2/resize:fit:750/0*eiQ7f84bz2KYdzHZ 750w, https://miro.medium.com/v2/resize:fit:786/0*eiQ7f84bz2KYdzHZ 786w, https://miro.medium.com/v2/resize:fit:828/0*eiQ7f84bz2KYdzHZ 828w, https://miro.medium.com/v2/resize:fit:1100/0*eiQ7f84bz2KYdzHZ 1100w, https://miro.medium.com/v2/resize:fit:1400/0*eiQ7f84bz2KYdzHZ 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*eiQ7f84bz2KYdzHZ 640w, https://miro.medium.com/v2/resize:fit:720/0*eiQ7f84bz2KYdzHZ 720w, https://miro.medium.com/v2/resize:fit:750/0*eiQ7f84bz2KYdzHZ 750w, https://miro.medium.com/v2/resize:fit:786/0*eiQ7f84bz2KYdzHZ 786w, https://miro.medium.com/v2/resize:fit:828/0*eiQ7f84bz2KYdzHZ 828w, https://miro.medium.com/v2/resize:fit:1100/0*eiQ7f84bz2KYdzHZ 1100w, https://miro.medium.com/v2/resize:fit:1400/0*eiQ7f84bz2KYdzHZ 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*eiQ7f84bz2KYdzHZ"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><em>The symmetry group of a multiset of subgraphs is a product of the permutation of the subgraphs (green) and the order of the nodes (orange).</em></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">ESAN is an instance of the ‚ÄúDeep Sets of Symmetric Objects‚Äù (DSS) architecture [33] and employs two base graph encoders: The first encoder is a siamese network processing each subgraph independently; the second one acts as an <em>information-sharing</em> module by processing the aggregation of the subgraphs. Following several such layers, the obtained subgraph representations are aggregated by a set-learning module to form an invariant representation of the original graph that is used in downstream tasks.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*qvfxkZakG4ETAErn 640w, https://miro.medium.com/v2/resize:fit:720/0*qvfxkZakG4ETAErn 720w, https://miro.medium.com/v2/resize:fit:750/0*qvfxkZakG4ETAErn 750w, https://miro.medium.com/v2/resize:fit:786/0*qvfxkZakG4ETAErn 786w, https://miro.medium.com/v2/resize:fit:828/0*qvfxkZakG4ETAErn 828w, https://miro.medium.com/v2/resize:fit:1100/0*qvfxkZakG4ETAErn 1100w, https://miro.medium.com/v2/resize:fit:1400/0*qvfxkZakG4ETAErn 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*qvfxkZakG4ETAErn 640w, https://miro.medium.com/v2/resize:fit:720/0*qvfxkZakG4ETAErn 720w, https://miro.medium.com/v2/resize:fit:750/0*qvfxkZakG4ETAErn 750w, https://miro.medium.com/v2/resize:fit:786/0*qvfxkZakG4ETAErn 786w, https://miro.medium.com/v2/resize:fit:828/0*qvfxkZakG4ETAErn 828w, https://miro.medium.com/v2/resize:fit:1100/0*qvfxkZakG4ETAErn 1100w, https://miro.medium.com/v2/resize:fit:1400/0*qvfxkZakG4ETAErn 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*qvfxkZakG4ETAErn"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><em>ESAN equivariant layers are constructed from a siamese network (encoder 1, orange) and an information-sharing module (encoder 2, yellow).</em></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Dropout GNNs [16] and Reconstruction GNNs [18] can be seen as special instances of ESAN using only the first encoder [34]. Furthermore, the second encoder is a generalisation of the cross-graph aggregation used in [29] and its addition is beneficial for the performance of the graph classification task [35]. Finally, ESAN considers the possibility of other <em>subgraph selection policies </em>(functions ùúã(<em>G</em>) that map an input graph <em>G</em> to a set of its subgraphs) beyond simple node deletion or egonets.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Significant part of the paper is dedicated to the analysis of the expressive power of ESAN‚Äìwhich gives rise to a new variant of the Weisfeiler-Lehman test dubbed ‚ÄúDSS-WL‚Äù‚Äìwith different architectural and subgraph selection policies. One of the conclusions is that ESAN architecture can distinguish 3-WL equivalent graphs using only a WL graph encoder (standard MPNN) and that it can enhance the expressive power of stronger architectures.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><span>It</span> has been previously argued that in order to design more powerful Graph Neural Networks that go beyond the expressivity of the Weisfeiler-Lehman test, one has to abandon the Message Passing paradigm. The emergence of recent GNN architectures based on subgraphs shows a cheap solution to this problem while still remaining within the remit of Message Passing [36].</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In addition to the increase in expressiveness, it appears that Subgraph GNNs have a lower-variance risk estimator when compared to standard GNNs in some graph ML tasks such as graph classification. These tasks are in essence invariant to (a few) node removals [37], and subgraph-based techniques reviewed in this post can be understood as a form of data augmentation.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[1] J. Gilmer et al.,<a href="https://arxiv.org/abs/1704.01212" target="_self"> Neural message passing for quantum chemistry</a> (2017). Proc. ICML.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[2] ‚ÄúLinear complexity‚Äù in the context of GNNs usually refers to algorithms that scale as ùí™(<em>n</em>) in the number of <em>nodes</em>. While the number of edges in the worst case can be ùí™(<em>n</em>¬≤), it is common to assume that the graph is sparse, in which case the number of edges is ùí™(<em>n</em>).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[3] K. Xu et al.,<a href="https://arxiv.org/abs/1810.00826" target="_self"> How powerful are graph neural networks?</a> (2019) ICLR.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[4] C. Morris et al.,<a href="https://aaai.org/ojs/index.php/AAAI/article/view/4384/4262" target="_self"> Weisfeiler and Leman go neural: Higher-order graph neural networks</a> (2019) AAAI.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[5] B. Weisfeiler, A. Lehman,<a href="https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf" target="_self"> The reduction of a graph to canonical form and the algebra which appears therein</a> (1968) Nauchno-Technicheskaya Informatsia 2(9):12‚Äì16.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[6] ‚ÄúColour‚Äù in this context is understood as a node-wise discrete label.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[7] Regular graphs in which each vertex has the same number of neighbours (i.e., equal degree) are an example of a family indistinguishable by the standard WL test. To fail a higher dimensional <em>k</em>-WL, more regularity is needed: a typical example in this case is the family of <em>k</em>-isoregular graphs.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[8] L√°szl√≥ Babai credits the invention of the <em>k</em>-WL tests to himself with <a href="https://www.cs.toronto.edu/dcs/people-faculty-combin.html" target="_self">Rudolf Mathon</a> and independently, <a href="https://en.wikipedia.org/wiki/Neil_Immerman" target="_self">Neil Immerman</a> and <a href="https://en.wikipedia.org/wiki/Eric_Lander" target="_self">Eric Lander</a> (the latter was trained as a mathematician but is more broadly known for his works in genomics and biology and also as the current Science Advisor in the Biden administration). See L. Babai, <a href="https://arxiv.org/abs/1512.03547" target="_self">Graph isomorphism in quasipolynomial time</a> (2015), arXiv:1512.03547 p. 27.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[9] H. Maron et al., <a href="https://arxiv.org/abs/1812.09902" target="_self">Invariant and equivariant graph networks</a> (2019) ICLR.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[10] H. Maron et al., <a href="https://arxiv.org/abs/1905.11136" target="_self">Provably powerful graph neural networks</a> (2019) NeurIPS. See also a <a href="http://irregulardeep.org/How-expressive-are-Invariant-Graph-Networks-%282-2%29/" target="_self">blog post</a> of the authors.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[11] The <em>k</em>-GNN architecture introduced by Morris in [4] incurs ùí™(<em>n·µè</em>) memory complexity. In a follow-up work, C. Morris et al., <a href="https://papers.nips.cc/paper/2020/hash/f81dee42585b3814de199b2e88757f5c-Abstract.html" target="_self">Weisfeiler and Leman go sparse: Towards scalable higher-order</a> (2020) NeurIPS 2020 also devised a local version of <em>k</em>-GNNs based on aggregation in local neighbourhoods [32], taking the sparsity of the underlying graph into account and showed that this local version has at least the same power as the ordinary <em>k</em>-WL. Invariant Graph Networks (IGN) introduced by Maron in [9] are based on <em>k</em>-order tensors and are <em>k</em>-WL-equivalent. IGNs are derived from a different variant of <em>k</em>-WL and are more advantageous in terms of their complexity compared to <em>k</em>-GNNs. In particular, the 3-WL-equivalent IGN has ‚Äúonly‚Äù quadratic complexity.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[12] A. Vaswani et al., <a href="https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" target="_self">Attention is all you need</a> (2017) NIPS.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[13] For a more detailed analysis of positional encoding in GNNs, see e.g. A. Loukas, <a href="https://static.aminer.cn/upload/pdf/program/5e5e18a093d709897ce21291_0.pdf" target="_self">What graph neural networks cannot learn: depth vs width</a> (2020) ICLR; ICLR‚Äô20, R. Sato et al., <a href="https://arxiv.org/abs/2002.03155" target="_self">Random features strengthen graph neural networks</a> (2021) SDM; R. Abboud et al., <a href="https://www.ijcai.org/proceedings/2021/0291.pdf" target="_self">The surprising power of graph neural networks with random node initialization</a> (2020), IJCAI.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[14] G. Bouritsas et al., <a href="https://arxiv.org/abs/2006.09252" target="_self">Improving graph neural network expressivity via subgraph isomorphism counting</a> (2020) arXiv:2006.09252; see an accompanying<a href="https://medium.com/beyond-weisfeiler-lehman-using-substructures-for-provably-expressive-graph-neural-networks-d476ad665fa3?sk=bc0d14c28a380b4d51debc4935345b73" target="_self"> post</a>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[15] The expressivity class of Graph Substructure Networks [14] does not follow the standard <em>k</em>-WL hierarchy. The analysis in the paper shows that GSN is at least as expressive at WL (i.e., can distinguish all the graphs that WL can distinguish) and in addition, can distinguish some non-isomorphic graphs on which WL fails. For higher-dimensional <em>k</em>-WL tests, examples of graphs indistinguishable by <em>k</em>-WL but distinguishable by GSN with a right substructure are shown, however, the exact class of graphs GSNs can distinguish is unknown. If the Reconstruction Conjecture holds, then GSN is maximally expressive.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[16] P. A. Papp et al., <a href="https://arxiv.org/pdf/2111.06283.pdf" target="_self">DropGNN: Random dropouts increase the expressiveness of Graph Neural Networks</a> (2021) arXiv:2111.06283.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[17] Y. Rong et al., <a href="https://openreview.net/pdf?id=Hkx1qkrKPr" target="_self">DropEdge: Towards deep graph convolutional networks on node classification</a> (2020) ICLR is a typical dropout method for graphs, motivated mainly by the desire to design deeper GNNs (see also the post about<a href="https://medium.com/do-we-need-deep-graph-neural-networks-be62d3ec5c59?sk=8daa06935676e78bdb229017d3c4bac9" target="_self"> deep GNNs</a>). In general, stochastic subgraph selection presents a potential problem since the output of the network is not permutation-invariant. Nevertheless, this seems not to result in any considerable performance degradation in the reported experimental results.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[18] L. Cotta et al., <a href="https://proceedings.neurips.cc/paper/2021/file/0d8080853a54f8985276b0130266a657-Paper.pdf" target="_self">Reconstruction for powerful graph representations</a> (2021) NeurIPS.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[19] The Reconstruction Conjecture first appeared in the PhD thesis of P. J. Kelly, On isometric transformations (1942), which he carried out at the University of Wisconsin‚ÄìMadison under the supervision of the <a href="https://en.wikipedia.org/wiki/History_of_the_Teller%E2%80%93Ulam_design" target="_self">father of the thermonuclear bomb</a>, Stanis≈Çaw Ulam. See J. A. Bondy, A graph reconstructor‚Äôs manual (1991) Surveys in Combinatorics 166:221‚Äì252 for a comprehensive review of graph reconstruction results.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[20] In the context of the Reconstruction Conjecture, individual subgraphs are called ‚Äúcards‚Äù (each card is of size <em>n</em><strong>‚àí</strong>1) and their collection a ‚Äúdeck‚Äù. Since the subgraphs in the deck are given up to isomorphism class, the deck is a multiset (a set where each element can appear more than once). A graph <em>H</em> is said to be a <em>reconstruction</em> of <em>G</em> if they have the same deck (denoted <em>H</em>~<em>G</em>). <em>G</em> is <em>reconstructible</em> if every its reconstruction is isomorphic to <em>G</em> itself (i.e., <em>H</em>~<em>G </em>implies <em>H</em>‚âÉ<em>G</em>). The Reconstruction Conjecture states that if <em>G</em> and <em>H</em> are two finite, undirected, simple graphs with at least three vertices and <em>H</em> is the reconstruction of <em>G</em>, then <em>H</em>‚âÉ<em>G</em>. Interestingly, directed graphs, hypergraphs, and infinite graphs are not reconstructible.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[21] B. D. McKay, <a href="https://ajc.maths.uq.edu.au/pdf/15/ocr-ajc-v15-p123.pdf" target="_self">Small graphs are reconstructible</a> (1997) Australasian J. Combinatorics 15:123‚Äì126.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[22] P. J. Kelly, <a href="https://projecteuclid.org/download/pdf_1/euclid.pjm/1103043674" target="_self">A congruence theorem for trees</a> (1957) Pacific J. Math. 7:961‚Äì968 extends the reconstruction results to smaller subgraphs of size <em>k</em>. The original reconstruction result is thus a special case with <em>k</em>=<em>n</em><strong>‚àí</strong>1.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[23] V. N√Ωdl, <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.109.7459&rep=rep1&type=pdf" target="_self">Graph reconstruction from subgraphs</a> (2001) Discrete Mathematics 235(1‚Äì3):335‚Äì341.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[24] M. Zaheer et al., <a href="https://papers.nips.cc/paper/2017/file/f22e4747da1aa27e363d86d40ff442fe-Paper.pdf" target="_self">Deep Sets</a> (2017), NIPS.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[25] There are precisely <em>n</em>!/(<em>k</em>!(<em>n</em><strong>‚àí</strong><em>k</em>)!) subgraphs of size <em>k</em> in a graph of size <em>n</em>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[26] B. Bollob√°s, Almost every graph has reconstruction number three (1990) Journal of Graph Theory 14(1):1‚Äì4.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[27] See the Supplement of [18].</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[28] Proposition 2 in [18] is shown for <em>k</em>‚â§‚åà<em>n</em>/2‚åâ.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[29] L. Zhao et al., <a href="https://arxiv.org/pdf/2110.03753.pdf" target="_self">From stars to subgraphs: Uplifting any GNN with local structure awareness</a> (2021) arXiv:2110.03753.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[30] A <em>k</em>-egonet of a node is its <em>k</em>-hop neighbourhood with the induced connectivity.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[31] CFI graphs are named after the initials of J.-Y. Cai, M. F√ºrer, and N. Immerman, <a href="https://people.cs.umass.edu/~immerman/pub/opt.pdf" target="_self">An optimal lower bound on the number of variables for graph identification</a> (1992) Combinatorica 12(4):389‚Äì410.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[32] B. Bevilacqua et al., <a href="https://arxiv.org/abs/2110.02910" target="_self">Equivariant Subgraph Aggregation Networks</a> (2021) arXiv:2110.02910. See a <a href="https://www.youtube.com/watch?v=voMue3G-_vk" target="_self">video</a> of the paper presentation by the lead authors.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[33] Equivariant architectures for ‚Äúcompound‚Äù objects such as sets of objects having their own internal symmetries (Deep Sets of Symmetric Objects, or DSS) were previously considered by H. Maron et al., <a href="https://arxiv.org/abs/2002.08599" target="_self">On learning sets of symmetric elements</a> (2020) ICML.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[34] The siamese networks used in Dropout GNN [16] and Reconstruction GNN [18] can be derived from a larger symmetry group that uses a different notion of group product called the <a href="https://en.wikipedia.org/wiki/Wreath_product" target="_self">wreath-product</a>, see R. Wang et al., <a href="https://arxiv.org/pdf/2006.03627.pdf" target="_self">Equivariant maps for hierarchical structures</a> (2020) arXiv:2006.03627.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[35] The use of the information sharing module is shown in [32] to improve the base encoder‚Äôs performance in 91% of the cases compared to 75% when using only the siamese network.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[36] Our review is by far not exhaustive, and several additional concurrent works have explored similar ideas, see e.g. M. Zhang and P. Li, <a href="https://arxiv.org/pdf/2110.13197.pdf" target="_self">Nested Graph Neural Networks</a> (2021) arXiv:2110.13197; D. Sandfelder et al., E<a href="https://arxiv.org/pdf/2107.10957.pdf" target="_self">go-GNNs: Exploiting ego structures in graph neural networks</a> (2021) arXiv:2107.10957; and E. H. Thiede et al. <a href="https://arxiv.org/pdf/2103.01710.pdf" target="_self">Autobahn: Automorphism-based graph neural nets</a> (2021) NeurIPS.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">[37] This was shown in [18] for <em>k</em>-Reconstruction GNNs, which are a special case of ESAN.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><em>We are grateful to Cristian Bodnar and Giorgos Bouritsas for proofreading this post and providing insightful feedback. For additional reading on Graph Neural Networks, see Michael‚Äôs blog on </em><a href="https://towardsdatascience.com/graph-deep-learning/home" target="_self">Towards Data Science</a><em>, </em><a href="https://michael-bronstein.medium.com/subscribe" target="_self">subscribe</a><em> to his posts and </em><a href="https://www.youtube.com/c/MichaelBronsteinGDL" target="_self">YouTube channel</a><em>, get</em><a href="https://michael-bronstein.medium.com/membership" target="_self"> Medium membership</a>, <em>and follow</em><a href="https://twitter.com/mmbronstein" target="_self"> Michael</a><em>,</em><a href="https://twitter.com/cottascience" target="_self"> Leonardo</a><em>, </em><a href="https://twitter.com/ffabffrasca" target="_self">Fabrizio</a><em>,</em><a href="https://twitter.com/HaggaiMaron" target="_self"> Haggai</a><em>, and </em><a href="https://twitter.com/chrsmrrs" target="_self">Christopher</a><em> on Twitter.</em></p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>