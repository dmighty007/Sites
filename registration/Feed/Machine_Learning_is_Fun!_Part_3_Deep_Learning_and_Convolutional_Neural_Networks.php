<!DOCTYPE html>
                <html>
                <head>
                    <title>Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@ageitgey?source=post_page-----f40359318721--------------------------------">Author : Adam Geitgey</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Update:</strong><em> This article is part of a series. Check out the full series: </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471" target="_self">Part 1</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3" target="_self">Part 2</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721" target="_self">Part 3</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78" target="_self">Part 4</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa" target="_self">Part 5</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a" target="_self">Part 6</a><em>, </em><a href="https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7" target="_self">Part 7</a><em> and </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-8-how-to-intentionally-trick-neural-networks-b55da32b7196" target="_self">Part 8</a><em>! You can also read this article in </em><a href="https://zhuanlan.zhihu.com/p/24524583" target="_self">普通话</a><em>, </em><a href="http://algotravelling.com/ru/%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D1%8D%D1%82%D0%BE-%D0%B2%D0%B5%D1%81%D0%B5%D0%BB%D0%BE-3/" target="_self">Русский</a><em>, </em><a href="https://medium.com/@jongdae.lim/기계-학습-machine-learning-은-즐겁다-part-3-928a841a3aa" target="_self">한국어</a><em>, </em><a href="https://medium.com/machina-sapiens/aprendizagem-de-máquina-é-divertido-parte-3-deep-learning-e-redes-neuronais-convolutivas-879e0ee7ba48" target="_self">Português</a><em>, </em><a href="https://viblo.asia/p/machine-learning-that-thu-vi-3-tim-kiem-anh-chua-chim-vyDZOX1xlwj" target="_self">Tiếng Việt</a><em>, </em><a href="https://shahaab-co.ir/mag/edu/ml/machine-learning-is-fun-part-3/" target="_self">فارسی</a> <em>or </em><a href="https://medium.com/botsupply/il-machine-learning-è-divertente-parte-3-deep-learning-e-convolutional-neural-network-cnns-cc106559ffa9" target="_self">Italiano</a><em>.</em></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Giant update:</strong><em> </em><a href="https://www.machinelearningisfun.com/get-the-book/" target="_self">I’ve written a new book based on these articles</a><em>! It not only expands and updates all my articles, but it has tons of brand new content and lots of hands-on coding projects. </em><a href="https://www.machinelearningisfun.com/get-the-book/" target="_self">Check it out now</a><em>!</em></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Are you tired of reading endless news stories about <em>deep learning</em> and not really knowing what that means? Let’s change that!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This time, we are going to learn how to write programs that recognize objects in images using deep learning. In other words, we’re going to explain the black magic that allows Google Photos to search your photos based on what is in the picture:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*F-6upZSC6GMMTP9yHeuwDg.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*F-6upZSC6GMMTP9yHeuwDg.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*F-6upZSC6GMMTP9yHeuwDg.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*F-6upZSC6GMMTP9yHeuwDg.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*F-6upZSC6GMMTP9yHeuwDg.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*F-6upZSC6GMMTP9yHeuwDg.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*F-6upZSC6GMMTP9yHeuwDg.gif 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*F-6upZSC6GMMTP9yHeuwDg.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*F-6upZSC6GMMTP9yHeuwDg.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*F-6upZSC6GMMTP9yHeuwDg.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*F-6upZSC6GMMTP9yHeuwDg.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*F-6upZSC6GMMTP9yHeuwDg.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*F-6upZSC6GMMTP9yHeuwDg.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*F-6upZSC6GMMTP9yHeuwDg.gif 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*F-6upZSC6GMMTP9yHeuwDg.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Google now lets you search your own photos by description — even if they aren’t tagged! How does this work??</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Just like <a href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471" target="_self">Part 1</a> and <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.lbsa5her1" target="_self">Part 2</a>, this guide is for anyone who is curious about machine learning but has no idea where to start. The goal is be accessible to anyone — which means that there’s a lot of generalizations and we skip lots of details. But who cares? If this gets anyone more interested in ML, then mission accomplished!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><em>(If you haven’t already read </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471" target="_self">part 1</a><em> and </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.lbsa5her1" target="_self">part 2</a><em>, read them now!)</em></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Recognizing Objects with Deep Learning</h4></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:34%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 267px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*wUZiI2Mg2cncuMWWXIiBgQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*wUZiI2Mg2cncuMWWXIiBgQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*wUZiI2Mg2cncuMWWXIiBgQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*wUZiI2Mg2cncuMWWXIiBgQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*wUZiI2Mg2cncuMWWXIiBgQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*wUZiI2Mg2cncuMWWXIiBgQ.png 1100w, https://miro.medium.com/v2/resize:fit:534/format:webp/1*wUZiI2Mg2cncuMWWXIiBgQ.png 534w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 267px" srcset="https://miro.medium.com/v2/resize:fit:640/1*wUZiI2Mg2cncuMWWXIiBgQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*wUZiI2Mg2cncuMWWXIiBgQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*wUZiI2Mg2cncuMWWXIiBgQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*wUZiI2Mg2cncuMWWXIiBgQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*wUZiI2Mg2cncuMWWXIiBgQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*wUZiI2Mg2cncuMWWXIiBgQ.png 1100w, https://miro.medium.com/v2/resize:fit:534/1*wUZiI2Mg2cncuMWWXIiBgQ.png 534w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/267/1*wUZiI2Mg2cncuMWWXIiBgQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">xkcd #1425 (<a href="http://xkcd.com/1425/" target="_self">View original here</a>)</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You might have seen <a href="http://xkcd.com/1425/" target="_self">this famous xkcd comic</a> before.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The goof is based on the idea that any 3-year-old child can recognize a photo of a bird, but figuring out how to make a computer recognize objects has puzzled the very best computer scientists for over 50 years.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the last few years, we’ve finally found a good approach to object recognition using <em>deep convolutional neural networks</em>. That sounds like a a bunch of made up words from a William Gibson Sci-Fi novel, but the ideas are totally understandable if you break them down one by one.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So let’s do it — let’s write a program that can recognize birds!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Starting Simple</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Before we learn how to recognize pictures of birds, let’s learn how to recognize something much simpler — the handwritten number “8”.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.lbsa5her1" target="_self">Part 2</a>, we learned about how neural networks can solve complex problems by chaining together lots of simple neurons. We created a small neural network to estimate the price of a house based on how many bedrooms it had, how big it was, and which neighborhood it was in:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Lt8RZaeQ6f6B_eA1oD32JQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*Lt8RZaeQ6f6B_eA1oD32JQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We also know that the idea of machine learning is that the same generic algorithms can be reused with different data to solve different problems. So let’s modify this same neural network to recognize handwritten text. But to make the job really simple, we’ll only try to recognize one letter — the numeral “8”.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Machine learning only works when you have data — preferably a lot of data. So we need lots and lots of handwritten “8”s to get started. Luckily, researchers created the <a href="http://yann.lecun.com/exdb/mnist/" target="_self">MNIST data set of handwritten numbers</a> for this very purpose. MNIST provides 60,000 images of handwritten digits, each as an 18x18 image. Here are some “8”s from the data set:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*jYKYXkfI4iaE6qg-dEUEcQ.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Some 8s from the MNIST data set</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">If you think about it, everything is just numbers</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The neural network we made in <a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-2-a26a10b68df3#.lbsa5her1" target="_self">Part 2</a> only took in a three numbers as the input (“3” bedrooms, “2000” sq. feet , etc.). But now we want to process images with our neural network. How in the world do we feed images into a neural network instead of just numbers?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The answer is incredible simple. A neural network takes numbers as input. To a computer, an image is really just a grid of numbers that represent how dark each pixel is:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:79%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 581px" srcset="https://miro.medium.com/v2/resize:fit:640/1*zY1qFB9aFfZz66YxxoI2aw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*zY1qFB9aFfZz66YxxoI2aw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*zY1qFB9aFfZz66YxxoI2aw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*zY1qFB9aFfZz66YxxoI2aw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*zY1qFB9aFfZz66YxxoI2aw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*zY1qFB9aFfZz66YxxoI2aw.gif 1100w, https://miro.medium.com/v2/resize:fit:1162/1*zY1qFB9aFfZz66YxxoI2aw.gif 1162w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 581px" srcset="https://miro.medium.com/v2/resize:fit:640/1*zY1qFB9aFfZz66YxxoI2aw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*zY1qFB9aFfZz66YxxoI2aw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*zY1qFB9aFfZz66YxxoI2aw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*zY1qFB9aFfZz66YxxoI2aw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*zY1qFB9aFfZz66YxxoI2aw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*zY1qFB9aFfZz66YxxoI2aw.gif 1100w, https://miro.medium.com/v2/resize:fit:1162/1*zY1qFB9aFfZz66YxxoI2aw.gif 1162w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/581/1*zY1qFB9aFfZz66YxxoI2aw.gif"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To feed an image into our neural network, we simply treat the 18x18 pixel image as an array of 324 numbers:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*UDgDe_-GMs4QQbT8UopoGA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*UDgDe_-GMs4QQbT8UopoGA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*UDgDe_-GMs4QQbT8UopoGA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*UDgDe_-GMs4QQbT8UopoGA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*UDgDe_-GMs4QQbT8UopoGA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*UDgDe_-GMs4QQbT8UopoGA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UDgDe_-GMs4QQbT8UopoGA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*UDgDe_-GMs4QQbT8UopoGA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*UDgDe_-GMs4QQbT8UopoGA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*UDgDe_-GMs4QQbT8UopoGA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*UDgDe_-GMs4QQbT8UopoGA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*UDgDe_-GMs4QQbT8UopoGA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*UDgDe_-GMs4QQbT8UopoGA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*UDgDe_-GMs4QQbT8UopoGA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*UDgDe_-GMs4QQbT8UopoGA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The handle 324 inputs, we’ll just enlarge our neural network to have 324 input nodes:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*b31hqXiBUjIXo2HSn_grFw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*b31hqXiBUjIXo2HSn_grFw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*b31hqXiBUjIXo2HSn_grFw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*b31hqXiBUjIXo2HSn_grFw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*b31hqXiBUjIXo2HSn_grFw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*b31hqXiBUjIXo2HSn_grFw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b31hqXiBUjIXo2HSn_grFw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*b31hqXiBUjIXo2HSn_grFw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*b31hqXiBUjIXo2HSn_grFw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*b31hqXiBUjIXo2HSn_grFw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*b31hqXiBUjIXo2HSn_grFw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*b31hqXiBUjIXo2HSn_grFw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*b31hqXiBUjIXo2HSn_grFw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*b31hqXiBUjIXo2HSn_grFw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*b31hqXiBUjIXo2HSn_grFw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Notice that our neural network also has two outputs now (instead of just one). The first output will predict the likelihood that the image is an “8” and thee second output will predict the likelihood it isn’t an “8”. By having a separate output for each type of object we want to recognize, we can use a neural network to classify objects into groups.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Our neural network is a lot bigger than last time (324 inputs instead of 3!). But any modern computer can handle a neural network with a few hundred nodes without blinking. This would even work fine on your cell phone.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">All that’s left is to train the neural network with images of “8”s and not-“8"s so it learns to tell them apart. When we feed in an “8”, we’ll tell it the probability the image is an “8” is 100% and the probability it’s not an “8” is 0%. Vice versa for the counter-example images.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here’s some of our training data:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*vEVQDKp9MgZkVPK4M70EhA.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*vEVQDKp9MgZkVPK4M70EhA.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Mmm… sweet, sweet training data</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We can train this kind of neural network in a few minutes on a modern laptop. When it’s done, we’ll have a neural network that can recognize pictures of “8”s with a pretty high accuracy. Welcome to the world of (late 1980’s-era) image recognition!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Tunnel Vision</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">It’s really neat that simply feeding pixels into a neural network actually worked to build image recognition! Machine learning is magic! <em>…right?</em></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><em>Well, of course it’s not that simple.</em></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">First, the good news is that our “8” recognizer really does work well on simple images where the letter is right in the middle of the image:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*5ciREAL7xdyXcD-cSRP7Jw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*5ciREAL7xdyXcD-cSRP7Jw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*5ciREAL7xdyXcD-cSRP7Jw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*5ciREAL7xdyXcD-cSRP7Jw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*5ciREAL7xdyXcD-cSRP7Jw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*5ciREAL7xdyXcD-cSRP7Jw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5ciREAL7xdyXcD-cSRP7Jw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*5ciREAL7xdyXcD-cSRP7Jw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*5ciREAL7xdyXcD-cSRP7Jw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*5ciREAL7xdyXcD-cSRP7Jw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*5ciREAL7xdyXcD-cSRP7Jw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*5ciREAL7xdyXcD-cSRP7Jw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*5ciREAL7xdyXcD-cSRP7Jw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*5ciREAL7xdyXcD-cSRP7Jw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*5ciREAL7xdyXcD-cSRP7Jw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But now the really bad news:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Our “8” recognizer <em>totally fails</em> to work when the letter isn’t perfectly centered in the image. Just the slightest position change ruins everything:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*b5jMTAiyVhOIB9hheXhMmA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*b5jMTAiyVhOIB9hheXhMmA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*b5jMTAiyVhOIB9hheXhMmA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*b5jMTAiyVhOIB9hheXhMmA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*b5jMTAiyVhOIB9hheXhMmA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*b5jMTAiyVhOIB9hheXhMmA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b5jMTAiyVhOIB9hheXhMmA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*b5jMTAiyVhOIB9hheXhMmA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*b5jMTAiyVhOIB9hheXhMmA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*b5jMTAiyVhOIB9hheXhMmA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*b5jMTAiyVhOIB9hheXhMmA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*b5jMTAiyVhOIB9hheXhMmA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*b5jMTAiyVhOIB9hheXhMmA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*b5jMTAiyVhOIB9hheXhMmA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*b5jMTAiyVhOIB9hheXhMmA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is because our network only learned the pattern of a perfectly-centered “8”. It has absolutely no idea what an off-center “8” is. It knows exactly one pattern and one pattern only.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">That’s not very useful in the real world. Real world problems are never that clean and simple. So we need to figure out how to make our neural network work in cases where the “8” isn’t perfectly centered.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Brute Force Idea #1: Searching with a Sliding Window</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We already created a really good program for finding an “8” centered in an image. What if we just scan all around the image for possible “8”s in smaller sections, one section at a time, until we find one?</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*bGBijVuJnTRj8025et0mcQ.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*bGBijVuJnTRj8025et0mcQ.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*bGBijVuJnTRj8025et0mcQ.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*bGBijVuJnTRj8025et0mcQ.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*bGBijVuJnTRj8025et0mcQ.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*bGBijVuJnTRj8025et0mcQ.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*bGBijVuJnTRj8025et0mcQ.gif 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*bGBijVuJnTRj8025et0mcQ.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*bGBijVuJnTRj8025et0mcQ.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*bGBijVuJnTRj8025et0mcQ.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*bGBijVuJnTRj8025et0mcQ.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*bGBijVuJnTRj8025et0mcQ.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*bGBijVuJnTRj8025et0mcQ.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*bGBijVuJnTRj8025et0mcQ.gif 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*bGBijVuJnTRj8025et0mcQ.gif"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This approach called a sliding window. It’s the brute force solution. It works well in some limited cases, but it’s really inefficient. You have to check the same image over and over looking for objects of different sizes. We can do better than this!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Brute Force Idea #2: More data and a Deep Neural Net</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">When we trained our network, we only showed it “8”s that were perfectly centered. What if we train it with more data, including “8”s in all different positions and sizes all around the image?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We don’t even need to collect new training data. We can just write a script to generate new images with the “8”s in all kinds of different positions in the image:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*biD9eS5eB6zXzieonNk-VQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*biD9eS5eB6zXzieonNk-VQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*biD9eS5eB6zXzieonNk-VQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*biD9eS5eB6zXzieonNk-VQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*biD9eS5eB6zXzieonNk-VQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*biD9eS5eB6zXzieonNk-VQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*biD9eS5eB6zXzieonNk-VQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*biD9eS5eB6zXzieonNk-VQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*biD9eS5eB6zXzieonNk-VQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*biD9eS5eB6zXzieonNk-VQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*biD9eS5eB6zXzieonNk-VQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*biD9eS5eB6zXzieonNk-VQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*biD9eS5eB6zXzieonNk-VQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*biD9eS5eB6zXzieonNk-VQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*biD9eS5eB6zXzieonNk-VQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">We created <strong>Synthetic Training Data</strong> by creating different versions of the training images we already had. This is a very useful technique!</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Using this technique, we can easily create an endless supply of training data.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">More data makes the problem harder for our neural network to solve, but we can compensate for that by making our network bigger and thus able to learn more complicated patterns.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To make the network bigger, we just stack up layer upon layer of nodes:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*wfmpsoFqWKC7VadjTJxwnQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*wfmpsoFqWKC7VadjTJxwnQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*wfmpsoFqWKC7VadjTJxwnQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*wfmpsoFqWKC7VadjTJxwnQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*wfmpsoFqWKC7VadjTJxwnQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*wfmpsoFqWKC7VadjTJxwnQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wfmpsoFqWKC7VadjTJxwnQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*wfmpsoFqWKC7VadjTJxwnQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*wfmpsoFqWKC7VadjTJxwnQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*wfmpsoFqWKC7VadjTJxwnQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*wfmpsoFqWKC7VadjTJxwnQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*wfmpsoFqWKC7VadjTJxwnQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*wfmpsoFqWKC7VadjTJxwnQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*wfmpsoFqWKC7VadjTJxwnQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*wfmpsoFqWKC7VadjTJxwnQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We call this a “deep neural network” because it has more layers than a traditional neural network.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This idea has been around since the late 1960s. But until recently, training this large of a neural network was just too slow to be useful. But once we figured out how to use 3d graphics cards (which were designed to do matrix multiplication really fast) instead of normal computer processors, working with large neural networks suddenly became practical. In fact, the exact same NVIDIA GeForce GTX 1080 video card that you use to play <a href="https://en.wikipedia.org/wiki/Overwatch_(video_game)" target="_self">Overwatch</a> can be used to train neural networks incredibly quickly.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:67%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 500px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 1100w, https://miro.medium.com/v2/resize:fit:1000/format:webp/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 1000w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 500px" srcset="https://miro.medium.com/v2/resize:fit:640/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 1100w, https://miro.medium.com/v2/resize:fit:1000/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png 1000w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/500/1*DSbLJ2Ll7Ex0qW-lT5zY8A.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But even though we can make our neural network really big and train it quickly with a 3d graphics card, that still isn’t going to get us all the way to a solution. We need to be smarter about how we process images into our neural network.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Think about it. It doesn’t make sense to train a network to recognize an “8” at the top of a picture separately from training it to recognize an “8” at the bottom of a picture as if those were two totally different objects.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">There should be some way to make the neural network smart enough to know that an “8” anywhere in the picture is the same thing without all that extra training. Luckily… there is!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">The Solution is Convolution</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As a human, you intuitively know that pictures have a <em>hierarchy</em> or <em>conceptual structure</em>. Consider this picture:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*v_06o9d5u4k2lp9cTHQUtg.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*v_06o9d5u4k2lp9cTHQUtg.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Gratuitous picture of my son</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As a human, you instantly recognize the hierarchy in this picture:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">The ground is covered in grass and concrete</li><li class="ff3" style="font-size:22px;">There is a child</li><li class="ff3" style="font-size:22px;">The child is sitting on a bouncy horse</li><li class="ff3" style="font-size:22px;">The bouncy horse is on top of the grass</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Most importantly, we recognize the idea of a <em>child</em> no matter what surface the child is on. We don’t have to re-learn the idea of <em>child</em> for every possible surface it could appear on.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But right now, our neural network can’t do this. It thinks that an “8” in a different part of the image is an entirely different thing. It doesn’t understand that moving an object around in the picture doesn’t make it something different. This means it has to re-learn the identify of each object in every possible position. That sucks.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We need to give our neural network understanding of <em>translation invariance </em>— an “8” is an “8” no matter where in the picture it shows up.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We’ll do this using a process called Convolution. The idea of convolution is inspired partly by computer science and partly by biology (i.e. mad scientists literally poking cat brains with weird probes to figure out how cats process images).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">How Convolution Works</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Instead of feeding entire images into our neural network as one grid of numbers, we’re going to do something a lot smarter that takes advantage of the idea that an object is the same no matter where it appears in a picture.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here’s how it’s going to work, step by step —</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Step 1: Break the image into overlapping image tiles</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Similar to our sliding window search above, let’s pass a sliding window over the entire original image and save each result as a separate, tiny picture tile:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*xS7EugfgQHk68iph7GHpQg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*xS7EugfgQHk68iph7GHpQg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*xS7EugfgQHk68iph7GHpQg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*xS7EugfgQHk68iph7GHpQg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*xS7EugfgQHk68iph7GHpQg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*xS7EugfgQHk68iph7GHpQg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xS7EugfgQHk68iph7GHpQg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*xS7EugfgQHk68iph7GHpQg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*xS7EugfgQHk68iph7GHpQg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*xS7EugfgQHk68iph7GHpQg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*xS7EugfgQHk68iph7GHpQg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*xS7EugfgQHk68iph7GHpQg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*xS7EugfgQHk68iph7GHpQg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*xS7EugfgQHk68iph7GHpQg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*xS7EugfgQHk68iph7GHpQg.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">By doing this, we turned our original image into 77 equally-sized tiny image tiles.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Step 2: Feed each image tile into a small neural network</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Earlier, we fed a single image into a neural network to see if it was an “8”. We’ll do the exact same thing here, but we’ll do it for each individual image tile:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*84-TdHvtAHkfnzwa1ZsTVg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*84-TdHvtAHkfnzwa1ZsTVg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*84-TdHvtAHkfnzwa1ZsTVg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*84-TdHvtAHkfnzwa1ZsTVg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*84-TdHvtAHkfnzwa1ZsTVg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*84-TdHvtAHkfnzwa1ZsTVg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*84-TdHvtAHkfnzwa1ZsTVg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*84-TdHvtAHkfnzwa1ZsTVg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*84-TdHvtAHkfnzwa1ZsTVg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*84-TdHvtAHkfnzwa1ZsTVg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*84-TdHvtAHkfnzwa1ZsTVg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*84-TdHvtAHkfnzwa1ZsTVg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*84-TdHvtAHkfnzwa1ZsTVg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*84-TdHvtAHkfnzwa1ZsTVg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*84-TdHvtAHkfnzwa1ZsTVg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Repeat this 77 times, once for each tile.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">However, <strong>there’s one big twist</strong>: We’ll keep the <strong>same neural network weights</strong> for every single tile in the same original image. In other words, we are treating every image tile equally. If something interesting appears in any given tile, we’ll mark that tile as interesting.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Step 3: Save the results from each tile into a new array</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We don’t want to lose track of the arrangement of the original tiles. So we save the result from processing each tile into a grid in the same arrangement as the original image. It looks like this:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*tpMqyjAFgsYWpvlNkZgFfw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*tpMqyjAFgsYWpvlNkZgFfw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*tpMqyjAFgsYWpvlNkZgFfw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*tpMqyjAFgsYWpvlNkZgFfw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*tpMqyjAFgsYWpvlNkZgFfw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*tpMqyjAFgsYWpvlNkZgFfw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tpMqyjAFgsYWpvlNkZgFfw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*tpMqyjAFgsYWpvlNkZgFfw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*tpMqyjAFgsYWpvlNkZgFfw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*tpMqyjAFgsYWpvlNkZgFfw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*tpMqyjAFgsYWpvlNkZgFfw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*tpMqyjAFgsYWpvlNkZgFfw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*tpMqyjAFgsYWpvlNkZgFfw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*tpMqyjAFgsYWpvlNkZgFfw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*tpMqyjAFgsYWpvlNkZgFfw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In other words, we’ve started with a large image and we ended with a slightly smaller array that records which sections of our original image were the most interesting.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Step 4: Downsampling</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The result of Step 3 was an array that maps out which parts of the original image are the most interesting. But that array is still pretty big:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*1WWTbW9yyEJ69TF1rsPv4g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*1WWTbW9yyEJ69TF1rsPv4g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*1WWTbW9yyEJ69TF1rsPv4g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*1WWTbW9yyEJ69TF1rsPv4g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*1WWTbW9yyEJ69TF1rsPv4g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*1WWTbW9yyEJ69TF1rsPv4g.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1WWTbW9yyEJ69TF1rsPv4g.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*1WWTbW9yyEJ69TF1rsPv4g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*1WWTbW9yyEJ69TF1rsPv4g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*1WWTbW9yyEJ69TF1rsPv4g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*1WWTbW9yyEJ69TF1rsPv4g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*1WWTbW9yyEJ69TF1rsPv4g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*1WWTbW9yyEJ69TF1rsPv4g.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*1WWTbW9yyEJ69TF1rsPv4g.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*1WWTbW9yyEJ69TF1rsPv4g.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To reduce the size of the array, we <em>downsample</em> it using an algorithm called <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer" target="_self">max pooling</a>. It sounds fancy, but it isn’t at all!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We’ll just look at each 2x2 square of the array and keep the biggest number:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*xOAroFiw9X0WSkCwgcIO6Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*xOAroFiw9X0WSkCwgcIO6Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*xOAroFiw9X0WSkCwgcIO6Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*xOAroFiw9X0WSkCwgcIO6Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*xOAroFiw9X0WSkCwgcIO6Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*xOAroFiw9X0WSkCwgcIO6Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xOAroFiw9X0WSkCwgcIO6Q.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*xOAroFiw9X0WSkCwgcIO6Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*xOAroFiw9X0WSkCwgcIO6Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*xOAroFiw9X0WSkCwgcIO6Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*xOAroFiw9X0WSkCwgcIO6Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*xOAroFiw9X0WSkCwgcIO6Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*xOAroFiw9X0WSkCwgcIO6Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*xOAroFiw9X0WSkCwgcIO6Q.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*xOAroFiw9X0WSkCwgcIO6Q.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The idea here is that if we found something interesting in any of the four input tiles that makes up each 2x2 grid square, we’ll just keep the most interesting bit. This reduces the size of our array while keeping the most important bits.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Final step: Make a prediction</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So far, we’ve reduced a giant image down into a fairly small array.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Guess what? That array is just a bunch of numbers, so we can use that small array as input into <em>another neural network</em>. This final neural network will decide if the image is or isn’t a match. To differentiate it from the convolution step, we call it a “fully connected” network.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So from start to finish, our whole five-step pipeline looks like this:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*tJ1Rkl5xw_5izEZXmNfh5Q.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*tJ1Rkl5xw_5izEZXmNfh5Q.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Adding Even More Steps</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Our image processing pipeline is a series of steps: convolution, max-pooling, and finally a fully-connected network.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">When solving problems in the real world, these steps can be combined and stacked as many times as you want! You can have two, three or even ten convolution layers. You can throw in max pooling wherever you want to reduce the size of your data.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The basic idea is to start with a large image and continually boil it down, step-by-step, until you finally have a single result. The more convolution steps you have, the more complicated features your network will be able to learn to recognize.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For example, the first convolution step might learn to recognize sharp edges, the second convolution step might recognize beaks using it’s knowledge of sharp edges, the third step might recognize entire birds using it’s knowledge of beaks, etc.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here’s what a more realistic deep convolutional network (like you would find in a research paper) looks like:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*JSnKtzEgiHd4p6UlNv_C7w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*JSnKtzEgiHd4p6UlNv_C7w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*JSnKtzEgiHd4p6UlNv_C7w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*JSnKtzEgiHd4p6UlNv_C7w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*JSnKtzEgiHd4p6UlNv_C7w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*JSnKtzEgiHd4p6UlNv_C7w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JSnKtzEgiHd4p6UlNv_C7w.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*JSnKtzEgiHd4p6UlNv_C7w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*JSnKtzEgiHd4p6UlNv_C7w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*JSnKtzEgiHd4p6UlNv_C7w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*JSnKtzEgiHd4p6UlNv_C7w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*JSnKtzEgiHd4p6UlNv_C7w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*JSnKtzEgiHd4p6UlNv_C7w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*JSnKtzEgiHd4p6UlNv_C7w.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*JSnKtzEgiHd4p6UlNv_C7w.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this case, they start a 224 x 224 pixel image, apply convolution and max pooling twice, apply convolution 3 more times, apply max pooling and then have two fully-connected layers. The end result is that the image is classified into one of 1000 categories!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Constructing the Right Network</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So how do you know which steps you need to combine to make your image classifier work?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Honestly, you have to answer this by doing a lot of experimentation and testing. You might have to train 100 networks before you find the optimal structure and parameters for the problem you are solving. Machine learning involves a lot of trial and error!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Building our Bird Classifier</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now finally we know enough to write a program that can decide if a picture is a bird or not.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As always, we need some data to get started. The free <a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_self">CIFAR10 data set</a> contains 6,000 pictures of birds and 52,000 pictures of things that are not birds. But to get even more data we’ll also add in the <a href="http://www.vision.caltech.edu/visipedia/CUB-200-2011.html" target="_self">Caltech-UCSD Birds-200–2011 data set</a> that has another 12,000 bird pics.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here’s a few of the birds from our combined data set:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*r9I5D3NXCn8gnLOjahuSQA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*r9I5D3NXCn8gnLOjahuSQA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*r9I5D3NXCn8gnLOjahuSQA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*r9I5D3NXCn8gnLOjahuSQA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*r9I5D3NXCn8gnLOjahuSQA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*r9I5D3NXCn8gnLOjahuSQA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r9I5D3NXCn8gnLOjahuSQA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*r9I5D3NXCn8gnLOjahuSQA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*r9I5D3NXCn8gnLOjahuSQA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*r9I5D3NXCn8gnLOjahuSQA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*r9I5D3NXCn8gnLOjahuSQA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*r9I5D3NXCn8gnLOjahuSQA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*r9I5D3NXCn8gnLOjahuSQA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*r9I5D3NXCn8gnLOjahuSQA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*r9I5D3NXCn8gnLOjahuSQA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">And here’s some of the 52,000 non-bird images:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ODaXoLQY4-D7zqHrqeA4Uw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ODaXoLQY4-D7zqHrqeA4Uw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ODaXoLQY4-D7zqHrqeA4Uw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ODaXoLQY4-D7zqHrqeA4Uw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ODaXoLQY4-D7zqHrqeA4Uw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ODaXoLQY4-D7zqHrqeA4Uw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ODaXoLQY4-D7zqHrqeA4Uw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*ODaXoLQY4-D7zqHrqeA4Uw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ODaXoLQY4-D7zqHrqeA4Uw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ODaXoLQY4-D7zqHrqeA4Uw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ODaXoLQY4-D7zqHrqeA4Uw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ODaXoLQY4-D7zqHrqeA4Uw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ODaXoLQY4-D7zqHrqeA4Uw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*ODaXoLQY4-D7zqHrqeA4Uw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*ODaXoLQY4-D7zqHrqeA4Uw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This data set will work fine for our purposes, but 72,000 low-res images is still pretty small for real-world applications. If you want Google-level performance, you need <em>millions</em> of large images. <mark>In machine learning, having more data is almost always more important that having better algorithms.</mark> Now you know why Google is so happy to offer you unlimited photo storage. They want your sweet, sweet data!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To build our classifier, we’ll use <a href="http://tflearn.org/" target="_self">TFLearn</a>. TFlearn is a wrapper around Google’s <a href="https://www.tensorflow.org/" target="_self">TensorFlow</a> deep learning library that exposes a simplified API. It makes building convolutional neural networks as easy as writing a few lines of code to define the layers of our network.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here’s the code to define and train the network:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre># -*- coding: utf-8 -*-

"""
Based on the tflearn example located here:
https://github.com/tflearn/tflearn/blob/master/examples/images/convnet_cifar10.py
"""
from __future__ import division, print_function, absolute_import

# Import tflearn and some helpers
import tflearn
from tflearn.data_utils import shuffle
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.conv import conv_2d, max_pool_2d
from tflearn.layers.estimator import regression
from tflearn.data_preprocessing import ImagePreprocessing
from tflearn.data_augmentation import ImageAugmentation
import pickle

# Load the data set
X, Y, X_test, Y_test = pickle.load(open("full_dataset.pkl", "rb"))

# Shuffle the data
X, Y = shuffle(X, Y)

# Make sure the data is normalized
img_prep = ImagePreprocessing()
img_prep.add_featurewise_zero_center()
img_prep.add_featurewise_stdnorm()

# Create extra synthetic training data by flipping, rotating and blurring the
# images on our data set.
img_aug = ImageAugmentation()
img_aug.add_random_flip_leftright()
img_aug.add_random_rotation(max_angle=25.)
img_aug.add_random_blur(sigma_max=3.)

# Define our network architecture:

# Input is a 32x32 image with 3 color channels (red, green and blue)
network = input_data(shape=[None, 32, 32, 3],
                     data_preprocessing=img_prep,
                     data_augmentation=img_aug)

# Step 1: Convolution
network = conv_2d(network, 32, 3, activation='relu')

# Step 2: Max pooling
network = max_pool_2d(network, 2)

# Step 3: Convolution again
network = conv_2d(network, 64, 3, activation='relu')

# Step 4: Convolution yet again
network = conv_2d(network, 64, 3, activation='relu')

# Step 5: Max pooling again
network = max_pool_2d(network, 2)

# Step 6: Fully-connected 512 node neural network
network = fully_connected(network, 512, activation='relu')

# Step 7: Dropout - throw away some data randomly during training to prevent over-fitting
network = dropout(network, 0.5)

# Step 8: Fully-connected neural network with two outputs (0=isn't a bird, 1=is a bird) to make the final prediction
network = fully_connected(network, 2, activation='softmax')

# Tell tflearn how we want to train the network
network = regression(network, optimizer='adam',
                     loss='categorical_crossentropy',
                     learning_rate=0.001)

# Wrap the network in a model object
model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path='bird-classifier.tfl.ckpt')

# Train it! We'll do 100 training passes and monitor it as it goes.
model.fit(X, Y, n_epoch=100, shuffle=True, validation_set=(X_test, Y_test),
          show_metric=True, batch_size=96,
          snapshot_epoch=True,
          run_id='bird-classifier')

# Save model when training is complete to a file
model.save("bird-classifier.tfl")
print("Network trained and saved as bird-classifier.tfl!")</pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you are training with a good video card with enough RAM (like an Nvidia GeForce GTX 980 Ti or better), this will be done in less than an hour. If you are training with a normal cpu, it might take a lot longer.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As it trains, the accuracy will increase. After the first pass, I got 75.4% accuracy. After just 10 passes, it was already up to 91.7%. After 50 or so passes, it capped out around 95.5% accuracy and additional training didn’t help, so I stopped it there.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Congrats! Our program can now recognize birds in images!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Testing our Network</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now that we have a trained neural network, we can use it! <a href="https://gist.github.com/ageitgey/a40dded08e82e59724c70da23786bbf0" target="_self">Here’s a simple script</a> that takes in a single image file and predicts if it is a bird or not.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But to really see how effective our network is, we need to test it with lots of images. The data set I created held back 15,000 images for validation. When I ran those 15,000 images through the network, it predicted the correct answer 95% of the time.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">That seems pretty good, right? Well… it depends!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">How accurate is 95% accurate?</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Our network claims to be 95% accurate. But the devil is in the details. That could mean all sorts of different things.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For example, what if 5% of our training images were birds and the other 95% were not birds? A program that guessed “not a bird” every single time would be 95% accurate! But it would also be 100% useless.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We need to look more closely at the numbers than just the overall accuracy. To judge how good a classification system really is, we need to look closely at <em>how</em> it failed, not just the percentage of the time that it failed.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Instead of thinking about our predictions as “right” and “wrong”, let’s break them down into four separate categories —</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">First, here are some of the birds that our network correctly identified as birds. Let’s call these <strong>True Positives:</strong></li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*iuk7uONvXNfEDwAyED0HIQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*iuk7uONvXNfEDwAyED0HIQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*iuk7uONvXNfEDwAyED0HIQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*iuk7uONvXNfEDwAyED0HIQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*iuk7uONvXNfEDwAyED0HIQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*iuk7uONvXNfEDwAyED0HIQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iuk7uONvXNfEDwAyED0HIQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*iuk7uONvXNfEDwAyED0HIQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*iuk7uONvXNfEDwAyED0HIQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*iuk7uONvXNfEDwAyED0HIQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*iuk7uONvXNfEDwAyED0HIQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*iuk7uONvXNfEDwAyED0HIQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*iuk7uONvXNfEDwAyED0HIQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*iuk7uONvXNfEDwAyED0HIQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*iuk7uONvXNfEDwAyED0HIQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Wow! Our network can recognize lots of different kinds of birds successfully!</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">Second, here are images that our network correctly identified as “not a bird”. These are called <strong>True Negatives:</strong></li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*QZWiJpImtlmohA-6TQPsEg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*QZWiJpImtlmohA-6TQPsEg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*QZWiJpImtlmohA-6TQPsEg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*QZWiJpImtlmohA-6TQPsEg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*QZWiJpImtlmohA-6TQPsEg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*QZWiJpImtlmohA-6TQPsEg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QZWiJpImtlmohA-6TQPsEg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*QZWiJpImtlmohA-6TQPsEg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*QZWiJpImtlmohA-6TQPsEg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*QZWiJpImtlmohA-6TQPsEg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*QZWiJpImtlmohA-6TQPsEg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*QZWiJpImtlmohA-6TQPsEg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*QZWiJpImtlmohA-6TQPsEg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*QZWiJpImtlmohA-6TQPsEg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*QZWiJpImtlmohA-6TQPsEg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Horses and trucks don’t fool us!</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">Third, here are some images that we thought were birds but were not really birds at all. These are our <strong>False Positives</strong>:</li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*UcKIK1Mxe29WB9Df1gembQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*UcKIK1Mxe29WB9Df1gembQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*UcKIK1Mxe29WB9Df1gembQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*UcKIK1Mxe29WB9Df1gembQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*UcKIK1Mxe29WB9Df1gembQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*UcKIK1Mxe29WB9Df1gembQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UcKIK1Mxe29WB9Df1gembQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*UcKIK1Mxe29WB9Df1gembQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*UcKIK1Mxe29WB9Df1gembQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*UcKIK1Mxe29WB9Df1gembQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*UcKIK1Mxe29WB9Df1gembQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*UcKIK1Mxe29WB9Df1gembQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*UcKIK1Mxe29WB9Df1gembQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*UcKIK1Mxe29WB9Df1gembQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*UcKIK1Mxe29WB9Df1gembQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Lots of planes were mistaken for birds! That makes sense.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">And finally, here are some images of birds that we didn’t correctly recognize as birds. These are our <strong>False Negatives</strong>:</li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Ac9OnpayukliEJchRKiKFQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Ac9OnpayukliEJchRKiKFQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Ac9OnpayukliEJchRKiKFQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Ac9OnpayukliEJchRKiKFQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Ac9OnpayukliEJchRKiKFQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Ac9OnpayukliEJchRKiKFQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ac9OnpayukliEJchRKiKFQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Ac9OnpayukliEJchRKiKFQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Ac9OnpayukliEJchRKiKFQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Ac9OnpayukliEJchRKiKFQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Ac9OnpayukliEJchRKiKFQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Ac9OnpayukliEJchRKiKFQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Ac9OnpayukliEJchRKiKFQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Ac9OnpayukliEJchRKiKFQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*Ac9OnpayukliEJchRKiKFQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">These birds fooled us! Stupid ostriches! Do they even count as birds?</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Using our validation set of 15,000 images, here’s how many times our predictions fell into each category:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*lgSDQ4-Js3elXBpavIp6FA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*lgSDQ4-Js3elXBpavIp6FA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*lgSDQ4-Js3elXBpavIp6FA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*lgSDQ4-Js3elXBpavIp6FA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*lgSDQ4-Js3elXBpavIp6FA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*lgSDQ4-Js3elXBpavIp6FA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lgSDQ4-Js3elXBpavIp6FA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*lgSDQ4-Js3elXBpavIp6FA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*lgSDQ4-Js3elXBpavIp6FA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*lgSDQ4-Js3elXBpavIp6FA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*lgSDQ4-Js3elXBpavIp6FA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*lgSDQ4-Js3elXBpavIp6FA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*lgSDQ4-Js3elXBpavIp6FA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*lgSDQ4-Js3elXBpavIp6FA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*lgSDQ4-Js3elXBpavIp6FA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Why do we break our results down like this? Because not all mistakes are created equal.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Imagine if we were writing a program to detect cancer from an MRI image. If we were detecting cancer, we’d rather have false positives than false negatives. False negatives would be the worse possible case — that’s when the program told someone they definitely didn’t have cancer but they actually did.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Instead of just looking at overall accuracy, we calculate <a href="https://en.wikipedia.org/wiki/Precision_and_recall" target="_self">Precision and Recall</a> metrics. Precision and Recall metrics give us a clearer picture of how well we did:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*T8SURWDvTTEY37yjUvu_pQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*T8SURWDvTTEY37yjUvu_pQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*T8SURWDvTTEY37yjUvu_pQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*T8SURWDvTTEY37yjUvu_pQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*T8SURWDvTTEY37yjUvu_pQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*T8SURWDvTTEY37yjUvu_pQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T8SURWDvTTEY37yjUvu_pQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*T8SURWDvTTEY37yjUvu_pQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*T8SURWDvTTEY37yjUvu_pQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*T8SURWDvTTEY37yjUvu_pQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*T8SURWDvTTEY37yjUvu_pQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*T8SURWDvTTEY37yjUvu_pQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*T8SURWDvTTEY37yjUvu_pQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*T8SURWDvTTEY37yjUvu_pQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*T8SURWDvTTEY37yjUvu_pQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This tells us that 97% of the time we guessed “Bird”, we were right! But it also tells us that we only found 90% of the actual birds in the data set. In other words, we might not find every bird but we are pretty sure about it when we do find one!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Where to go from here</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now that you know the basics of deep convolutional networks, you can try out some of the <a href="https://github.com/tflearn/tflearn/tree/master/examples#tflearn-examples" target="_self">examples that come with tflearn</a> to get your hands dirty with different neural network architectures. It even comes with built-in data sets so you don’t even have to find your own images.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You also know enough now to start branching and learning about other areas of machine learning. Why not learn <a href="http://karpathy.github.io/2016/05/31/rl/" target="_self">how to use algorithms to train computers how to play Atari games</a> next?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you liked this article, please consider <a href="http://eepurl.com/b9fg2T" target="_self">signing up for my Machine Learning is Fun! email list</a>. I’ll only email you when I have something new and awesome to share. It’s the best way to find out when I write more articles like this.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You can also follow me on Twitter at <a href="https://twitter.com/ageitgey" target="_self">@ageitgey</a>, <a href="mailto:ageitgey@gmail.com" target="_self">email me directly</a> or <a href="https://www.linkedin.com/in/ageitgey" target="_self">find me on linkedin</a>. I’d love to hear from you if I can help you or your team with machine learning.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><em>Now continue on to </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78" target="_self">Machine Learning is Fun Part 4</a><em>, </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-5-language-translation-with-deep-learning-and-the-magic-of-sequences-2ace0acca0aa" target="_self">Part 5</a><em> and </em><a href="https://medium.com/@ageitgey/machine-learning-is-fun-part-6-how-to-do-speech-recognition-with-deep-learning-28293c162f7a" target="_self">Part 6</a><em>!</em></p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>