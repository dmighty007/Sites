<!DOCTYPE html>
                <html>
                <head>
                    <title>What do we learn from region based object detectors (Faster R-CNN, R-FCN, FPN)?</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://jonathan-hui.medium.com/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/?source=post_page-----7e354377a7c9--------------------------------">Author : Jonathan Hui</a> </h5></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*2MSAHlNwHs7XyEX5. 640w, https://miro.medium.com/v2/resize:fit:720/0*2MSAHlNwHs7XyEX5. 720w, https://miro.medium.com/v2/resize:fit:750/0*2MSAHlNwHs7XyEX5. 750w, https://miro.medium.com/v2/resize:fit:786/0*2MSAHlNwHs7XyEX5. 786w, https://miro.medium.com/v2/resize:fit:828/0*2MSAHlNwHs7XyEX5. 828w, https://miro.medium.com/v2/resize:fit:1100/0*2MSAHlNwHs7XyEX5. 1100w, https://miro.medium.com/v2/resize:fit:1400/0*2MSAHlNwHs7XyEX5. 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*2MSAHlNwHs7XyEX5. 640w, https://miro.medium.com/v2/resize:fit:720/0*2MSAHlNwHs7XyEX5. 720w, https://miro.medium.com/v2/resize:fit:750/0*2MSAHlNwHs7XyEX5. 750w, https://miro.medium.com/v2/resize:fit:786/0*2MSAHlNwHs7XyEX5. 786w, https://miro.medium.com/v2/resize:fit:828/0*2MSAHlNwHs7XyEX5. 828w, https://miro.medium.com/v2/resize:fit:1100/0*2MSAHlNwHs7XyEX5. 1100w, https://miro.medium.com/v2/resize:fit:1400/0*2MSAHlNwHs7XyEX5. 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/0*2MSAHlNwHs7XyEX5."></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>What do we learn from region based object detectors (Faster R-CNN, R-FCN, FPN)?</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this series, we will take a comprehensive journey on object detection. In Part 1 here, we cover the region based object detectors including Fast R-CNN, Faster R-CNN, R-FCN and FPN. In part 2, we will study the single shoot detectors. In part 3, we cover the performance and some implementation issues. By studying them in one context, we study what is working, what matters and where can be improved. Hopefully, by studying how we get here, it will give us more insights on where we are heading.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9" target="_self">Part 1</a>: What do we learn from region based object detectors (Faster R-CNN, R-FCN, FPN)?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://medium.com/@jonathan_hui/what-do-we-learn-from-single-shot-object-detectors-ssd-yolo-fpn-focal-loss-3888677c5f4d" target="_self">Part 2</a>: What do we learn from single shot object detectors (SSD, YOLO), FPN & Focal loss?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://medium.com/@jonathan_hui/design-choices-lessons-learned-and-trends-for-object-detections-4f48b59ec5ff" target="_self">Part 3</a>: Design choices, lessons learned and trends for object detections?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5"><strong>Sliding-window detectors</strong></h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Since AlexNet won the 2012 ILSVRC challenge, the use of the CNN for classification has dominated the field. One brute force approach for object detection is to slide windows from left and right, and from up to down to identify objects using classification. To detect different object types at various viewing distances, we use windows of varied sizes and aspect ratios.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*-GaZ8hGBKsbtGfRJqvOVHQ.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Sliding-windows (From right to left, up and down)</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We cut out patches from the picture according to the sliding windows. The patches are warped since many classifiers take fixed size images only. However, this should not impact the classification accuracy since the classifier are trained to handle warped images.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:40%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 310px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:620/format:webp/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 620w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 310px" srcset="https://miro.medium.com/v2/resize:fit:640/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:620/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg 620w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/310/1*A7DE4HKukbXpQqwvCaLOEQ.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Warp an image to a fixed size image.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The warped image patch is fed into a CNN classifier to extract 4096 features. Then we apply a SVM classifier to identify the class and another linear regressor for the boundary box.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*BYSA3iip3Cdr0L_x5r468A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*BYSA3iip3Cdr0L_x5r468A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*BYSA3iip3Cdr0L_x5r468A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*BYSA3iip3Cdr0L_x5r468A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*BYSA3iip3Cdr0L_x5r468A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*BYSA3iip3Cdr0L_x5r468A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BYSA3iip3Cdr0L_x5r468A.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*BYSA3iip3Cdr0L_x5r468A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*BYSA3iip3Cdr0L_x5r468A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*BYSA3iip3Cdr0L_x5r468A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*BYSA3iip3Cdr0L_x5r468A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*BYSA3iip3Cdr0L_x5r468A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*BYSA3iip3Cdr0L_x5r468A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*BYSA3iip3Cdr0L_x5r468A.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*BYSA3iip3Cdr0L_x5r468A.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">System flow for the sliding-window detector.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Below is the pseudo code. We create many windows to detect different object shapes at different locations. To improve performance, one obvious solution is to reduce the number of <em>windows</em>.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>for window in windows<br/>    patch = get_patch(image, window)<br/>    results = detector(patch)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Selective Search</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Instead of a brute force approach, we use a region proposal method to create <strong>regions of interest (ROIs) </strong>for object detection. In <strong>selective search </strong>(<strong>SS</strong>), we start with each individual pixel as its own group. Next, we calculate the texture for each group and combine two that are the closest. But to avoid a single region in gobbling others, we prefer grouping smaller group first. We continue merging regions until everything is combined together. In the first row below, we show how we grow the regions, and the blue rectangles in the second rows show all possible ROIs we made during the merging.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*_8BNWWwyod1LWUdzcAUr8w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*_8BNWWwyod1LWUdzcAUr8w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*_8BNWWwyod1LWUdzcAUr8w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*_8BNWWwyod1LWUdzcAUr8w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*_8BNWWwyod1LWUdzcAUr8w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*_8BNWWwyod1LWUdzcAUr8w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_8BNWWwyod1LWUdzcAUr8w.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*_8BNWWwyod1LWUdzcAUr8w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*_8BNWWwyod1LWUdzcAUr8w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*_8BNWWwyod1LWUdzcAUr8w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*_8BNWWwyod1LWUdzcAUr8w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*_8BNWWwyod1LWUdzcAUr8w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*_8BNWWwyod1LWUdzcAUr8w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*_8BNWWwyod1LWUdzcAUr8w.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*_8BNWWwyod1LWUdzcAUr8w.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">(Image source: van de Sande et al. ICCV’11)</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">R-CNN</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">R-CNN makes use of a region proposal method to create about 2000 <strong>ROI</strong>s (regions of interest). The regions are warped into fixed size images and feed into a CNN network individually. It is then followed by fully connected layers to classify the object and to refine the boundary box.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Wmw21tBUez37bj-1ws7XEw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Wmw21tBUez37bj-1ws7XEw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Wmw21tBUez37bj-1ws7XEw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Wmw21tBUez37bj-1ws7XEw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Wmw21tBUez37bj-1ws7XEw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Wmw21tBUez37bj-1ws7XEw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wmw21tBUez37bj-1ws7XEw.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Wmw21tBUez37bj-1ws7XEw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*Wmw21tBUez37bj-1ws7XEw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*Wmw21tBUez37bj-1ws7XEw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*Wmw21tBUez37bj-1ws7XEw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*Wmw21tBUez37bj-1ws7XEw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*Wmw21tBUez37bj-1ws7XEw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Wmw21tBUez37bj-1ws7XEw.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*Wmw21tBUez37bj-1ws7XEw.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Use region proposals, CNN, affine layers to locate objects.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here is the system flow.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ciyhZpgEvxDm1YxZd1SJWg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ciyhZpgEvxDm1YxZd1SJWg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ciyhZpgEvxDm1YxZd1SJWg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ciyhZpgEvxDm1YxZd1SJWg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ciyhZpgEvxDm1YxZd1SJWg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ciyhZpgEvxDm1YxZd1SJWg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ciyhZpgEvxDm1YxZd1SJWg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*ciyhZpgEvxDm1YxZd1SJWg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ciyhZpgEvxDm1YxZd1SJWg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ciyhZpgEvxDm1YxZd1SJWg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ciyhZpgEvxDm1YxZd1SJWg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ciyhZpgEvxDm1YxZd1SJWg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ciyhZpgEvxDm1YxZd1SJWg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*ciyhZpgEvxDm1YxZd1SJWg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*ciyhZpgEvxDm1YxZd1SJWg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">System flow for R-CNN</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">With far fewer but higher quality ROIs, R-CNN run faster and more accurate than the sliding windows.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>ROIs = region_proposal(image)<br/>for ROI in ROIs<br/>    patch = get_patch(image, ROI)<br/>    results = detector(patch)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Boundary box regressor</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Region proposal methods are computation intense. To speed up the process, we often pick a less expensive region proposal method to create ROIs followed by a linear regressor (using fully connected layers) to refine the boundary box further.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:94%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 688px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1376/format:webp/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 1376w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 688px" srcset="https://miro.medium.com/v2/resize:fit:640/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1376/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg 1376w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/688/1*rvPyjhiVQnOm3yOqSDUKuA.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Use regression to refine the original ROI in blue to the red one.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Fast R-CNN</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">R-CNN needs many proposals to be accurate and many regions overlap with each other. <strong>R-CNN is slow in training & inference. </strong>If we have 2,000 proposals, each of them is processed by a CNN separately, i.e. we repeat feature extractions 2,000 times for different ROIs.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Instead of extracting features for each image patch from scratch, we use a <strong>feature extractor</strong> (a CNN) to extract features for the whole image first. We also use an external region proposal method, like the selective search, to create ROIs which later combine with the corresponding feature maps to form patches for object detection. We warp the patches to a fixed size using <strong>ROI pooling</strong> and feed them to fully connected layers for classification and <strong>localization</strong> (detecting the location of the object). By not repeating the feature extractions, Fast R-CNN cuts down the process time significantly.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Dd3-sugNKInTIv12u8cWkw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Dd3-sugNKInTIv12u8cWkw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Dd3-sugNKInTIv12u8cWkw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Dd3-sugNKInTIv12u8cWkw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Dd3-sugNKInTIv12u8cWkw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Dd3-sugNKInTIv12u8cWkw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dd3-sugNKInTIv12u8cWkw.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Dd3-sugNKInTIv12u8cWkw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*Dd3-sugNKInTIv12u8cWkw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*Dd3-sugNKInTIv12u8cWkw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*Dd3-sugNKInTIv12u8cWkw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*Dd3-sugNKInTIv12u8cWkw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*Dd3-sugNKInTIv12u8cWkw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Dd3-sugNKInTIv12u8cWkw.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*Dd3-sugNKInTIv12u8cWkw.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Apply region proposal on feature maps and form fixed size patches using ROI pooling.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here is the network flow:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*fLMNHfe_QFxW569s4eR7Dg.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*fLMNHfe_QFxW569s4eR7Dg.jpeg"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the pseudo-code below, the expensive feature extraction is moving out of the for-loop, a significant speed improvement since it was executed for all 2000 ROIs. Fast R-CNN is 10x faster than R-CNN in training and 150x faster in inferencing.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>feature_maps = process(image)<br/>ROIs = region_proposal(image)<br/>for ROI in ROIs<br/>    patch = roi_pooling(feature_maps, ROI)<br/>    results = detector2(patch)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">One major takeaway for Fast R-CNN is that the whole network (the feature extractor, the classifier, and the boundary box regressor) are trained end-to-end with<strong> multi-task losses</strong> (classification loss and localization loss). This improves accuracy.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>ROI Pooling</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Because Fast R-CNN uses fully connected layers, we apply <strong>ROI pooling</strong> to warp the variable size ROIs into in a predefined size shape.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s simplify the discussion by transforming 8 × 8 feature maps into a predefined 2 × 2 shape.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">Top left below: our feature maps.</li><li class="ff3" style="font-size:22px;">Top right: we overlap the ROI (blue) with the feature maps.</li><li class="ff3" style="font-size:22px;">Bottom left: we split ROIs into the target dimension. For example, with our 2×2 target, we split the ROIs into 4 sections with similar or equal sizes.</li><li class="ff3" style="font-size:22px;">Bottom right: find the maximum for each section and the result is our warped feature maps.</li></ul></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*LLP4tKGsYGgAx3uPfmGdsw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*LLP4tKGsYGgAx3uPfmGdsw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*LLP4tKGsYGgAx3uPfmGdsw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*LLP4tKGsYGgAx3uPfmGdsw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*LLP4tKGsYGgAx3uPfmGdsw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*LLP4tKGsYGgAx3uPfmGdsw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LLP4tKGsYGgAx3uPfmGdsw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*LLP4tKGsYGgAx3uPfmGdsw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*LLP4tKGsYGgAx3uPfmGdsw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*LLP4tKGsYGgAx3uPfmGdsw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*LLP4tKGsYGgAx3uPfmGdsw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*LLP4tKGsYGgAx3uPfmGdsw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*LLP4tKGsYGgAx3uPfmGdsw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*LLP4tKGsYGgAx3uPfmGdsw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*LLP4tKGsYGgAx3uPfmGdsw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Input feature map (top left), output feature map (bottom right), blue box is the ROI (top right).</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So we get a 2 × 2 feature patch that we can feed into the classifier and box regressor.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Faster R-CNN</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Fast R-CNN depends on an external region proposal method like selective search. However, those algorithms run on CPU and they are slow. In testing, Fast R-CNN takes 2.3 seconds to make a prediction in which 2 seconds are for generating 2000 ROIs.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>feature_maps = process(image)<br/>ROIs = region_proposal(image)         # Expensive!<br/>for ROI in ROIs<br/>    patch = roi_pooling(feature_maps, ROI)<br/>    results = detector2(patch)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Faster R-CNN adopts similar design as the Fast R-CNN except it replaces the region proposal method by an internal deep network and the ROIs are derived from the feature maps instead. The new region proposal network (<strong>RPN</strong>) is more efficient and run at 10 ms per image in generating ROIs.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*F-WbcUMpWSE1tdKRgew2Ug.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*F-WbcUMpWSE1tdKRgew2Ug.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*F-WbcUMpWSE1tdKRgew2Ug.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*F-WbcUMpWSE1tdKRgew2Ug.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*F-WbcUMpWSE1tdKRgew2Ug.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*F-WbcUMpWSE1tdKRgew2Ug.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F-WbcUMpWSE1tdKRgew2Ug.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*F-WbcUMpWSE1tdKRgew2Ug.png 640w, https://miro.medium.com/v2/resize:fit:720/1*F-WbcUMpWSE1tdKRgew2Ug.png 720w, https://miro.medium.com/v2/resize:fit:750/1*F-WbcUMpWSE1tdKRgew2Ug.png 750w, https://miro.medium.com/v2/resize:fit:786/1*F-WbcUMpWSE1tdKRgew2Ug.png 786w, https://miro.medium.com/v2/resize:fit:828/1*F-WbcUMpWSE1tdKRgew2Ug.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*F-WbcUMpWSE1tdKRgew2Ug.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*F-WbcUMpWSE1tdKRgew2Ug.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*F-WbcUMpWSE1tdKRgew2Ug.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Network flow is the same as the Fast R-CNN.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The network flow is similar but the region proposal is now replaced by a convolutional network (RPN).</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*0cxB2pAxQ0A7AhTl-YT2JQ.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">The external region proposal is replaced by an internal deep network.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Region proposal network</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The region proposal network (<strong>RPN</strong>) takes the output feature maps from the first convolutional network as input. It slides 3 × 3 filters over the feature maps to make class-agnostic region proposals using a convolutional network like ZF network (below). Other deep network likes VGG or ResNet can be used for more comprehensive feature extraction at the cost of speed. The ZF network outputs 256 values, which is feed into 2 separate fully connected layers to predict a boundary box and 2 objectness scores. The <strong>objectness </strong>measures whether the box contains an object. We can use a regressor to compute a single objectness score but for simplicity, Faster R-CNN uses a classifier with 2 possible classes: one for the “have an object” category and one without (i.e. the background class).</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*z0OHn89t0bOIHwoIOwNDtg.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*z0OHn89t0bOIHwoIOwNDtg.jpeg"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For each location in the feature maps, RPN makes <strong>k</strong> guesses. Therefore RPN outputs 4×k coordinates and 2×k scores per location. The diagram below shows the 8 × 8 feature maps with a 3× 3 filter, and it outputs a total of 8 × 8 × 3 ROIs (for k = 3). The right side diagram demonstrates the 3 proposals made by a single location.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:94%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 688px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1376/format:webp/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 1376w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 688px" srcset="https://miro.medium.com/v2/resize:fit:640/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1376/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg 1376w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/688/1*smu6PiCx4LaPwGIo3HG0GQ.jpeg"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here, we get 3 guesses and we will refine our guesses later. Since we just need one to be correct, we will be better off if our initial guesses have different shapes and size. Therefore, Faster R-CNN does not make random boundary box proposals. Instead, it predicts offsets like 𝛿x, 𝛿y that are relative to the top left corner of some reference boxes called <strong>anchors</strong>. We constraints the value of those offsets so our guesses still resemble the anchors.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:53%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 400px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*yF_FrZAkXA3XKFA-sf7XZw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*yF_FrZAkXA3XKFA-sf7XZw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*yF_FrZAkXA3XKFA-sf7XZw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*yF_FrZAkXA3XKFA-sf7XZw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*yF_FrZAkXA3XKFA-sf7XZw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*yF_FrZAkXA3XKFA-sf7XZw.png 1100w, https://miro.medium.com/v2/resize:fit:800/format:webp/1*yF_FrZAkXA3XKFA-sf7XZw.png 800w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 400px" srcset="https://miro.medium.com/v2/resize:fit:640/1*yF_FrZAkXA3XKFA-sf7XZw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*yF_FrZAkXA3XKFA-sf7XZw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*yF_FrZAkXA3XKFA-sf7XZw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*yF_FrZAkXA3XKFA-sf7XZw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*yF_FrZAkXA3XKFA-sf7XZw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*yF_FrZAkXA3XKFA-sf7XZw.png 1100w, https://miro.medium.com/v2/resize:fit:800/1*yF_FrZAkXA3XKFA-sf7XZw.png 800w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/400/1*yF_FrZAkXA3XKFA-sf7XZw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To make k predictions per location, we need k anchors centered at each location. Each prediction is associated with a specific anchor but different locations share the same anchor shapes.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:46%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 350px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*RJoauxGwUTF17ZANQmL8jw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*RJoauxGwUTF17ZANQmL8jw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*RJoauxGwUTF17ZANQmL8jw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*RJoauxGwUTF17ZANQmL8jw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*RJoauxGwUTF17ZANQmL8jw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*RJoauxGwUTF17ZANQmL8jw.png 1100w, https://miro.medium.com/v2/resize:fit:700/format:webp/1*RJoauxGwUTF17ZANQmL8jw.png 700w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 350px" srcset="https://miro.medium.com/v2/resize:fit:640/1*RJoauxGwUTF17ZANQmL8jw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*RJoauxGwUTF17ZANQmL8jw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*RJoauxGwUTF17ZANQmL8jw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*RJoauxGwUTF17ZANQmL8jw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*RJoauxGwUTF17ZANQmL8jw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*RJoauxGwUTF17ZANQmL8jw.png 1100w, https://miro.medium.com/v2/resize:fit:700/1*RJoauxGwUTF17ZANQmL8jw.png 700w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/350/1*RJoauxGwUTF17ZANQmL8jw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Those anchors are carefully pre-selected so they are diverse and cover real-life objects at different scales and aspect ratios reasonable well. This guides the initial training with better guesses and allows each prediction to specialize in a certain shape. This strategy makes early training more stable and easier.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><mark>Faster R-CNN uses far more anchors. It deploys 9 anchor boxes: 3 different scales at 3 different aspect ratio. Using 9 anchors per location, it generates 2 × 9 objectness scores and 4 × 9 coordinates per location.</mark></p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*PszFnq3rqa_CAhBrI94Eeg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*PszFnq3rqa_CAhBrI94Eeg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*PszFnq3rqa_CAhBrI94Eeg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*PszFnq3rqa_CAhBrI94Eeg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*PszFnq3rqa_CAhBrI94Eeg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*PszFnq3rqa_CAhBrI94Eeg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PszFnq3rqa_CAhBrI94Eeg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*PszFnq3rqa_CAhBrI94Eeg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*PszFnq3rqa_CAhBrI94Eeg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*PszFnq3rqa_CAhBrI94Eeg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*PszFnq3rqa_CAhBrI94Eeg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*PszFnq3rqa_CAhBrI94Eeg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*PszFnq3rqa_CAhBrI94Eeg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*PszFnq3rqa_CAhBrI94Eeg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*PszFnq3rqa_CAhBrI94Eeg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;"><a href="https://arxiv.org/pdf/1506.01497.pdf" target="_self">Source</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4"><strong>Anchors</strong> are also called <strong>priors</strong> or <strong>default boundary boxes</strong> in different papers.</p></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Performance for R-CNN methods</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As shown below, Faster R-CNN is even much faster.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:67%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 500px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1000/format:webp/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 1000w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 500px" srcset="https://miro.medium.com/v2/resize:fit:640/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1000/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg 1000w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/500/1*fO2MSeQxIVVUUp6csJ8oWg.jpeg"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Region-based Fully Convolutional Networks (R-FCN)</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s assume we only have a feature map detecting the right eye of a face. Can we use it to locate a face? It should. Since the right eye should be on the top-left corner of a facial picture, we can use that to locate the face.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*gqxSBKVla8dzwADKgADpWg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*gqxSBKVla8dzwADKgADpWg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*gqxSBKVla8dzwADKgADpWg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*gqxSBKVla8dzwADKgADpWg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*gqxSBKVla8dzwADKgADpWg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*gqxSBKVla8dzwADKgADpWg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gqxSBKVla8dzwADKgADpWg.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*gqxSBKVla8dzwADKgADpWg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*gqxSBKVla8dzwADKgADpWg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*gqxSBKVla8dzwADKgADpWg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*gqxSBKVla8dzwADKgADpWg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*gqxSBKVla8dzwADKgADpWg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*gqxSBKVla8dzwADKgADpWg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*gqxSBKVla8dzwADKgADpWg.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*gqxSBKVla8dzwADKgADpWg.jpeg"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If we have other feature maps specialized in detecting the left eye, the nose or the mouth, we can combine the results together to locate the face better.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So why we go through all the trouble. In Faster R-CNN, the <em>detector</em> applies multiple fully connected layers to make predictions. With 2,000 ROIs, it can be expensive.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>feature_maps = process(image)<br/>ROIs = region_proposal(feature_maps)<br/>for ROI in ROIs<br/>    patch = roi_pooling(feature_maps, ROI)<br/>    class_scores, box = detector(patch)         # Expensive!<br/>    class_probabilities = softmax(class_scores)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">R-FCN improves speed by reducing the amount of work needed for each ROI. The region-based feature maps above are independent of ROIs and can be computed outside each ROI. The remaining work is much simpler and therefore R-FCN is faster than Faster R-CNN.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>feature_maps = process(image)<br/>ROIs = region_proposal(feature_maps)         <br/>score_maps = compute_score_map(feature_maps)<br/>for ROI in ROIs<br/>    V = region_roi_pool(score_maps, ROI)     <br/>    class_scores, box = average(V)                   # Much simpler!<br/>    class_probabilities = softmax(class_scores)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s consider a 5 × 5 feature map <strong>M</strong> with a blue square object inside. We divide the square object equally into 3 × 3 regions. Now, we create a new feature map from M to detect the top left (TL) corner of the square only. The new feature map looks like the one on the right below. Only the yellow <strong>grid cell</strong> [2, 2] is activated.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*S0enLblW1t7VK19E1Fs4lw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*S0enLblW1t7VK19E1Fs4lw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*S0enLblW1t7VK19E1Fs4lw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*S0enLblW1t7VK19E1Fs4lw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*S0enLblW1t7VK19E1Fs4lw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*S0enLblW1t7VK19E1Fs4lw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S0enLblW1t7VK19E1Fs4lw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*S0enLblW1t7VK19E1Fs4lw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*S0enLblW1t7VK19E1Fs4lw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*S0enLblW1t7VK19E1Fs4lw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*S0enLblW1t7VK19E1Fs4lw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*S0enLblW1t7VK19E1Fs4lw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*S0enLblW1t7VK19E1Fs4lw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*S0enLblW1t7VK19E1Fs4lw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*S0enLblW1t7VK19E1Fs4lw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Create a new feature map from the left to detect the top left corner of an object.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Since we divide the square into 9 parts, we can create 9 feature maps each detecting the corresponding region of the object. These feature maps are called <strong>position-sensitive score maps </strong>because each map detects (scores) a sub-region of the object.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*HaOHsDYAf8LU2YQ7D3ymOg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*HaOHsDYAf8LU2YQ7D3ymOg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*HaOHsDYAf8LU2YQ7D3ymOg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*HaOHsDYAf8LU2YQ7D3ymOg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*HaOHsDYAf8LU2YQ7D3ymOg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*HaOHsDYAf8LU2YQ7D3ymOg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HaOHsDYAf8LU2YQ7D3ymOg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*HaOHsDYAf8LU2YQ7D3ymOg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*HaOHsDYAf8LU2YQ7D3ymOg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*HaOHsDYAf8LU2YQ7D3ymOg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*HaOHsDYAf8LU2YQ7D3ymOg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*HaOHsDYAf8LU2YQ7D3ymOg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*HaOHsDYAf8LU2YQ7D3ymOg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*HaOHsDYAf8LU2YQ7D3ymOg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*HaOHsDYAf8LU2YQ7D3ymOg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Generate 9 score maps</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s say the dotted red rectangle below is the ROI proposed. We divide it into 3 × 3 regions and ask how likely each region contains the corresponding part of the object. For example, how likely the top-left ROI region contains the left eye. We store the results into a 3 × 3 vote array in the right diagram below. For example, vote_array[0][0] contains the score on whether we find the top-left region of the square object.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Ym6b1qS0pXpeRVMysvvukg.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*Ym6b1qS0pXpeRVMysvvukg.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Apply ROI onto the feature maps to output a 3 x 3 array.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This process to map score maps and ROIs to the vote array is called <strong>position-sensitive</strong> <strong>ROI-pool</strong>. The process is extremely close to the ROI pool we discussed before. We will not cover it further but you can refer to the future reading section for more information.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*K4brSqensF8wL5i6JV1Eig.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*K4brSqensF8wL5i6JV1Eig.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*K4brSqensF8wL5i6JV1Eig.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*K4brSqensF8wL5i6JV1Eig.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*K4brSqensF8wL5i6JV1Eig.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*K4brSqensF8wL5i6JV1Eig.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K4brSqensF8wL5i6JV1Eig.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*K4brSqensF8wL5i6JV1Eig.png 640w, https://miro.medium.com/v2/resize:fit:720/1*K4brSqensF8wL5i6JV1Eig.png 720w, https://miro.medium.com/v2/resize:fit:750/1*K4brSqensF8wL5i6JV1Eig.png 750w, https://miro.medium.com/v2/resize:fit:786/1*K4brSqensF8wL5i6JV1Eig.png 786w, https://miro.medium.com/v2/resize:fit:828/1*K4brSqensF8wL5i6JV1Eig.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*K4brSqensF8wL5i6JV1Eig.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*K4brSqensF8wL5i6JV1Eig.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*K4brSqensF8wL5i6JV1Eig.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Overlay a portion of the ROI onto the corresponding score map to calculate V[i][j]</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">After calculating all the values for the position-sensitive ROI pool, the class score is the average of all its elements.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ZJiWcIl2DUyx1-ZqArw33A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ZJiWcIl2DUyx1-ZqArw33A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ZJiWcIl2DUyx1-ZqArw33A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ZJiWcIl2DUyx1-ZqArw33A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ZJiWcIl2DUyx1-ZqArw33A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ZJiWcIl2DUyx1-ZqArw33A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZJiWcIl2DUyx1-ZqArw33A.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*ZJiWcIl2DUyx1-ZqArw33A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ZJiWcIl2DUyx1-ZqArw33A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ZJiWcIl2DUyx1-ZqArw33A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ZJiWcIl2DUyx1-ZqArw33A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ZJiWcIl2DUyx1-ZqArw33A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ZJiWcIl2DUyx1-ZqArw33A.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*ZJiWcIl2DUyx1-ZqArw33A.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*ZJiWcIl2DUyx1-ZqArw33A.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">ROI pool</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s say we have <strong>C</strong> classes to detect. We expand it to C + 1 classes so we include a new class for the background (non-object). Each class will have its own 3 × 3 score maps and therefore a total of (C+1) × 3 × 3 score maps. Using its own set of score maps, we predict a class score for each class. Then we apply a softmax on those scores to compute the probability for each class.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The following is the data flow. For our example, we have k=3 below.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Gv45peeSM2wRQEdaLG_YoQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Gv45peeSM2wRQEdaLG_YoQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Gv45peeSM2wRQEdaLG_YoQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Gv45peeSM2wRQEdaLG_YoQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Gv45peeSM2wRQEdaLG_YoQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Gv45peeSM2wRQEdaLG_YoQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gv45peeSM2wRQEdaLG_YoQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Gv45peeSM2wRQEdaLG_YoQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Gv45peeSM2wRQEdaLG_YoQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Gv45peeSM2wRQEdaLG_YoQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Gv45peeSM2wRQEdaLG_YoQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Gv45peeSM2wRQEdaLG_YoQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Gv45peeSM2wRQEdaLG_YoQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Gv45peeSM2wRQEdaLG_YoQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/max/700/1*Gv45peeSM2wRQEdaLG_YoQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Our journey so far</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We start with the basic sliding window algorithm.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>for window in windows<br/>    patch = get_patch(image, window)<br/>    results = detector(patch)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Then we try to reduce the number of windows and move as much work as possible outside the for-loop.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>ROIs = region_proposal(image)<br/>for ROI in ROIs<br/>    patch = get_patch(image, ROI)<br/>    results = detector(patch)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In <a href="https://medium.com/@jonathan_hui/what-do-we-learn-from-single-shot-object-detectors-ssd-yolo-fpn-focal-loss-3888677c5f4d" target="_self">Part 2</a>, we go even further to completely remove the for-loop. Single shot detectors make object detections in single shot without a separate step of region proposal.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Further reading on FPN, R-FCN and Mask R-CNN</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Both FPN and R-FCN are more complex than we described here. For further study, please refer to:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><a href="https://medium.com/@jonathan_hui/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c" target="_self">Feature Pyramid Networks (FPN) for object detection.</a></li><li class="ff3" style="font-size:22px;"><a href="https://medium.com/@jonathan_hui/understanding-region-based-fully-convolutional-networks-r-fcn-for-object-detection-828316f07c99" target="_self">Region-based Fully Convolutional Networks (R-FCN)</a>.</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://medium.com/@jonathan_hui/image-segmentation-with-mask-r-cnn-ebe6d793272"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">Image segmentation with Mask R-CNN</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">In a previous article, we discuss the use of region based object detector like Faster R-CNN to detect objects. Instead…</h3><p>medium.com</p></a></div></div></div></div></section><br><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Resources</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://github.com/facebookresearch/Detectron" target="_self">Detectron</a>: Facebook Research’s implementation of the Faster R-CNN and Mask R-CNN using Caffe2.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The official implementation for the <a href="https://github.com/rbgirshick/py-faster-rcnn" target="_self">Faster R-CNN</a> in MATLAB.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://github.com/endernewton/tf-faster-rcnn" target="_self">Faster R-CNN</a> implementation in TensorFlow.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://github.com/msracver/Deformable-ConvNets" target="_self">R-FCN</a> implementation in MXNet.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://github.com/daijifeng001/R-FCN" target="_self">R-FCN </a>implementation in Caffe and MATLAB.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="https://github.com/xdever/RFCN-tensorflow" target="_self">R-FCN</a> implementation in TensorFlow.</p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>