<!DOCTYPE html>
                <html>
                <head>
                    <title>Inside LLaMA: Meta AI New Large Language Model that Outperforms GPT-3 Across Many Tasks</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://pub.towardsai.net/inside-llama-meta-ai-new-large-language-model-that-outperforms-gpt-3-across-many-tasks-d1e42f23c804"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://jrodthoughts.medium.com/?source=post_page-----d1e42f23c804--------------------------------">Author : Jesus Rodriguez</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Inside LLaMA: Meta AI New Large Language Model that Outperforms GPT-3 Across Many Tasks</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5 text-muted">An open-source implementation of LLaMA is already available.</h4></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*AI4xFlr8mYASsylX.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*AI4xFlr8mYASsylX.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*AI4xFlr8mYASsylX.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*AI4xFlr8mYASsylX.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*AI4xFlr8mYASsylX.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*AI4xFlr8mYASsylX.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AI4xFlr8mYASsylX.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*AI4xFlr8mYASsylX.png 640w, https://miro.medium.com/v2/resize:fit:720/0*AI4xFlr8mYASsylX.png 720w, https://miro.medium.com/v2/resize:fit:750/0*AI4xFlr8mYASsylX.png 750w, https://miro.medium.com/v2/resize:fit:786/0*AI4xFlr8mYASsylX.png 786w, https://miro.medium.com/v2/resize:fit:828/0*AI4xFlr8mYASsylX.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*AI4xFlr8mYASsylX.png 1100w, https://miro.medium.com/v2/resize:fit:1400/0*AI4xFlr8mYASsylX.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/0*AI4xFlr8mYASsylX.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Created Using Midjourney</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">I recently started an AI-focused educational newsletter, that already has over 150,000 subscribers. TheSequence is a no-BS (meaning no hype, no news etc) ML-oriented newsletter that takes 5 minutes to read. The goal is to keep you up to date with machine learning projects, research papers and concepts. Please give it a try by subscribing below:</p></blockquote></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://thesequence.substack.com/"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">TheSequence | Jesus Rodriguez | Substack</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">The best source to stay up-to-date with the developments in the machine learning, artificial intelligence, and data…</h3><p>thesequence.substack.com</p></a></div></div></div></div></section><br><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Large Language Models (LLMs) have recently taken the world by storm with their remarkable ability to perform new tasks from textual instructions or a few examples. This ability, known as few-shot learning, was first observed when models were scaled up to a sufficient size. As a result, researchers have focused on scaling these models even further. The general assumption is that more parameters will lead to better performance. However, recent research has shown that, for a given compute budget, the best performance is not achieved by the largest models. Instead, smaller models trained on more data outperform their larger counterparts. In that context, <a href="https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/" target="_self">Meta AI recently published a paper detailing LLaMA</a>, a 65B LLM that is able to outperform GPT-3 across many tasks despite being significantly smaller.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The core principle behind LLaMA is to achieve the best possible performance at various inference budgets by training on more tokens than what is typically used. LLaMA ranges from 7B to 65B parameters and has competitive performance compared to the best existing LLMs. For instance, LLaMA-13B outperforms GPT-3 on most benchmarks despite being 10× smaller. This model is likely to democratize the access and study of LLMs since it can be run on a single GPU. At the higher end of the scale, the 65B-parameter model is also competitive with the best large language models such as Chinchilla or PaLM-540B.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">What sets LLaMA apart from other models is that it only uses publicly available data, making it compatible with open sourcing. Most existing models rely on data that is either not publicly available or undocumented. Although there are some exceptions, such as OPT, GPT-NeoX, BLOOM, and GLM, none of them are competitive with PaLM-62B or Chinchilla.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Architecture</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">LLaMA’s mode is based on a standard transformer architecture, incorporating various improvements from recent research, such as pre-normalization, SwiGLU activation function, and rotary embeddings. To enhance training stability, LLaMA normalizes the input of each transformer sub-layer using the RMSNorm normalizing function instead of normalizing the output as in the original architecture. Additionally, LLaMA replaces the ReLU non-linearity with the SwiGLU activation function to improve performance, using a dimension of 234d as well as the absolute positional embeddings and adding rotary positional embeddings at each layer of the network to reduce computational overhead.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To enhance training efficiency, Meta AI used an efficient implementation of the causal multi-head attention operator, reducing memory usage and computation together with checkpointing to save expensive activations during the backward pass and manually implement the backward function for the transformer layers to reduce the number of activations that need to be recomputed. Finally, To reduce memory usage further, LLaMA relies on model and sequence parallelism and overlap computation of activations and communication between GPUs over the network. The result was visible during the training of the 65B-parameter model. LLaMA processed approximately 380 tokens/sec/GPU on 2048 A100 GPUs with 80GB of RAM, taking around 21 days to train over our dataset containing 1.4T tokens.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">LLaMA was evaluated on 20 benchmarks, including zero-shot and few-shot tasks, and compared it with other foundation models, such as GPT-3, Gopher, Chinchilla, and PaLM, along with OPT models, GPT-J, and GPTNeo. Results showed that LLaMA was able to outperform GPT-3 despite being 10 times smaller in size.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:34%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 269px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*SHdmbeFMwQmIXWZhN-gyow.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*SHdmbeFMwQmIXWZhN-gyow.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*SHdmbeFMwQmIXWZhN-gyow.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*SHdmbeFMwQmIXWZhN-gyow.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*SHdmbeFMwQmIXWZhN-gyow.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*SHdmbeFMwQmIXWZhN-gyow.png 1100w, https://miro.medium.com/v2/resize:fit:538/format:webp/1*SHdmbeFMwQmIXWZhN-gyow.png 538w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 269px" srcset="https://miro.medium.com/v2/resize:fit:640/1*SHdmbeFMwQmIXWZhN-gyow.png 640w, https://miro.medium.com/v2/resize:fit:720/1*SHdmbeFMwQmIXWZhN-gyow.png 720w, https://miro.medium.com/v2/resize:fit:750/1*SHdmbeFMwQmIXWZhN-gyow.png 750w, https://miro.medium.com/v2/resize:fit:786/1*SHdmbeFMwQmIXWZhN-gyow.png 786w, https://miro.medium.com/v2/resize:fit:828/1*SHdmbeFMwQmIXWZhN-gyow.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*SHdmbeFMwQmIXWZhN-gyow.png 1100w, https://miro.medium.com/v2/resize:fit:538/1*SHdmbeFMwQmIXWZhN-gyow.png 538w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:269/1*SHdmbeFMwQmIXWZhN-gyow.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image Credit: Meta AI</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">LLaMA in Action</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Some of the results of LLaMA are incredibly sophisticated and factually accurate, showing strong signs of reasoning.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:80%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 592px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*CwffYbidulgx8wHpZZRh7w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*CwffYbidulgx8wHpZZRh7w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*CwffYbidulgx8wHpZZRh7w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*CwffYbidulgx8wHpZZRh7w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*CwffYbidulgx8wHpZZRh7w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*CwffYbidulgx8wHpZZRh7w.png 1100w, https://miro.medium.com/v2/resize:fit:1184/format:webp/1*CwffYbidulgx8wHpZZRh7w.png 1184w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 592px" srcset="https://miro.medium.com/v2/resize:fit:640/1*CwffYbidulgx8wHpZZRh7w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*CwffYbidulgx8wHpZZRh7w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*CwffYbidulgx8wHpZZRh7w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*CwffYbidulgx8wHpZZRh7w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*CwffYbidulgx8wHpZZRh7w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*CwffYbidulgx8wHpZZRh7w.png 1100w, https://miro.medium.com/v2/resize:fit:1184/1*CwffYbidulgx8wHpZZRh7w.png 1184w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:592/1*CwffYbidulgx8wHpZZRh7w.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image Credit: Meta AI</p><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:76%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 564px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Dd0lct1y8-M5Uqlj5yOLog.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Dd0lct1y8-M5Uqlj5yOLog.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Dd0lct1y8-M5Uqlj5yOLog.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Dd0lct1y8-M5Uqlj5yOLog.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Dd0lct1y8-M5Uqlj5yOLog.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Dd0lct1y8-M5Uqlj5yOLog.png 1100w, https://miro.medium.com/v2/resize:fit:1128/format:webp/1*Dd0lct1y8-M5Uqlj5yOLog.png 1128w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 564px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Dd0lct1y8-M5Uqlj5yOLog.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Dd0lct1y8-M5Uqlj5yOLog.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Dd0lct1y8-M5Uqlj5yOLog.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Dd0lct1y8-M5Uqlj5yOLog.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Dd0lct1y8-M5Uqlj5yOLog.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Dd0lct1y8-M5Uqlj5yOLog.png 1100w, https://miro.medium.com/v2/resize:fit:1128/1*Dd0lct1y8-M5Uqlj5yOLog.png 1128w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:564/1*Dd0lct1y8-M5Uqlj5yOLog.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image Credit: Meta AI</p><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:77%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 572px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*UiMq0lYRx1uX_CstJ2beLQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*UiMq0lYRx1uX_CstJ2beLQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*UiMq0lYRx1uX_CstJ2beLQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*UiMq0lYRx1uX_CstJ2beLQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*UiMq0lYRx1uX_CstJ2beLQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*UiMq0lYRx1uX_CstJ2beLQ.png 1100w, https://miro.medium.com/v2/resize:fit:1144/format:webp/1*UiMq0lYRx1uX_CstJ2beLQ.png 1144w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 572px" srcset="https://miro.medium.com/v2/resize:fit:640/1*UiMq0lYRx1uX_CstJ2beLQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*UiMq0lYRx1uX_CstJ2beLQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*UiMq0lYRx1uX_CstJ2beLQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*UiMq0lYRx1uX_CstJ2beLQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*UiMq0lYRx1uX_CstJ2beLQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*UiMq0lYRx1uX_CstJ2beLQ.png 1100w, https://miro.medium.com/v2/resize:fit:1144/1*UiMq0lYRx1uX_CstJ2beLQ.png 1144w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:572/1*UiMq0lYRx1uX_CstJ2beLQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image Credit: Meta AI</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">The First LLaMA Implementation</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">LLaMA hasn’t been open-sourced yet. However, not wasting any time, AI startup Nebuly released ChatLLaMA, an open-source implementation of LLaMA based on RLHF. ChatLLaMA enables the implementation of ChatGPT-style service using pre-trained LLaMA models. Compared to the original ChatGPT, ChatLLaMA offers faster and cheaper training processes and single-GPU inference, thanks to the smaller size of LLaMA architectures. Plus, the library includes built-in support for DeepSpeed ZERO, allowing you to speed up the fine-tuning process. ChatLLaMA also supports all LLaMA model architectures (7B, 13B, 33B, 65B), giving you the flexibility to fine-tune the model based on your preferences for training time and inference performance.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The code for using ChatLLaMA is super simple, as illustrated below:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><span>from</span> chatllama.rlhf.trainer <span>import</span> RLTrainer<br/><span>from</span> chatllama.rlhf.config <span>import</span> Config<br/><br/>path = <span>"path_to_config_file.yaml"</span><br/>config = Config(path=path)<br/>trainer = RLTrainer(config.trainer)<br/>trainer.distillate()<br/>trainer.train()<br/>trainer.training_stats.plot()</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">LLaMA is certainly a very interesting development in the LLM space. Meta AI has <a href="https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform" target="_self">enabled early access to the model</a>. Hopefully, a generally available release will be available soon.</p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>