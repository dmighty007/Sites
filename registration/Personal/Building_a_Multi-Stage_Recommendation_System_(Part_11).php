<!DOCTYPE html>
                <html>
                <head>
                    <title>Building a Multi-Stage Recommendation System (Part 1.1)</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/mlearning-ai/building-a-multi-stage-recommendation-system-part-1-1-95961ccf3dd8"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@biarnes-adrien?source=post_page-----95961ccf3dd8--------------------------------">Author : Adrien Biarnes</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Building a Multi-Stage Recommendation System (Part 1.1)</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5 text-muted">Understanding candidate generation and the two-tower model</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Introduction</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this blog post, we will first discover why multi-step recommendation should be the go-to strategy for companies with large item catalogs. Then we will move on to describe one of the famous latest architecture for candidate generation, namely the two tower architecture. In <a href="https://medium.com/mlearning-ai/building-a-multi-stage-recommendation-system-part-1-2-ce006f0825d1" target="_self">the subsequent post</a>, we will also implement this model and apply it using the H&M Kaggle competition dataset.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*v3vWFYmejaHzx1GSLVngaw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*v3vWFYmejaHzx1GSLVngaw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*v3vWFYmejaHzx1GSLVngaw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*v3vWFYmejaHzx1GSLVngaw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*v3vWFYmejaHzx1GSLVngaw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*v3vWFYmejaHzx1GSLVngaw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v3vWFYmejaHzx1GSLVngaw.jpeg 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*v3vWFYmejaHzx1GSLVngaw.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/1*v3vWFYmejaHzx1GSLVngaw.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/1*v3vWFYmejaHzx1GSLVngaw.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/1*v3vWFYmejaHzx1GSLVngaw.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/1*v3vWFYmejaHzx1GSLVngaw.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/1*v3vWFYmejaHzx1GSLVngaw.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1400/1*v3vWFYmejaHzx1GSLVngaw.jpeg 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*v3vWFYmejaHzx1GSLVngaw.jpeg"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: <a href="https://dl.acm.org/doi/10.1145/2959100.2959190" target="_self">Youtube 2016 paper</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Recommendation systems are one of the hottest areas in tech and more specifically in machine learning right now. And this is for the very reason that it is one of the most profitable and applicable areas of machine learning business-wise. They can be used in a huge variety of contexts for almost any business selling goods or services to clients by enabling them to deal with information overload.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Why multi-stage recommendation and not single-stage?</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>TL;DR</strong>: To me, the most important reasons to go from single stage recommender to multi-stage one are the following:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">Potential to recommend a much larger corpus of items</li><li class="ff3" style="font-size:22px;">Under a fixed computational budget one can hope for a much better performance because:<br></br>- Instead of having a single model trying to reach the best balance between precision and recall you can split the burden in two. The candidate generator is specialized into reaching the best possible recall and the ranker shoots for precision.<br></br>- Because when you reach the ranking step you have much smaller subset of candidates to score which allows you to use very heavyweight model and still match the execution time constraints</li><li class="ff3" style="font-size:22px;">A great increase in modeling flexibility and greater control of your recommendation. You can indeed decide to stack multi candidate generators, each one specialized on a different aspect. For example, you can easily add a policy that proposes new items randomly in order to have a greater control over the exploration/exploitation trade-off</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As a data scientist or machine learning engineer, when you start to learn about recommendation systems, you spend the majority of your time learning about the different modeling approaches and core models like k-NN, Matrix Factorization, Factorization Machines, Bayesian Probabilistic Ranking... before switching to more advanced ones like neural networks. From my point of view, all these topics are extremely important and if you want to get serious about recommender systems you must understand these algorithms very well. But when working in the industry, you’ll quickly realize that there are a set of prominent challenges that you must consider and work on very thoroughly. For me, the most important ones are :</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><mark>the cold start problem or how to deal with new items and new users</mark></li><li class="ff3" style="font-size:22px;">the <a href="https://arxiv.org/abs/1703.01049" target="_self">feedback loop issues</a> when using log training data</li><li class="ff3" style="font-size:22px;">counter-factual reasoning or how to reduce the gap between offline and online evaluation</li><li class="ff3" style="font-size:22px;">and the last one that we will address in this blog post: how to deal with very large action spaces efficiently?</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So let’s say you are designing a recommendation system for YouTube. You have several hundred million videos (potentially billions) in your catalog. You want your recommendation to be very accurate and personalized to the user and the context. This means that you’ll eventually have to generate and exploit a lot of features about the item, the user, the context, and the cross-combination of these categories with additional statistics like counts and ratios. A lot of these features will be categorical with potentially very high cardinalities. Now adding to that, that you want to exploit the new shiny transformer architecture you’ll have a very hard time matching the execution time constraints that you are being given to produce recommendations.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Indeed, quoting Eugene Yann’s <a href="https://eugeneyan.com/writing/real-time-recommendations/" target="_self">blog post about real-time recommendations</a>: “<em>Google found that taking an additional 500ms to generate search results </em><a href="https://glinden.blogspot.com/2006/11/marissa-mayer-at-web-20.html" target="_self">reduced traffic by 20%</a><em>. Amazon shared that 100ms additional latency </em><a href="http://radar.oreilly.com/2008/08/radar-theme-web-ops.html" target="_self">reduces profit by 1%</a><em>”. </em>In addition to responsiveness, latency requirements can also come from third parties. It is the case for real-time advertisement bidding platforms for example. When engaged in a bid, Criteo only has a few milliseconds to choose the products to show to the user (from billions of candidates). If the requirement is not met, Criteo looses the bid (and potentially money).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So imagine that you have a catalog of 1 billion videos that you must choose from to display a dozen ones to the user. If you have let’s say 200 milliseconds to make the call, you can spend as little as 0.2 nanoseconds (10^-9) on a candidate to decide whether it is a better choice than the other candidates. Obviously in such a short amount of time you won’t be able to compute much.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The solution to this problem is to avoid scoring all the potential candidates that you have in your catalog. One simple way to do it is to implement business rules based for example on popularity. You can, for example, say that you only want to score the most popular items of the last 2 weeks or only the items from same channels or same topic. This is perfectly fine and should probably be assessed before moving on to fancier solutions.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">But using business rules you will probably hit a wall pretty quickly. Let’s consider the case where you are trying to suggest content to watch after a specific video and you only consider the most popular items as candidates. If your query video is about a very niche topic only liked by a handful of your users it is very likely that the most relevant videos to suggest are also niche and will never be part of your most popular candidates.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In order to solve this problem as best as we can with a machine learning approach we will want to do 2 things:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">Create a representation space where we can represent a query video and the potential candidates so that the most relevant videos to consider are close to each other</li><li class="ff3" style="font-size:22px;">Use a vector database to efficiently store and query similar items</li></ol></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:69%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 512px" srcset="https://miro.medium.com/v2/resize:fit:640/1*oQesVSwU48t_BaQbyiMDuw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*oQesVSwU48t_BaQbyiMDuw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*oQesVSwU48t_BaQbyiMDuw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*oQesVSwU48t_BaQbyiMDuw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*oQesVSwU48t_BaQbyiMDuw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*oQesVSwU48t_BaQbyiMDuw.gif 1100w, https://miro.medium.com/v2/resize:fit:1024/1*oQesVSwU48t_BaQbyiMDuw.gif 1024w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 512px" srcset="https://miro.medium.com/v2/resize:fit:640/1*oQesVSwU48t_BaQbyiMDuw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*oQesVSwU48t_BaQbyiMDuw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*oQesVSwU48t_BaQbyiMDuw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*oQesVSwU48t_BaQbyiMDuw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*oQesVSwU48t_BaQbyiMDuw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*oQesVSwU48t_BaQbyiMDuw.gif 1100w, https://miro.medium.com/v2/resize:fit:1024/1*oQesVSwU48t_BaQbyiMDuw.gif 1024w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:512/1*oQesVSwU48t_BaQbyiMDuw.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: <a href="http://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html" target="_self">Announcing ScaNN: Efficient Vector Similarity Search</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Two tower model</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This modern approach to candidate generation is gaining more and more traction because of its effectiveness. The idea is that one deep neural network tower computes the query embedding and another tower computes the candidate embedding. We can then simply compute the dot product between the two embeddings to determine how close the candidate is to the query (recall that the dot product is the unnormalized version of the cosine similarity, it is a measure of similarity).</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*IB4_8V05kAdN_jMJvgER-w.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*IB4_8V05kAdN_jMJvgER-w.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*IB4_8V05kAdN_jMJvgER-w.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*IB4_8V05kAdN_jMJvgER-w.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*IB4_8V05kAdN_jMJvgER-w.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*IB4_8V05kAdN_jMJvgER-w.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*IB4_8V05kAdN_jMJvgER-w.gif 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*IB4_8V05kAdN_jMJvgER-w.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*IB4_8V05kAdN_jMJvgER-w.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*IB4_8V05kAdN_jMJvgER-w.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*IB4_8V05kAdN_jMJvgER-w.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*IB4_8V05kAdN_jMJvgER-w.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*IB4_8V05kAdN_jMJvgER-w.gif 1100w, https://miro.medium.com/v2/resize:fit:1400/1*IB4_8V05kAdN_jMJvgER-w.gif 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*IB4_8V05kAdN_jMJvgER-w.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: <a href="https://blog.tensorflow.org/2020/09/introducing-tensorflow-recommenders.html" target="_self">https://blog.tensorflow.org/2020/09/introducing-tensorflow-recommenders.html</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">One nice benefit of this approach is that it also unlocks engineering optimizations. Indeed, one can simply cache the candidates and query representations which saves a lot of compute at inference time. All the extra compute will then be available for the next step in the pipeline (the ranking step) so as to increase precision even more. But caching is a tradeoff. The cached representation won’t embed the latest informations which can be of a problem depending on the nature of the data. For example if you use the number of displays as a feature, then your cached representation will be outdated at the time of inference.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">It is also noticeable that all the major players in the industry are currently using this architecture in production. For example, the below diagram, extracted from Pinterest’s engineering blog, describes the two tower architecture that they have recently deploy to unify their candidate generation approaches for the home.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Ta5EPHN3goa-rmSw4qYCOg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*Ta5EPHN3goa-rmSw4qYCOg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*Ta5EPHN3goa-rmSw4qYCOg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*Ta5EPHN3goa-rmSw4qYCOg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*Ta5EPHN3goa-rmSw4qYCOg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Ta5EPHN3goa-rmSw4qYCOg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ta5EPHN3goa-rmSw4qYCOg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*Ta5EPHN3goa-rmSw4qYCOg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*Ta5EPHN3goa-rmSw4qYCOg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*Ta5EPHN3goa-rmSw4qYCOg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*Ta5EPHN3goa-rmSw4qYCOg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*Ta5EPHN3goa-rmSw4qYCOg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*Ta5EPHN3goa-rmSw4qYCOg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*Ta5EPHN3goa-rmSw4qYCOg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*Ta5EPHN3goa-rmSw4qYCOg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: <a href="https://medium.com/pinterest-engineering/pinterest-home-feed-unified-lightweight-scoring-a-two-tower-approach-b3143ac70b55" target="_self">Pinterest’s engineering blog post</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Another blog post from Twitter describes the two-tower architecture they deployed for accounts recommendations:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*66WV7RCzS2dv4_C4-_gsRw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*66WV7RCzS2dv4_C4-_gsRw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*66WV7RCzS2dv4_C4-_gsRw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*66WV7RCzS2dv4_C4-_gsRw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*66WV7RCzS2dv4_C4-_gsRw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*66WV7RCzS2dv4_C4-_gsRw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*66WV7RCzS2dv4_C4-_gsRw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*66WV7RCzS2dv4_C4-_gsRw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*66WV7RCzS2dv4_C4-_gsRw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*66WV7RCzS2dv4_C4-_gsRw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*66WV7RCzS2dv4_C4-_gsRw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*66WV7RCzS2dv4_C4-_gsRw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*66WV7RCzS2dv4_C4-_gsRw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*66WV7RCzS2dv4_C4-_gsRw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*66WV7RCzS2dv4_C4-_gsRw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: <a href="https://blog.twitter.com/engineering/en_us/topics/insights/2022/model-based-candidate-generation-for-account-recommendations" target="_self">Twitter — Model-based candidate generation for account recommendations</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">YouTube also made modifications to their candidate generation model from <a href="https://dl.acm.org/doi/10.1145/2959100.2959190" target="_self">the 2016 paper</a> to match a two tower architecture (as seen in <a href="https://research.google/pubs/pub48840/" target="_self">their 2019 paper</a>):</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*6BTyKWuCGzFibB8UJtHVKg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*6BTyKWuCGzFibB8UJtHVKg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*6BTyKWuCGzFibB8UJtHVKg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*6BTyKWuCGzFibB8UJtHVKg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*6BTyKWuCGzFibB8UJtHVKg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*6BTyKWuCGzFibB8UJtHVKg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6BTyKWuCGzFibB8UJtHVKg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*6BTyKWuCGzFibB8UJtHVKg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*6BTyKWuCGzFibB8UJtHVKg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*6BTyKWuCGzFibB8UJtHVKg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*6BTyKWuCGzFibB8UJtHVKg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*6BTyKWuCGzFibB8UJtHVKg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*6BTyKWuCGzFibB8UJtHVKg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*6BTyKWuCGzFibB8UJtHVKg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*6BTyKWuCGzFibB8UJtHVKg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: <a href="https://research.google/pubs/pub48840/" target="_self">YouTube RecSys 2019 paper</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The attentive reader will have seen that the penultimate layer of YouTube architecture above is the L2 normalization. Adding this computaion before the dot product allows to use the cosine similarity as the measure of similarity between queries and candidates.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now how does this model work exactly ?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">I think that by looking at the diagrams you can already understand quite a good deal of the internals. We have one tower for the query and one tower for the candidate. The query can be a user in a user-2-item scenario like a home feed or an item in an item-2-item scenario like a related items recommendation. For each tower, we take a bunch of a categorical and continuous features that we embed and project into an multi-layer perceptron. At the end, the representation of the query has to be as similar as possible to the representation of your positive candidate in the final embedding space. This means that query and items live in the same space. Now there is still a few important questions that we want to address:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">How do we train this model ?</li><li class="ff3" style="font-size:22px;">How do we serve it ?</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Training a two-tower model</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Nowadays, everyone has switched to using implicit engagement data. For this to work, we need to record every user interaction on the platform. We can then consider every interaction as a positive engagement signal (a click on a recommended video for example). Every user-item pair for which the user did not have an interaction is considered to be a potential negative signal (this is called missing as negatives strategy). Implicit data is much noisier but it is way better than explicit data (like thumbs up or 5 stars ratings) because the volume is much more important (especially if you train neural networks).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">One of the first questions I always ask myself and which I think is one of the most important drivers to understand a model is: how is this problem framed as a machine learning task? In the case of candidate generation, we usually frame it as a supervised multi-class classification task. For each observation in the dataset, we want to accurately output the correct label among the set of possible labels. In this case, the number of possibilities is huge which is why we also talk about extreme multi-class classification.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now if we look at the diagrams we see that the output of the network is the dot product between the two tower embeddings which will result in a scalar. So how does that translate to a multi-class classification problem?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Well, this is pretty easy. I will first explain this in plain English, then give a more formal definition. Given a pair of query and item that positively interacted, we extract their respective features. We then forward propagate the features into the two towers and obtain the two representations from which we can compute the dot product representing their similarity.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This will allow us to score one pair of items. But we want to do multi-class classification. This means that we need to score all the other items in the catalog. Well, to do that, we can simply repeat the scoring process. We can forward propagate the other items that we consider to be the negatives into the candidate item tower to compute their representations and get the similarities between the negative items and the query.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Finally, we will obtain one score for every item in our catalog representing its similarity with the query. In the end, we simply select the candidate with the maximum similarity score.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now there are two problems with this simple procedure:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">The selection of the candidate with the maximum similarity score requires using the max operation which is not differentiable out of the box. And we need every computation to be differentiable to learn using backpropagation. So what we do instead is use the smoothen differentiable version of the max operation which is the softmax. The softmax applied on the output score vector will give us a probability vector which we can then use in the cross-entropy loss to obtain an end-to-end trainable network.</li><li class="ff3" style="font-size:22px;">Computing the representation vector of every single candidate in the catalog is way too expensive. So we simply compute the similarity scores for a set of sampled negative items and compute the softmax over these scores.</li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Formally, we define the set of queries <strong>X</strong> and candidate items <strong>Y</strong> by the sets of feature vectors:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:42%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 328px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*nYRcgCuIbK69Pzr-F1aG9g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*nYRcgCuIbK69Pzr-F1aG9g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*nYRcgCuIbK69Pzr-F1aG9g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*nYRcgCuIbK69Pzr-F1aG9g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*nYRcgCuIbK69Pzr-F1aG9g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*nYRcgCuIbK69Pzr-F1aG9g.png 1100w, https://miro.medium.com/v2/resize:fit:656/format:webp/1*nYRcgCuIbK69Pzr-F1aG9g.png 656w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 328px" srcset="https://miro.medium.com/v2/resize:fit:640/1*nYRcgCuIbK69Pzr-F1aG9g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*nYRcgCuIbK69Pzr-F1aG9g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*nYRcgCuIbK69Pzr-F1aG9g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*nYRcgCuIbK69Pzr-F1aG9g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*nYRcgCuIbK69Pzr-F1aG9g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*nYRcgCuIbK69Pzr-F1aG9g.png 1100w, https://miro.medium.com/v2/resize:fit:656/1*nYRcgCuIbK69Pzr-F1aG9g.png 656w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:328/1*nYRcgCuIbK69Pzr-F1aG9g.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Then we define the two towers as two embedding functions <strong>u</strong> and <strong>v</strong> that map their parameters <strong>θ </strong>along with the input features of dimension <strong>d</strong> to a <strong>k</strong> dimensional embedding space:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*DscpruGS5-KVt-AV4pJ-GA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*DscpruGS5-KVt-AV4pJ-GA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*DscpruGS5-KVt-AV4pJ-GA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*DscpruGS5-KVt-AV4pJ-GA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*DscpruGS5-KVt-AV4pJ-GA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*DscpruGS5-KVt-AV4pJ-GA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DscpruGS5-KVt-AV4pJ-GA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*DscpruGS5-KVt-AV4pJ-GA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*DscpruGS5-KVt-AV4pJ-GA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*DscpruGS5-KVt-AV4pJ-GA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*DscpruGS5-KVt-AV4pJ-GA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*DscpruGS5-KVt-AV4pJ-GA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*DscpruGS5-KVt-AV4pJ-GA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*DscpruGS5-KVt-AV4pJ-GA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*DscpruGS5-KVt-AV4pJ-GA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now we define the dot product similarity score:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:78%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 578px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*SGGLCHg1iIo2vxs9hraxdw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*SGGLCHg1iIo2vxs9hraxdw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*SGGLCHg1iIo2vxs9hraxdw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*SGGLCHg1iIo2vxs9hraxdw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*SGGLCHg1iIo2vxs9hraxdw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*SGGLCHg1iIo2vxs9hraxdw.png 1100w, https://miro.medium.com/v2/resize:fit:1156/format:webp/1*SGGLCHg1iIo2vxs9hraxdw.png 1156w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 578px" srcset="https://miro.medium.com/v2/resize:fit:640/1*SGGLCHg1iIo2vxs9hraxdw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*SGGLCHg1iIo2vxs9hraxdw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*SGGLCHg1iIo2vxs9hraxdw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*SGGLCHg1iIo2vxs9hraxdw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*SGGLCHg1iIo2vxs9hraxdw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*SGGLCHg1iIo2vxs9hraxdw.png 1100w, https://miro.medium.com/v2/resize:fit:1156/1*SGGLCHg1iIo2vxs9hraxdw.png 1156w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:578/1*SGGLCHg1iIo2vxs9hraxdw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*vQzq7zuyPEj-25G10GAOrQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*vQzq7zuyPEj-25G10GAOrQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*vQzq7zuyPEj-25G10GAOrQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*vQzq7zuyPEj-25G10GAOrQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*vQzq7zuyPEj-25G10GAOrQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*vQzq7zuyPEj-25G10GAOrQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vQzq7zuyPEj-25G10GAOrQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*vQzq7zuyPEj-25G10GAOrQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*vQzq7zuyPEj-25G10GAOrQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*vQzq7zuyPEj-25G10GAOrQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*vQzq7zuyPEj-25G10GAOrQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*vQzq7zuyPEj-25G10GAOrQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*vQzq7zuyPEj-25G10GAOrQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*vQzq7zuyPEj-25G10GAOrQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*vQzq7zuyPEj-25G10GAOrQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: <a href="https://research.google/pubs/pub48840/" target="_self">YoutTube 2019 paper</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The softmax operation is used to define the probability of a candidate item to be the closest candidate given the query and the model parameters:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:61%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 460px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*yQwbBXQXznJWCyTY9pLR1A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*yQwbBXQXznJWCyTY9pLR1A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*yQwbBXQXznJWCyTY9pLR1A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*yQwbBXQXznJWCyTY9pLR1A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*yQwbBXQXznJWCyTY9pLR1A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*yQwbBXQXznJWCyTY9pLR1A.png 1100w, https://miro.medium.com/v2/resize:fit:920/format:webp/1*yQwbBXQXznJWCyTY9pLR1A.png 920w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 460px" srcset="https://miro.medium.com/v2/resize:fit:640/1*yQwbBXQXznJWCyTY9pLR1A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*yQwbBXQXznJWCyTY9pLR1A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*yQwbBXQXznJWCyTY9pLR1A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*yQwbBXQXznJWCyTY9pLR1A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*yQwbBXQXznJWCyTY9pLR1A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*yQwbBXQXznJWCyTY9pLR1A.png 1100w, https://miro.medium.com/v2/resize:fit:920/1*yQwbBXQXznJWCyTY9pLR1A.png 920w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:460/1*yQwbBXQXznJWCyTY9pLR1A.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Finally equipped with the candidate probabilities, and given that we have T observations in the dataset, we can define the loss function as the usual cross entropy loss (or negative log likelihood as you wish to call it).</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:65%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 486px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*L4kBCT0O93OxfmzAVAnAqg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*L4kBCT0O93OxfmzAVAnAqg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*L4kBCT0O93OxfmzAVAnAqg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*L4kBCT0O93OxfmzAVAnAqg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*L4kBCT0O93OxfmzAVAnAqg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*L4kBCT0O93OxfmzAVAnAqg.png 1100w, https://miro.medium.com/v2/resize:fit:972/format:webp/1*L4kBCT0O93OxfmzAVAnAqg.png 972w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 486px" srcset="https://miro.medium.com/v2/resize:fit:640/1*L4kBCT0O93OxfmzAVAnAqg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*L4kBCT0O93OxfmzAVAnAqg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*L4kBCT0O93OxfmzAVAnAqg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*L4kBCT0O93OxfmzAVAnAqg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*L4kBCT0O93OxfmzAVAnAqg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*L4kBCT0O93OxfmzAVAnAqg.png 1100w, https://miro.medium.com/v2/resize:fit:972/1*L4kBCT0O93OxfmzAVAnAqg.png 972w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:486/1*L4kBCT0O93OxfmzAVAnAqg.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Negative sampling strategies for two tower models</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As I wrote earlier, scoring every possible item in the catalog is by no means a viable strategy when you have millions of items. The only way forward is to use negative sampling strategies. I will here discuss the most common and simple strategy. There is in reality quite a good deal of sampling strategies and I can’t cover them all in this simple blog post.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The most commonly found strategy is called in-batch negative sampling. The idea is basically, for a specific observation in a batch we consider every other observations in this same batch as negatives. Here is a schema extracted from the 2018 paper “<a href="https://arxiv.org/pdf/1706.03847.pdf" target="_self">Recurrent Neural Networks with Top-k Gains for Session-based Recommendations</a>” by Hidasi et al.:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*TSgV1Aj63vuAaPSMyJQrQQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*TSgV1Aj63vuAaPSMyJQrQQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*TSgV1Aj63vuAaPSMyJQrQQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*TSgV1Aj63vuAaPSMyJQrQQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*TSgV1Aj63vuAaPSMyJQrQQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*TSgV1Aj63vuAaPSMyJQrQQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TSgV1Aj63vuAaPSMyJQrQQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*TSgV1Aj63vuAaPSMyJQrQQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*TSgV1Aj63vuAaPSMyJQrQQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*TSgV1Aj63vuAaPSMyJQrQQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*TSgV1Aj63vuAaPSMyJQrQQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*TSgV1Aj63vuAaPSMyJQrQQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*TSgV1Aj63vuAaPSMyJQrQQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*TSgV1Aj63vuAaPSMyJQrQQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*TSgV1Aj63vuAaPSMyJQrQQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So in the above case, with a batch size of 3 we are expected to score 3 different candidates resulting in an output vector of size 3 to feed the softmax and subsequently compute the cross-entropy loss for the batch. In the case of the two tower model, what we do is simply forward propagate the query-item pairs of the batch in the two towers which gives us the query and the item representations. We then have all we need to compute the loss.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now one important thing to consider is that by sampling negative items we get an approximation of the full softmax that can be severely biased. Indeed, item frequencies follow a power-law distribution. So in any given batch, it is much more likely to find popular items than niche content. This means that popular items will be used much more frequently as negatives and therefore will be much more penalized. To correct for this, and compute an unbiased estimate of the full softmax, we generally subtract the log of the sampling probabilities of the items to the logit scores (the score before the softmax). Check out <a href="https://www.tensorflow.org/extras/candidate_sampling.pdf" target="_self">this article</a> from the TensorFlow team if you want the math derivations that led to this formula.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*6W-c2BdCkV8V7CbSUOD0Yg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*6W-c2BdCkV8V7CbSUOD0Yg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*6W-c2BdCkV8V7CbSUOD0Yg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*6W-c2BdCkV8V7CbSUOD0Yg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*6W-c2BdCkV8V7CbSUOD0Yg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*6W-c2BdCkV8V7CbSUOD0Yg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6W-c2BdCkV8V7CbSUOD0Yg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*6W-c2BdCkV8V7CbSUOD0Yg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*6W-c2BdCkV8V7CbSUOD0Yg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*6W-c2BdCkV8V7CbSUOD0Yg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*6W-c2BdCkV8V7CbSUOD0Yg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*6W-c2BdCkV8V7CbSUOD0Yg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*6W-c2BdCkV8V7CbSUOD0Yg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*6W-c2BdCkV8V7CbSUOD0Yg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*6W-c2BdCkV8V7CbSUOD0Yg.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Evaluating a two-tower model</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As with any machine learning model, we need to split the dataset into a training and a validation set. There is nothing specific here apart from the fact that recommendation logs dataset do have a temporal component. This means that we need to perform a temporal split (keeping for example the last day user interactions for the validation set) in order to avoid any information leakage.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The only thing important to state here which is not necessarily specific to the two-tower model but rather to any candidate generation model is that we want to optimize for recall. This means that the most important metric to monitor is the recall up to the number of elements we want to send to the ranker. Most commonly found metrics lie in the range Recall@100 to Recall@1000.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Serving a two-tower model</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So once the model is trained, how do move forward and put it in production? Recall that our goal at serving time is to retrieve the K (say 1000) most interesting items given the query that will further be ranked by the ranker to display the final subset of items that should be the most relevant (say a dozen).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The two-tower model gives us query representations that leave in the same space as candidate representations. This allows us to retrieve the most interesting candidates given a query by simply computing the dot product between the query and the candidates. Now recall also that we don’t want to assess the full spectrum of candidates. We want a sub-linear search mechanism. This is where the need of a vector database that perform approximate neighbors search arises. For now, we won’t get into the details of this search in sub-linear time is performed. Just be aware that it exists and can give us the K most similar vector to a given vector very efficiently.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">At inference, the candidate generation can be decomposed in 2 steps:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">Compute the query representation</li><li class="ff3" style="font-size:22px;">Find the K candidate representations most similar to the query representation</li></ol></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*__OUa9H2o9LaM6gQPfINBw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*__OUa9H2o9LaM6gQPfINBw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*__OUa9H2o9LaM6gQPfINBw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*__OUa9H2o9LaM6gQPfINBw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*__OUa9H2o9LaM6gQPfINBw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*__OUa9H2o9LaM6gQPfINBw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*__OUa9H2o9LaM6gQPfINBw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*__OUa9H2o9LaM6gQPfINBw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*__OUa9H2o9LaM6gQPfINBw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*__OUa9H2o9LaM6gQPfINBw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*__OUa9H2o9LaM6gQPfINBw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*__OUa9H2o9LaM6gQPfINBw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*__OUa9H2o9LaM6gQPfINBw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*__OUa9H2o9LaM6gQPfINBw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*__OUa9H2o9LaM6gQPfINBw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image from author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In order to perform step 2 we first need to build the nearest neighbor index. This requires another offline pipeline in addition to the traditional training pipeline. For every possible item in the catalog, its responsibility is to compute the vector representation v(x) and store it in vector database (in the form of a nearest neighbor index).</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:39%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 307px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*7dZtKhOASeqYJqp0haxbrA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*7dZtKhOASeqYJqp0haxbrA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*7dZtKhOASeqYJqp0haxbrA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*7dZtKhOASeqYJqp0haxbrA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*7dZtKhOASeqYJqp0haxbrA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*7dZtKhOASeqYJqp0haxbrA.png 1100w, https://miro.medium.com/v2/resize:fit:614/format:webp/1*7dZtKhOASeqYJqp0haxbrA.png 614w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 307px" srcset="https://miro.medium.com/v2/resize:fit:640/1*7dZtKhOASeqYJqp0haxbrA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*7dZtKhOASeqYJqp0haxbrA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*7dZtKhOASeqYJqp0haxbrA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*7dZtKhOASeqYJqp0haxbrA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*7dZtKhOASeqYJqp0haxbrA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*7dZtKhOASeqYJqp0haxbrA.png 1100w, https://miro.medium.com/v2/resize:fit:614/1*7dZtKhOASeqYJqp0haxbrA.png 614w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:307/1*7dZtKhOASeqYJqp0haxbrA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image from author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The above image suggest the index is built in batch mode (meaning for the full catalog at once). But in reality a realtime streaming pipeline would be much more suitable (each time a new item is added to the catalog it would trigger the pipeline to add its vector representation to the index).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Approximate nearest neighbors search</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is not really the subject of this blog post so I won’t get into too much details but it is still important to understand the subject pretty deeply if one wants to put a two-tower model or any other advanced candidate generator in production.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So what is a vector database? Well it is basically a framework or API that allows you to build data structures to store and efficiently retrieve the closest vectors given a specific query vector and a measure of distance like the L2 norm or the dot product. More formally, given a set of vectors x_i, it allows to one resolve the following problem very efficiently:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:61%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 456px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ksgv4LBl7uK1OFN5hzCLNA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ksgv4LBl7uK1OFN5hzCLNA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ksgv4LBl7uK1OFN5hzCLNA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ksgv4LBl7uK1OFN5hzCLNA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ksgv4LBl7uK1OFN5hzCLNA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ksgv4LBl7uK1OFN5hzCLNA.png 1100w, https://miro.medium.com/v2/resize:fit:912/format:webp/1*ksgv4LBl7uK1OFN5hzCLNA.png 912w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 456px" srcset="https://miro.medium.com/v2/resize:fit:640/1*ksgv4LBl7uK1OFN5hzCLNA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ksgv4LBl7uK1OFN5hzCLNA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ksgv4LBl7uK1OFN5hzCLNA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ksgv4LBl7uK1OFN5hzCLNA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ksgv4LBl7uK1OFN5hzCLNA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ksgv4LBl7uK1OFN5hzCLNA.png 1100w, https://miro.medium.com/v2/resize:fit:912/1*ksgv4LBl7uK1OFN5hzCLNA.png 912w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:456/1*ksgv4LBl7uK1OFN5hzCLNA.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">When searching the index, you won’t only get the closest item but the K closest items. These libraries are great because they allow you to control the trade-off between precision and execution speed. They have grown out of <a href="https://www.jstage.jst.go.jp/article/mta/6/1/6_2/_pdf/" target="_self">a body of research</a> that I encourage you to read if you have the time. To me the two most important concepts that allow them to reach a great execution speed are:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><a href="https://ieeexplore.ieee.org/abstract/document/1238663/" target="_self">Inverted file indexes</a>: This is the key to non-exhaustive search. The vector space is split into <a href="https://fr.wikipedia.org/wiki/Diagramme_de_Vorono%C3%AF" target="_self">Voronoï cells</a>. Each vector is affected a cell and at search time we only compute the similarity with the vectors of the cell the query belongs to and potentially some neighbor cells</li><li class="ff3" style="font-size:22px;"><a href="https://hal.inria.fr/inria-00514462v2/document" target="_self">Product quantization</a>: It can be seen as a lossy compression technique for high-dimensional vectors, that allows relatively accurate reconstructions and distance computations in the compressed domain.</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To me, the most notorious libraries to perform approximate nearest neighbor search are:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;"><a href="https://github.com/facebookresearch/faiss/wiki" target="_self">FAISS</a> from Facebook</li><li class="ff3" style="font-size:22px;"><a href="https://github.com/spotify/annoy" target="_self">Annoy</a> from Spotify</li><li class="ff3" style="font-size:22px;"><a href="https://github.com/google-research/google-research/tree/master/scann?source=techstories.org" target="_self">Scann</a> from Google (which is to date the fastest implementation to date)</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Conclusion</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this blog post we have seen why it is important to consider a two-stage recommendation strategy (especially if you have a large item catalog). We went through a thorough explanation of one of the latest candidate generator model (the two-tower model). We have also drawn a roadmap to put this model in production.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In <a href="https://medium.com/mlearning-ai/building-a-multi-stage-recommendation-system-part-1-2-ce006f0825d1" target="_self">the next blog post</a>, we will implement this model in TensorFlow 2 so we can get into the internals. We will also apply the model using the H&M Kaggle dataset.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the meantime, stay safe and hydrated :-)</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://medium.com/mlearning-ai/mlearning-ai-submission-suggestions-b51e2b130bfb"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">Mlearning.ai Submission Suggestions</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">How to become a writer on Mlearning.ai</h3><p>medium.com</p></a></div></div></div></div></section><br><?php include_once 'Elemental/footer.php'; ?>