<!DOCTYPE html>
                <html>
                <head>
                    <title>Simple and Multiple Linear Regression in Python</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://towardsdatascience.com/simple-and-multiple-linear-regression-in-python-c928425168f9"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@adi.bronshtein?source=post_page-----c928425168f9--------------------------------">Author : Adi Bronshtein</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Simple and Multiple Linear Regression in Python</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Quick introduction to linear regression in Python</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Hi everyone! After <a href="https://medium.com/@adi.bronshtein/a-quick-introduction-to-the-pandas-python-library-f1b678f34673" target="_self">briefly introducing the “Pandas” library</a> as well as the <a href="https://medium.com/@adi.bronshtein/a-quick-introduction-to-the-numpy-library-6f61b7dee4db" target="_self">NumPy library</a>, I wanted to provide a quick introduction to building models in Python, and what better place to start than one of the very basic models, linear regression? This will be the first post about machine learning and I plan to write about more complex models in the future. Stay tuned! But for right now, let’s focus on linear regression.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this blog post, I want to focus on the concept of linear regression and mainly on the implementation of it in Python. <a href="https://en.wikipedia.org/wiki/Linear_regression" target="_self">Linear regression</a> is a statistical model that examines the linear relationship between two (Simple Linear Regression ) or more (Multiple Linear Regression) variables — a dependent variable and independent variable(s). Linear relationship basically means that when one (or more) independent variables increases (or decreases), the dependent variable increases (or decreases) too:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:76%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 560px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*N2usf10aKCq1JBIqxj-YFQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*N2usf10aKCq1JBIqxj-YFQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*N2usf10aKCq1JBIqxj-YFQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*N2usf10aKCq1JBIqxj-YFQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*N2usf10aKCq1JBIqxj-YFQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*N2usf10aKCq1JBIqxj-YFQ.png 1100w, https://miro.medium.com/v2/resize:fit:1120/format:webp/1*N2usf10aKCq1JBIqxj-YFQ.png 1120w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 560px" srcset="https://miro.medium.com/v2/resize:fit:640/1*N2usf10aKCq1JBIqxj-YFQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*N2usf10aKCq1JBIqxj-YFQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*N2usf10aKCq1JBIqxj-YFQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*N2usf10aKCq1JBIqxj-YFQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*N2usf10aKCq1JBIqxj-YFQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*N2usf10aKCq1JBIqxj-YFQ.png 1100w, https://miro.medium.com/v2/resize:fit:1120/1*N2usf10aKCq1JBIqxj-YFQ.png 1120w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:560/1*N2usf10aKCq1JBIqxj-YFQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As you can see, a linear relationship can be positive (independent variable goes up, dependent variable goes up) or negative (independent variable goes up, dependent variable goes down). Like I said, I will focus on the implementation of regression models in Python, so I don’t want to delve too much into the math under the regression hood, but I will write a little bit about it. If you’d like a blog post about that, please don’t hesitate to write me in the responses!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">A Little Bit About the Math</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A relationship between variables Y and X is represented by this equation:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><strong>Y`i = mX + b</strong></span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this equation, <em>Y</em> is the dependent variable — or the variable we are trying to predict or estimate; X is the independent variable — the variable we are using to make predictions; m is the slope of the regression line — it represent the effect <em>X</em> has on <em>Y</em>. In other words, if <em>X</em> increases by 1 unit, <em>Y</em> will increase by exactly <em>m</em> units. (<strong>“Full disclosure”</strong>: this is true only if we know that <em>X</em> and <em>Y</em> have a linear relationship. In almost all linear regression cases, this will not be true!) <mark>b </mark><mark>is a constant, also known as the Y-intercept</mark>. If X equals <em>0, Y </em>would be equal to <em>b </em>(<strong>Caveat</strong>: see full disclosure from earlier!). This is not necessarily applicable in real life — we won’t always know the exact relationship between <em>X</em> and <em>Y</em> or have an exact linear relationship.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">These caveats lead us to a <strong>Simple Linear Regression</strong> (SLR). In a SLR model, we build a model based on data — the slope and Y-intercept derive from the data; furthermore, we don’t need the relationship between <em>X</em> and <em>Y </em>to be exactly linear. SLR models also include the errors in the data (also known as residuals). I won’t go too much into it now, maybe in a later post, but residuals are basically the differences between the true value of Y and the predicted/estimated value of Y. It is important to note that in a linear regression, we are trying to predict a continuous variable. In a regression model, we are trying to minimize these errors by finding the “line of best fit” — the regression line from the errors would be minimal. We are trying to minimize the length of the black lines (or more accurately, the distance of the blue dots) from the red line — as close to zero as possible. It is related to (or equivalent to) minimizing the <a href="https://en.wikipedia.org/wiki/Mean_squared_error" target="_self">mean squared error (MSE)</a> or the sum of <a href="https://en.wikipedia.org/wiki/Residual_sum_of_squares" target="_self">squares of error (SSE)</a>, also called the “residual sum of squares.” (RSS) but this might be beyond the scope of this blog post :-)</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*A71zTD6_QqUzLhMKj1Rgiw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*A71zTD6_QqUzLhMKj1Rgiw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*A71zTD6_QqUzLhMKj1Rgiw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*A71zTD6_QqUzLhMKj1Rgiw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*A71zTD6_QqUzLhMKj1Rgiw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*A71zTD6_QqUzLhMKj1Rgiw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A71zTD6_QqUzLhMKj1Rgiw.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*A71zTD6_QqUzLhMKj1Rgiw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*A71zTD6_QqUzLhMKj1Rgiw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*A71zTD6_QqUzLhMKj1Rgiw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*A71zTD6_QqUzLhMKj1Rgiw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*A71zTD6_QqUzLhMKj1Rgiw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*A71zTD6_QqUzLhMKj1Rgiw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*A71zTD6_QqUzLhMKj1Rgiw.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*A71zTD6_QqUzLhMKj1Rgiw.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In most cases, we will have more than one independent variable — we’ll have multiple variables; it can be as little as two independent variables and up to hundreds (or theoretically even thousands) of variables. in those cases we will use a Multiple Linear Regression model (MLR). The regression equation is pretty much the same as the simple regression equation, just with more variables:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><strong>Y’i = b0 + b1X1i + b2X2i</strong></span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This concludes the math portion of this post :) Ready to get to implementing it in Python?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Linear Regression in Python</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">There are two main ways to perform linear regression in Python — with <a href="http://www.statsmodels.org/stable/regression.html" target="_self">Statsmodels</a> and <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" target="_self">scikit-learn</a>. It is also possible to use the <a href="https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.linregress.html" target="_self">Scipy library</a>, but I feel this is not as common as the two other libraries I’ve mentioned. Let’s look into doing linear regression in both of them:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Linear Regression in Statsmodels</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><a href="http://www.statsmodels.org/stable/index.html" target="_self">Statsmodels</a> is “a Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration.” (from the documentation)</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As in with <a href="https://medium.com/@adi.bronshtein/a-quick-introduction-to-the-pandas-python-library-f1b678f34673" target="_self">Pandas</a> and <a href="https://medium.com/@adi.bronshtein/a-quick-introduction-to-the-numpy-library-6f61b7dee4db" target="_self">NumPy</a>, the easiest way to get or install Statsmodels is through the <a href="https://www.continuum.io/downloads" target="_self">Anaconda package</a>. If, for some reason you are interested in installing in another way, check out <a href="http://www.statsmodels.org/stable/install.html" target="_self">this link</a>. After installing it, you will need to import it every time you want to use it:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><strong>import statsmodels.api as sm</strong></span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s see how to actually use Statsmodels for linear regression. I’ll use an example from the <a href="https://generalassemb.ly/education/data-science-immersive" target="_self">data science class</a> I took at <a href="https://generalassemb.ly/locations/washington-dc/downtown-dc" target="_self">General Assembly DC</a>:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">First, we import a <a href="http://scikit-learn.org/stable/datasets/" target="_self">dataset from sklearn</a> (the other library I’ve mentioned):</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><strong>from</strong> <strong>sklearn</strong> <strong>import</strong> datasets <em>## imports datasets from scikit-learn</em><br/>data = datasets.load_boston() <em>## loads Boston dataset from datasets library </em></span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is a <a href="https://archive.ics.uci.edu/ml/datasets/housing" target="_self">dataset of the Boston house prices</a> (link to the description). Because it is a dataset designated for testing and learning machine learning tools, it comes with a description of the dataset, and we can see it by using the command <strong>print</strong> data.DESCR (this is only true for sklearn datasets, not every dataset! Would have been cool though…). I’m adding the beginning of the description, for better understanding of the variables:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>Boston House Prices dataset<br/>===========================<br/><br/>Notes<br/>------<br/>Data Set Characteristics:  <br/><br/>    :Number of Instances: 506 <br/><br/>    :Number of Attributes: 13 numeric/categorical predictive<br/>    <br/>    :Median Value (attribute 14) is usually the target<br/><br/>    :Attribute Information (in order):<br/>        - CRIM     per capita crime rate by town<br/>        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.<br/>        - INDUS    proportion of non-retail business acres per town<br/>        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)<br/>        - NOX      nitric oxides concentration (parts per 10 million)<br/>        - RM       average number of rooms per dwelling<br/>        - AGE      proportion of owner-occupied units built prior to 1940<br/>        - DIS      weighted distances to five Boston employment centres<br/>        - RAD      index of accessibility to radial highways<br/>        - TAX      full-value property-tax rate per $10,000<br/>        - PTRATIO  pupil-teacher ratio by town<br/>        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town<br/>        - LSTAT    % lower status of the population<br/>        - MEDV     Median value of owner-occupied homes in $1000's<br/><br/>    :Missing Attribute Values: None<br/><br/>    :Creator: Harrison, D. and Rubinfeld, D.L.<br/><br/>This is a copy of UCI ML housing dataset.<br/>http://archive.ics.uci.edu/ml/datasets/Housing<br/><br/><br/>This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Running <em>data.feature_names</em> and <em>data.target</em> would print the column names of the independent variables and the dependent variable, respectively. Meaning, Scikit-learn has already set the house value/price data as a target variable and 13 other variables are set as predictors. Let’s see how to run a linear regression on this dataset.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">First, we should load the data as a pandas data frame for easier analysis and set the median home value as our target variable:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><strong>import</strong> <strong>numpy</strong> <strong>as</strong> <strong>np</strong><br/><strong>import</strong> <strong>pandas</strong> <strong>as</strong> <strong>pd</strong></span><span># define the data/predictors as the pre-set feature names  <br/>df = pd.DataFrame(data.data, columns=data.feature_names)<br/><br/><em># Put the target (housing value -- MEDV) in another DataFrame</em><br/>target = pd.DataFrame(data.target, columns=["MEDV"])</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">What we’ve done here is to take the dataset and load it as a pandas data frame; after that, we’re setting the predictors (as df) — the independent variables that are pre-set in the dataset. We’re also setting the target — the dependent variable, or the variable we’re trying to predict/estimate.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Next we’ll want to fit a linear regression model. We need to choose variables that we think we’ll be good predictors for the dependent variable — that can be done by checking the correlation(s) between variables, by plotting the data and searching visually for relationship, by conducting preliminary research on what variables are good predictors of y etc. For this first example, let’s take RM — the average number of rooms and LSTAT — percentage of lower status of the population. It’s important to note that Statsmodels does not add a constant by default. Let’s see it first without a constant in our regression model:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><em>## Without a constant</em><br/><br/><strong>import</strong> <strong>statsmodels.api</strong> <strong>as</strong> <strong>sm</strong><br/><br/>X = df["RM"]<br/>y = target["MEDV"]<br/><br/><em># Note the difference in argument order</em><br/>model = sm.OLS(y, X).fit()<br/>predictions = model.predict(X) # make the predictions by the model<br/><br/><em># Print out the statistics</em><br/>model.summary()</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The output:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*XTFRhbi48lb3Up1SGCo_ug.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*XTFRhbi48lb3Up1SGCo_ug.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*XTFRhbi48lb3Up1SGCo_ug.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*XTFRhbi48lb3Up1SGCo_ug.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*XTFRhbi48lb3Up1SGCo_ug.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*XTFRhbi48lb3Up1SGCo_ug.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XTFRhbi48lb3Up1SGCo_ug.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*XTFRhbi48lb3Up1SGCo_ug.png 640w, https://miro.medium.com/v2/resize:fit:720/1*XTFRhbi48lb3Up1SGCo_ug.png 720w, https://miro.medium.com/v2/resize:fit:750/1*XTFRhbi48lb3Up1SGCo_ug.png 750w, https://miro.medium.com/v2/resize:fit:786/1*XTFRhbi48lb3Up1SGCo_ug.png 786w, https://miro.medium.com/v2/resize:fit:828/1*XTFRhbi48lb3Up1SGCo_ug.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*XTFRhbi48lb3Up1SGCo_ug.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*XTFRhbi48lb3Up1SGCo_ug.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*XTFRhbi48lb3Up1SGCo_ug.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Interpreting the Table </strong>—This is a very long table, isn’t it? First we have what’s the dependent variable and the model and the method. <strong>OLS</strong> stands for <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares" target="_self">Ordinary Least Squares</a> and the method “Least Squares” means that we’re trying to fit a regression line that would minimize the square of distance from the regression line (see the previous section of this post). Date and Time are pretty self-explanatory :) So as number of observations. Df of residuals and models relates to the <a href="https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics)" target="_self">degrees of freedom</a> — “the number of values in the final calculation of a statistic that are free to vary.”</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The coefficient of 3.6534 means that as the <em>RM</em> variable increases by 1, the predicted value of <em>MDEV</em> increases by <em>3.6534</em>. A few other important values are the R-squared — the percentage of variance our model explains; the standard error (is the standard deviation of the sampling distribution of a statistic, most commonly of the mean); the t scores and p-values, for hypothesis test — the <em>RM</em> has statistically significant p-value; there is a 95% confidence intervals for the <em>RM (</em>meaning we predict at a 95% percent confidence that the value of <em>RM</em> is between <em>3.548</em> to <em>3.759</em>).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If we do want to add a constant to our model — we have to set it by using the command <code>X = sm.add_constant(X)</code> where X is the name of your data frame containing your input (independent) variables.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><strong>import</strong> <strong>statsmodels.api</strong> <strong>as</strong> <strong>sm # </strong>import statsmodels<strong> </strong><br/><br/>X = df["RM"] <em>## X usually means our input variables (or independent variables)</em><br/>y = target["MEDV"] <em>## Y usually means our output/dependent variable</em><br/>X = sm.add_constant(X) <em>## let's add an intercept (beta_0) to our model</em><br/><br/><em># Note the difference in argument order</em><br/>model = sm.OLS(y, X).fit() <em>## sm.OLS(output, input)</em><br/>predictions = model.predict(X)<br/><br/><em># Print out the statistics</em><br/>model.summary()</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The output:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*X6IV-_exaTqm7y0p5FC2Zg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*X6IV-_exaTqm7y0p5FC2Zg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*X6IV-_exaTqm7y0p5FC2Zg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*X6IV-_exaTqm7y0p5FC2Zg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*X6IV-_exaTqm7y0p5FC2Zg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*X6IV-_exaTqm7y0p5FC2Zg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X6IV-_exaTqm7y0p5FC2Zg.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*X6IV-_exaTqm7y0p5FC2Zg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*X6IV-_exaTqm7y0p5FC2Zg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*X6IV-_exaTqm7y0p5FC2Zg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*X6IV-_exaTqm7y0p5FC2Zg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*X6IV-_exaTqm7y0p5FC2Zg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*X6IV-_exaTqm7y0p5FC2Zg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*X6IV-_exaTqm7y0p5FC2Zg.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*X6IV-_exaTqm7y0p5FC2Zg.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Interpreting the Table </strong>— With the constant term the coefficients are different. Without a constant we are forcing our model to go through the origin, but now we have a y-intercept at <em>-34.67</em>. We also changed the slope of the <em>RM</em> predictor from <em>3.634</em> to <em>9.1021</em>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Now let’s try fitting a regression model with more than one variable — we’ll be using RM and LSTAT I’ve mentioned before. Model fitting is the same:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>X = df[[“RM”, “LSTAT”]]<br/>y = target[“MEDV”]</span><span>model = sm.OLS(y, X).fit()<br/>predictions = model.predict(X)</span><span>model.summary()</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">And the output:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*PtOVDktQ-QoClML4RZybaA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*PtOVDktQ-QoClML4RZybaA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*PtOVDktQ-QoClML4RZybaA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*PtOVDktQ-QoClML4RZybaA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*PtOVDktQ-QoClML4RZybaA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*PtOVDktQ-QoClML4RZybaA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PtOVDktQ-QoClML4RZybaA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*PtOVDktQ-QoClML4RZybaA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*PtOVDktQ-QoClML4RZybaA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*PtOVDktQ-QoClML4RZybaA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*PtOVDktQ-QoClML4RZybaA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*PtOVDktQ-QoClML4RZybaA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*PtOVDktQ-QoClML4RZybaA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*PtOVDktQ-QoClML4RZybaA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*PtOVDktQ-QoClML4RZybaA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Note: this table looks different because I’ve updated my Jupyter Notebook</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Interpreting the Output </strong>— We can see here that this model has a much higher R-squared value — 0.948, meaning that this model explains 94.8% of the variance in our dependent variable. Whenever we add variables to a regression model, R² will be higher, but this is a pretty high R². We can see that both <em>RM</em> and <em>LSTAT</em> are statistically significant in predicting (or estimating) the median house value; not surprisingly , we see that as <em>RM</em> increases by <em>1</em>, <em>MEDV</em> will increase by 4.9069 and when <em>LSTAT</em> increases by <em>1</em>, <em>MEDV</em> will <strong>decrease</strong> by -0.6557. As you may remember, <em>LSTAT </em>is the percentage of lower status of the population, and unfortunately we can expect that it will lower the median value of houses. With this same logic, the more rooms in a house, usually the higher its value will be.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This was the example of both single and multiple linear regression in Statsmodels. We could have used as little or as many variables we wanted in our regression model(s) — up to all the 13! Next, I will demonstrate how to run linear regression models in SKLearn.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Linear Regression in SKLearn</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">SKLearn is pretty much the golden standard when it comes to machine learning in Python. It has many learning algorithms, for regression, classification, clustering and dimensionality reduction. Check out <a href="https://medium.com/@adi.bronshtein/a-quick-introduction-to-k-nearest-neighbors-algorithm-62214cea29c7" target="_self">my post on the KNN algorithm</a> for a map of the different algorithms and more links to SKLearn. In order to use linear regression, we need to import it:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><strong>from</strong> <strong>sklearn</strong> <strong>import</strong> linear_model</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s use the same dataset we used before, the Boston housing prices. The process would be the same in the beginning — importing the datasets from SKLearn and loading in the Boston dataset:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><strong>from</strong> <strong>sklearn</strong> <strong>import</strong> datasets <em>## imports datasets from scikit-learn</em><br/>data = datasets.load_boston() <em>## loads Boston dataset from datasets library</em></span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Next, we’ll load the data to Pandas (same as before):</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span># define the data/predictors as the pre-set feature names  <br/>df = pd.DataFrame(data.data, columns=data.feature_names)<br/><br/><em># Put the target (housing value -- MEDV) in another DataFrame</em><br/>target = pd.DataFrame(data.target, columns=["MEDV"])</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So now, as before, we have the data frame that contains the independent variables (marked as “df”) and the data frame with the dependent variable (marked as “target”). Let’s fit a regression model using SKLearn. First we’ll define our X and y — this time I’ll use all the variables in the data frame to predict the housing price:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>X = df<br/>y = target[“MEDV”]</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">And then I’ll fit a model:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>lm = linear_model.LinearRegression()<br/>model = lm.fit(X,y)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The lm.fit() function fits a linear model. We want to use the model to make predictions (that’s what we’re here for!), so we’ll use lm.predict():</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>predictions = lm.predict(X)<br/>print(predictions)[0:5]</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The print function would print the first 5 predictions for y (I didn’t print the entire list to “save room”. Removing [0:5] would print the entire list):</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>[ 30.00821269  25.0298606   30.5702317   28.60814055  27.94288232]</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Remember, lm.predict() predicts the y (dependent variable) using the linear model we fitted. You must have noticed that when we run a linear regression with SKLearn, we don’t get a pretty table (okay, it’s not that pretty… but it’s pretty useful) like in Statsmodels. What we can do is use built-in functions to return the score, the coefficients and the estimated intercepts. Let’s see how it works:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>lm.score(X,y)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Would give this output:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>0.7406077428649428</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is the R² score of our model. As you probably remember, this the percentage of explained variance of the predictions. If you’re interested, <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score" target="_self">read more here</a>. Next, let’s check out the coefficients for the predictors:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>lm.coef_</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">will give this output:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>array([ -1.07170557e-01,   4.63952195e-02,   2.08602395e-02,<br/>         2.68856140e+00,  -1.77957587e+01,   3.80475246e+00,<br/>         7.51061703e-04,  -1.47575880e+00,   3.05655038e-01,<br/>        -1.23293463e-02,  -9.53463555e-01,   9.39251272e-03,<br/>        -5.25466633e-01])</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">and the intercept:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>lm.intercept_</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">that will give this output:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span>36.491103280363134</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">These are all (estimated/predicted) parts of the multiple regression equation I’ve mentioned earlier. Check out the documentation to read more about coef_ and intercept_.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">So, this is has a been a quick (but rather long!) introduction on how to conduct linear regression in Python. In practice, you would not use the entire dataset, but you will split your data into a training data to train your model on, and a test data — to, you guessed it, test your model/predictions on. If you would like to read about it, <a href="https://medium.com/@adi.bronshtein/train-test-split-and-cross-validation-in-python-80b61beca4b6" target="_self">please check out my next blog post.</a> In the meanwhile, I hope you enjoyed this post and that I’ll “see” you on the next one.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Thank you for reading!</p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>