<!DOCTYPE html>
                <html>
                <head>
                    <title>StyleGAN: In depth explaination</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://pub.towardsai.net/introduction-to-stylegan-ec0a6b0706c"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@minhhnguyen0312?source=post_page-----ec0a6b0706c--------------------------------">Author : Albert Nguyen</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>StyleGAN: In depth explaination</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Generative Adversarial Networks (GAN) have yielded state-of-the-art results in generative tasks and have become one of the most important frameworks in Deep Learning. Many variants of GAN have been proposed to improve the quality of generated images or allow conditional synthesis. However, they have yet to offer intuitive, scale-specific control of the synthesis procedure until StyleGAN.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">StyleGAN is an extension of progressive GAN, an architecture that allows us to generate high-quality and high-resolution images. As proposed in [<a href="https://arxiv.org/pdf/1812.04948.pdf" target="_self">paper</a>], StyleGAN only changes the generator architecture by having an MLP network to learn image styles and inject noise at each layer to generate stochastic variations.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this post, we will explore the architecture of StyleGAN.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">ProGAN Architecture</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Because StyleGAN is built on ProGAN, we will first have a quick look through ProgGAN architecture.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*iNUD-JcHRyvY5y8v.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*iNUD-JcHRyvY5y8v.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*iNUD-JcHRyvY5y8v.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*iNUD-JcHRyvY5y8v.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*iNUD-JcHRyvY5y8v.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*iNUD-JcHRyvY5y8v.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iNUD-JcHRyvY5y8v.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*iNUD-JcHRyvY5y8v.png 640w, https://miro.medium.com/v2/resize:fit:720/0*iNUD-JcHRyvY5y8v.png 720w, https://miro.medium.com/v2/resize:fit:750/0*iNUD-JcHRyvY5y8v.png 750w, https://miro.medium.com/v2/resize:fit:786/0*iNUD-JcHRyvY5y8v.png 786w, https://miro.medium.com/v2/resize:fit:828/0*iNUD-JcHRyvY5y8v.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*iNUD-JcHRyvY5y8v.png 1100w, https://miro.medium.com/v2/resize:fit:1400/0*iNUD-JcHRyvY5y8v.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/0*iNUD-JcHRyvY5y8v.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: add sauce here</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Like a general GAN, ProGAN consists of a Generator and Discriminator. The Generator will try to produce “realistic images,” and the Discriminator will classify whether it is fake.<br></br>Unlike general GAN, ProGAN Discriminator will classify the image at different scales. In training, Discriminator will receive input at different resolutions and combine them to tell if the image is real or fake. The real data image will undergo a “progressive downsampling process” to produce lower-resolution images. For example, a 256x256 image will be turned into a list of [256x256, 128x128, 64x64, 32x32, 16x16] images and fed into the Discriminator. On the other hand, the Generator will produce images at such resolutions and feed them into the Discriminator.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The architecture of ProGAN has shown success in producing high-quality images. And StyleGAN is built based on this architecture to obtain an intuitive synthesis procedure.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*fsOyFVnhWEFnBOPv_ZQ0gQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: <a href="https://arxiv.org/pdf/1710.10196.pdf" target="_self">PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Note:</strong> The progressive growth of ProGAN allows the Generator to first learn the image’s overall distribution (context) at early layers and details at later layers.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">StyleGAN Generator</h4></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*cc7VoijneUVcFymjFh-boQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*cc7VoijneUVcFymjFh-boQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*cc7VoijneUVcFymjFh-boQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*cc7VoijneUVcFymjFh-boQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*cc7VoijneUVcFymjFh-boQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*cc7VoijneUVcFymjFh-boQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cc7VoijneUVcFymjFh-boQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*cc7VoijneUVcFymjFh-boQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*cc7VoijneUVcFymjFh-boQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*cc7VoijneUVcFymjFh-boQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*cc7VoijneUVcFymjFh-boQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*cc7VoijneUVcFymjFh-boQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*cc7VoijneUVcFymjFh-boQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*cc7VoijneUVcFymjFh-boQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*cc7VoijneUVcFymjFh-boQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: <a href="https://arxiv.org/pdf/1812.04948.pdf" target="_self">A Style-Based Generator Architecture for Generative Adversarial Networks</a></p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">There are three changes in the StyleGAN Generator:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;"><a href="#3214" target="_self">A starting learnable constant</a></li><li class="ff3" style="font-size:22px;"><a href="#ffdd" target="_self">Mapping Network</a> and <a href="#ccdf" target="_self">Adaptive Instance Normalization (AdaIN)</a></li><li class="ff3" style="font-size:22px;"><a href="#a0d5" target="_self">Noise Injection for Stochastic Variation</a></li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Starting Constant</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">General GANs Generator generates images from a latent code. Instead, StyleGAN starts with a constant learned image of size 4x4. The progressive growth of the Generator will add new content and upscale this image by applying <code>style</code> and <code>noise</code>at each block.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Mapping Network (Style Learning Network)</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The latent code <code>z</code>, which we often referred in GAN as the mapping of the image at latent space, is now used to produce the style of the image.<br></br>The vector <code>z</code>is first sampled from a predefined distribution (Uniform or Gaussian) at latent space Z. Then it is mapped into an intermediate latent space W to produce w. The mapping network is implemented using an 8-layer MLP:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*_VUXFwZGAYke4_GFqCgqlQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*_VUXFwZGAYke4_GFqCgqlQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*_VUXFwZGAYke4_GFqCgqlQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*_VUXFwZGAYke4_GFqCgqlQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*_VUXFwZGAYke4_GFqCgqlQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*_VUXFwZGAYke4_GFqCgqlQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_VUXFwZGAYke4_GFqCgqlQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*_VUXFwZGAYke4_GFqCgqlQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*_VUXFwZGAYke4_GFqCgqlQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*_VUXFwZGAYke4_GFqCgqlQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*_VUXFwZGAYke4_GFqCgqlQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*_VUXFwZGAYke4_GFqCgqlQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*_VUXFwZGAYke4_GFqCgqlQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*_VUXFwZGAYke4_GFqCgqlQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*_VUXFwZGAYke4_GFqCgqlQ.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">An affine transformation on the intermediate latent code w will produce style <code>y = (y_s, y_b)</code> and feed into the <strong>AdaIN </strong>layer, following up with a convolution to draw new contents to the image.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>The Entangled Problem</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">There is a question we must ask about the <strong>Mapping Network</strong>. Why do we need it? Why not just put the latent z instead?</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The reason is because of the ‘entangled problem,’ which means that each element of z control more than one factor of the image. Unfortunately, this also means that some elements can affect the same factor. Therefore, we can not scale a single factor without affecting the other. For example, when analyzing the Generator, you may find some elements of z control hair length elements. So you want to change the hair length of the image by scaling up and down these elements. But you may end up with a totally different image because these elements also affect other factors like gender, eye color, etc.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is because the latent ‘z’ is sampled from a fixed distribution (uniform or normal) while the data distribution is probably different.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:17%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 151px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*R-5F2YGcHosWhY-22LOD5A.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*R-5F2YGcHosWhY-22LOD5A.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*R-5F2YGcHosWhY-22LOD5A.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*R-5F2YGcHosWhY-22LOD5A.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*R-5F2YGcHosWhY-22LOD5A.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*R-5F2YGcHosWhY-22LOD5A.png 1100w, https://miro.medium.com/v2/resize:fit:302/format:webp/1*R-5F2YGcHosWhY-22LOD5A.png 302w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 151px" srcset="https://miro.medium.com/v2/resize:fit:640/1*R-5F2YGcHosWhY-22LOD5A.png 640w, https://miro.medium.com/v2/resize:fit:720/1*R-5F2YGcHosWhY-22LOD5A.png 720w, https://miro.medium.com/v2/resize:fit:750/1*R-5F2YGcHosWhY-22LOD5A.png 750w, https://miro.medium.com/v2/resize:fit:786/1*R-5F2YGcHosWhY-22LOD5A.png 786w, https://miro.medium.com/v2/resize:fit:828/1*R-5F2YGcHosWhY-22LOD5A.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*R-5F2YGcHosWhY-22LOD5A.png 1100w, https://miro.medium.com/v2/resize:fit:302/1*R-5F2YGcHosWhY-22LOD5A.png 302w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:151/1*R-5F2YGcHosWhY-22LOD5A.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This requires the Generator to learn how to match factors from ‘z’ to data distribution. And the <strong>Mapping Network</strong> covers this job in StyleGAN. “This mapping can be adapted to ‘unwrap’ W so that the factors of variations become more linear” — Tero et al., 2018. i.e., each factor in w contributes to one aspect of the image. The <strong>Mapping Network</strong> allows the Generator to reserve its capacity to generate more realistic images.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:59%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 441px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*3IqI0lpF7VZhBDi3XT3vlw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*3IqI0lpF7VZhBDi3XT3vlw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*3IqI0lpF7VZhBDi3XT3vlw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*3IqI0lpF7VZhBDi3XT3vlw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*3IqI0lpF7VZhBDi3XT3vlw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*3IqI0lpF7VZhBDi3XT3vlw.png 1100w, https://miro.medium.com/v2/resize:fit:882/format:webp/1*3IqI0lpF7VZhBDi3XT3vlw.png 882w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 441px" srcset="https://miro.medium.com/v2/resize:fit:640/1*3IqI0lpF7VZhBDi3XT3vlw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*3IqI0lpF7VZhBDi3XT3vlw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*3IqI0lpF7VZhBDi3XT3vlw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*3IqI0lpF7VZhBDi3XT3vlw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*3IqI0lpF7VZhBDi3XT3vlw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*3IqI0lpF7VZhBDi3XT3vlw.png 1100w, https://miro.medium.com/v2/resize:fit:882/1*3IqI0lpF7VZhBDi3XT3vlw.png 882w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:441/1*3IqI0lpF7VZhBDi3XT3vlw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: <a href="https://arxiv.org/pdf/1812.04948.pdf" target="_self">A Style-Based Generator Architecture for Generative Adversarial Networks</a>.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">There are many other works on ‘disentanglement’ to solve this problem. [<a href="https://paperswithcode.com/task/disentanglement" target="_self">Disentanglement</a>]</p></blockquote></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Adaptive Instance Normalization (AdaIN)</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The latent code ‘w’ produced by the M<strong>apping network </strong>is then fed into a learned affine transform and AdaIN layer. The affine transform is implemented using two linear layers to create a style with <code>scale = y_s</code> and <code>bias = y_b</code> . The AdaIN operation formula:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:50%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 380px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*wIWU5cietop7IJWWn5DNdA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*wIWU5cietop7IJWWn5DNdA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*wIWU5cietop7IJWWn5DNdA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*wIWU5cietop7IJWWn5DNdA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*wIWU5cietop7IJWWn5DNdA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*wIWU5cietop7IJWWn5DNdA.png 1100w, https://miro.medium.com/v2/resize:fit:760/format:webp/1*wIWU5cietop7IJWWn5DNdA.png 760w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 380px" srcset="https://miro.medium.com/v2/resize:fit:640/1*wIWU5cietop7IJWWn5DNdA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*wIWU5cietop7IJWWn5DNdA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*wIWU5cietop7IJWWn5DNdA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*wIWU5cietop7IJWWn5DNdA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*wIWU5cietop7IJWWn5DNdA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*wIWU5cietop7IJWWn5DNdA.png 1100w, https://miro.medium.com/v2/resize:fit:760/1*wIWU5cietop7IJWWn5DNdA.png 760w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:380/1*wIWU5cietop7IJWWn5DNdA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: <a href="https://arxiv.org/pdf/1812.04948.pdf" target="_self">A Style-Based Generator Architecture for Generative Adversarial Networks</a>.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Where <code>x</code> is the output feature map of the previous layer. The AdaIN first normalizes each channel <code>x_i</code> to “zero mean” and “unit variance” and then applies the scale <code>y_s</code> and <code>y_b</code> . This means the style <code>y</code> will control the statistic of the feature map for the next convolutional layer. Where <code>y_s</code> is the standard deviation, and <code>y_b</code> is mean. <em>The style decides which channels will have more contribution in the next convolution</em>.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7"><strong>Localized Feature</strong></h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">One property of the AdaIN is that it makes the effect of each style <em>localized in the network</em>. In other words, the style will only affect the image in the next convolution.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The instance normalization makes all channels ‘zero mean’ and ‘unit variance.’ By doing this, it denies the scaling effects of previous <code>y_s</code> and <code>y_b</code> . This allows scale-specific modification to the styles to control image synthesis. Evidence for this, and also to encourage the localization in the network while training, is <strong>Style mixing.</strong> The model can generate styles from two latent codes <code>w_1</code> and <code>w_2</code> , (or more). For example, for the first four blocks, we use the styles from <code>w_1</code> , and then use the styles from <code>w_2</code> . The picture below shows the result of using two different latent codes.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:88%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 650px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*hZuW-1sbzCyUliaLHgt0Hg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*hZuW-1sbzCyUliaLHgt0Hg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*hZuW-1sbzCyUliaLHgt0Hg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*hZuW-1sbzCyUliaLHgt0Hg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*hZuW-1sbzCyUliaLHgt0Hg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*hZuW-1sbzCyUliaLHgt0Hg.png 1100w, https://miro.medium.com/v2/resize:fit:1300/format:webp/1*hZuW-1sbzCyUliaLHgt0Hg.png 1300w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 650px" srcset="https://miro.medium.com/v2/resize:fit:640/1*hZuW-1sbzCyUliaLHgt0Hg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*hZuW-1sbzCyUliaLHgt0Hg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*hZuW-1sbzCyUliaLHgt0Hg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*hZuW-1sbzCyUliaLHgt0Hg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*hZuW-1sbzCyUliaLHgt0Hg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*hZuW-1sbzCyUliaLHgt0Hg.png 1100w, https://miro.medium.com/v2/resize:fit:1300/1*hZuW-1sbzCyUliaLHgt0Hg.png 1300w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:650/1*hZuW-1sbzCyUliaLHgt0Hg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Source: <a href="https://arxiv.org/pdf/1812.04948.pdf" target="_self">A Style-Based Generator Architecture for Generative Adversarial Networks</a>.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Stochastic Variation with Noise Injection</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Stochastic variations in an image are small details that do not change the overall context of the image. For example, hair placement, smile angle, stubble, freckles, etc. Yes! They do not change the overall image but are there, and the Generator will learn to generate them. The <strong>Noise Injection </strong>to the StyleGAN generator before <strong>AdaIN</strong> layers help generate such variations.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:53%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 403px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*koeyxm7W6creMVwPeNBc9g.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*koeyxm7W6creMVwPeNBc9g.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*koeyxm7W6creMVwPeNBc9g.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*koeyxm7W6creMVwPeNBc9g.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*koeyxm7W6creMVwPeNBc9g.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*koeyxm7W6creMVwPeNBc9g.png 1100w, https://miro.medium.com/v2/resize:fit:806/format:webp/1*koeyxm7W6creMVwPeNBc9g.png 806w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 403px" srcset="https://miro.medium.com/v2/resize:fit:640/1*koeyxm7W6creMVwPeNBc9g.png 640w, https://miro.medium.com/v2/resize:fit:720/1*koeyxm7W6creMVwPeNBc9g.png 720w, https://miro.medium.com/v2/resize:fit:750/1*koeyxm7W6creMVwPeNBc9g.png 750w, https://miro.medium.com/v2/resize:fit:786/1*koeyxm7W6creMVwPeNBc9g.png 786w, https://miro.medium.com/v2/resize:fit:828/1*koeyxm7W6creMVwPeNBc9g.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*koeyxm7W6creMVwPeNBc9g.png 1100w, https://miro.medium.com/v2/resize:fit:806/1*koeyxm7W6creMVwPeNBc9g.png 806w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:403/1*koeyxm7W6creMVwPeNBc9g.png"></picture></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The noise added to the feature map has zero mean and a small scale of variance (compared to the feature map). Therefore, the overall context of the image is preserved as the statistics of the feature map stay “the same.”</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:72%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 537px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*IODCvnLC4SrOqqJ_fZI9Nw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*IODCvnLC4SrOqqJ_fZI9Nw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*IODCvnLC4SrOqqJ_fZI9Nw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*IODCvnLC4SrOqqJ_fZI9Nw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*IODCvnLC4SrOqqJ_fZI9Nw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*IODCvnLC4SrOqqJ_fZI9Nw.png 1100w, https://miro.medium.com/v2/resize:fit:1074/format:webp/1*IODCvnLC4SrOqqJ_fZI9Nw.png 1074w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 537px" srcset="https://miro.medium.com/v2/resize:fit:640/1*IODCvnLC4SrOqqJ_fZI9Nw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*IODCvnLC4SrOqqJ_fZI9Nw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*IODCvnLC4SrOqqJ_fZI9Nw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*IODCvnLC4SrOqqJ_fZI9Nw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*IODCvnLC4SrOqqJ_fZI9Nw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*IODCvnLC4SrOqqJ_fZI9Nw.png 1100w, https://miro.medium.com/v2/resize:fit:1074/1*IODCvnLC4SrOqqJ_fZI9Nw.png 1074w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:537/1*IODCvnLC4SrOqqJ_fZI9Nw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">The noise does not change the overall statistics of the image</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This allows the Generator to reserve its capacity to learn how to generate new content on the given style without learning how to generate stochastic variations.</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">According to the paper, the noise also appears tightly localized in the network. This is interesting and somehow similar to the styles. But noise is noise, and it has nothing to do with the <strong>AdaIN</strong>. The author of the paper hypothesizes that the generator is pressured to introduce new content asap. This leads to creating stochastic variations based on the new noise provided and denies the effects of previous noises.</p></blockquote></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Conclusion</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To wrap up, StyleGAN achieves style-based image generation by disentangling styles from randomness. We can control the synthesis by controlling the style by localizing or scaling the latent code. The Generator also separates the introduction of stochastic variation. Give us more control over the synthesis procedure of StyleGAN.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">Bonus</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Although the StyleGAN reaches state-of-the-art performance in generative tasks. It introduces a problem with artifacts in the generated images. In the StyleGAN2 paper, they spotted the problem in the Adaptive Instance Normalization and the Progressive Growing of the Generator. <a href="https://arxiv.org/abs/1912.04958" target="_self">Link to paper!!</a></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">StyleGAN has been proposed since 2018. But I hope this post will help some readers understand the architecture of StyleGAN.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>My result running StyleGAN for a night:</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">They are pretty nice tho 😁😁</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*UvRjEWF97xZ5w5ZOpIarkA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*UvRjEWF97xZ5w5ZOpIarkA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*UvRjEWF97xZ5w5ZOpIarkA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*UvRjEWF97xZ5w5ZOpIarkA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*UvRjEWF97xZ5w5ZOpIarkA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*UvRjEWF97xZ5w5ZOpIarkA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UvRjEWF97xZ5w5ZOpIarkA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*UvRjEWF97xZ5w5ZOpIarkA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*UvRjEWF97xZ5w5ZOpIarkA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*UvRjEWF97xZ5w5ZOpIarkA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*UvRjEWF97xZ5w5ZOpIarkA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*UvRjEWF97xZ5w5ZOpIarkA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*UvRjEWF97xZ5w5ZOpIarkA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*UvRjEWF97xZ5w5ZOpIarkA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*UvRjEWF97xZ5w5ZOpIarkA.png"></picture></div><br></div></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>