<!DOCTYPE html>
                <html>
                <head>
                    <title>Five mistakes to avoid when modeling with imbalanced datasets</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://medium.com/data-science-at-microsoft/five-mistakes-to-avoid-when-modeling-with-imbalanced-datasets-d58a8c09929c"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@phillipchiltonadkins?source=post_page-----d58a8c09929c--------------------------------">Author : Phillip Chilton Adkins</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Five mistakes to avoid when modeling with imbalanced datasets</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5 text-muted">And what to try instead</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">By <a href="https://www.linkedin.com/in/phillip-adkins-bbab794/" target="_self">Phillip Adkins</a>, <a href="https://www.linkedin.com/in/micheleschradergarner/" target="_self">Michele Garner</a>, and <a href="https://www.linkedin.com/in/david-kooistra-423307127/" target="_self">Dave Kooistra</a></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Got 99 records — and Trues: only one</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Welcome to the world of imbalanced datasets.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*GkjHdLAq-Q9n-g2s 640w, https://miro.medium.com/v2/resize:fit:720/0*GkjHdLAq-Q9n-g2s 720w, https://miro.medium.com/v2/resize:fit:750/0*GkjHdLAq-Q9n-g2s 750w, https://miro.medium.com/v2/resize:fit:786/0*GkjHdLAq-Q9n-g2s 786w, https://miro.medium.com/v2/resize:fit:828/0*GkjHdLAq-Q9n-g2s 828w, https://miro.medium.com/v2/resize:fit:1100/0*GkjHdLAq-Q9n-g2s 1100w, https://miro.medium.com/v2/resize:fit:1400/0*GkjHdLAq-Q9n-g2s 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/0*GkjHdLAq-Q9n-g2s 640w, https://miro.medium.com/v2/resize:fit:720/0*GkjHdLAq-Q9n-g2s 720w, https://miro.medium.com/v2/resize:fit:750/0*GkjHdLAq-Q9n-g2s 750w, https://miro.medium.com/v2/resize:fit:786/0*GkjHdLAq-Q9n-g2s 786w, https://miro.medium.com/v2/resize:fit:828/0*GkjHdLAq-Q9n-g2s 828w, https://miro.medium.com/v2/resize:fit:1100/0*GkjHdLAq-Q9n-g2s 1100w, https://miro.medium.com/v2/resize:fit:1400/0*GkjHdLAq-Q9n-g2s 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/0*GkjHdLAq-Q9n-g2s"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Photo by <a href="https://unsplash.com/@rupert_britton?utm_source=medium&utm_medium=referral" target="_self">Rupert Britton</a> on <a href="https://unsplash.com?utm_source=medium&utm_medium=referral" target="_self">Unsplash</a>.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As data science professionals, it is not uncommon to encounter target dependent variables that occur so infrequently in the dataset they might as well be outliers. Some example data sets with this issue might include fraud versus non-fraud credit card transactions, cancer screenings, or mechanical failures.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Unfortunately, much of the available imbalanced model–fitting advice doesn’t actually lead to better models.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">To keep things simple, let’s focus on binary classification. Here are five common faux-pas and their fixes to result in higher quality models when working with imbalanced datasets, along with examples of how making these mistakes could have an impact on the model’s outcome.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:70%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 522px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 1100w, https://miro.medium.com/v2/resize:fit:1044/format:webp/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 1044w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 522px" srcset="https://miro.medium.com/v2/resize:fit:640/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 1100w, https://miro.medium.com/v2/resize:fit:1044/1*nwZ3Ev6n2SkrjiVNWoW_cg.png 1044w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:522/1*nwZ3Ev6n2SkrjiVNWoW_cg.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Visual representation of highly imbalanced data.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Mistake 1: During first approach, defaulting to dataset doctoring</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s suppose there’s a project to design a binary classification model to identify emails as fraudulent (spam) or not fraudulent (ham). After doing some initial data exploration, findings show the dataset is imbalanced with 100 times more ham examples than spam examples.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">It may be tempting to start the modeling process by resampling the dataset. Two common methods include <strong>downsampling</strong> (the removal of some of the majority class) and <strong>upsampling</strong> (the addition of duplicate records from the minority class).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Intuitively, resampling the dataset may seem like the right approach. However, a sample is meant to be representative of the full population of the thing it’s measuring, and downsampling means losing data. This is especially true if the remaining dataset isn’t rich enough to be representative of the population, in which case it could lead to a model that underperforms during its application. Upsampling is a safer choice but has its own issues, such as potentially blowing up the size and memory consumption of the data.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">More importantly, resampling and reweighting are often sources of common errors that can decrease model accuracy anywhere from a minor dip to a catastrophic plunge, yield misleading evaluation statistics, or make iterating on model building substantially less efficient.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Overall, we suggest that resampling is generally an anti-pattern that should be avoided unless there’s a good reason to apply it. Another technique related to resampling is “reweighting” or “sample weighting.” While not quite as prone to inducing errors as resampling, we also consider using reweighting as a default approach for modeling on imbalanced datasets an anti-pattern.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">What to try instead</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Instead of resampling the data, <strong>leave the data unbalanced</strong>. The techniques outlined below provide stronger alternatives to downsampling and upsampling.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Mistake 2: Relying on “predict” to predict</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For models with scikit-learn–style APIs, using the “predict” function of a binary classifier produces a discrete class prediction (e.g., a 0 or 1). What some people overlook is that the “predict” function is generally based on a heuristic that applies a default internal decision threshold of 0.5<strong> </strong>to the model’s decision function. In other words, if the model’s decision function is 0.5 or greater, “predict” will yield a “True” or a 1 and otherwise it will return a “False” or a 0.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">However, this heuristic often isn’t even close to the best you can do on a given dataset — and is often just plain bad on imbalanced data.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Relying on the “predict” function when tackling a model fit on an imbalanced dataset may cause the model to appear as if it’s struggling due to the built-in default decision threshold. This means that <strong>the model might be well fit, but the “predict” function isn’t pulling the best binary prediction out of it.</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">What to try instead</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A better solution for training, testing, and validating models derived from unbalanced datasets is to <strong>tune and determine a custom decision threshold</strong> to optimize a cost function relevant to your specific use case.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Luckily, most libraries and packages come with a function to predict outcome probabilities or decision functions for each class, such as scikit-learn’s “predict_proba”. Instead of using a built-in decision function, the decision function can be used with a decision threshold set by the data practitioner to maximize predictive performance. The threshold allows a Machine Learning practitioner the freedom to sculpt and optimize the model’s output behavior.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For example, on the previously mentioned spam/ham project, you may be seeing an f1 score of 0.0 on your validation or test sets while using the predict function. Rather than assuming this is due to the model’s inability to focus in on the rare spam items, you might find that using the decision function and a well-chosen threshold will increase your f1.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the “Relying on ‘predict’ to predict” experiment in the <a href="https://github.com/PilCAki/imbalanced-dataset-common-errors/blob/main/Imbalanced%20Dataset%20Examples.ipynb" target="_self">linked experiments notebook</a>, we demonstrate a case in which the f1-score we achieve using “predict” is 0.16 while we are able to obtain an f1-score of 0.43 with a custom decision function.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This result is not an exception. In fact, it can be almost guaranteed to occur every time using simple reasoning. The performance of the model using “predict” is contained as a subset of the results available when auditioning a variety of decision thresholds. Because max(V) &gt;= v if v is in V, of course we can obtain better performance through tuning the decision threshold!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Mistake 3: Relying on algorithm defaults</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The impulse to resample datasets may stem from faulty reasoning that the Machine Learning modeling techniques will have an easier time learning from balanced data. In reality, <strong>most Machine Learning algorithms actually learn brilliantly well from unbalanced data — as long as they are tuned properly.</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Using the default hyperparameters for various algorithms may result in poor performance and require longer training times on imbalanced datasets.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">What to try instead</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Adjusting the right model hyperparameters can significantly improve performance on imbalanced data. </strong>Some algorithms even have hyperparameters that specifically address class balance, which then speeds up training time and improves performance.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For example, XGBoost works faster and more accurately when “base_score” is set to the ratio of positive samples in the data. The default XGBoost hyperparams cause the algorithm to spend many boosting iterations learning the bias, slowing learning and potentially causing the algorithm to take errant turns along the way. Setting the right constant initialization allows the algorithm to focus on learning variations in the data rather than approximating a constant.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We demonstrate this in the <a href="https://github.com/PilCAki/imbalanced-dataset-common-errors/blob/main/Imbalanced%20Dataset%20Examples.ipynb" target="_self">linked experiments notebook</a>. Using a dataset with a class balance ratio of 99 to 1, we compare a default XGBoost base_score to our recommended XGBoost initialization.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*KCXa_RWaTfNHTs0VRZ-0HQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*KCXa_RWaTfNHTs0VRZ-0HQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Log loss for properly initialized XGBoost is immediately better than the default settings on imbalanced data. The more imbalanced the data, the more pronounced is this effect. See linked Jupyter notebook for code to generate this plot.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*CofZ05P4wDUGglV4Uwx7kA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*CofZ05P4wDUGglV4Uwx7kA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*CofZ05P4wDUGglV4Uwx7kA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*CofZ05P4wDUGglV4Uwx7kA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*CofZ05P4wDUGglV4Uwx7kA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*CofZ05P4wDUGglV4Uwx7kA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CofZ05P4wDUGglV4Uwx7kA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*CofZ05P4wDUGglV4Uwx7kA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*CofZ05P4wDUGglV4Uwx7kA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*CofZ05P4wDUGglV4Uwx7kA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*CofZ05P4wDUGglV4Uwx7kA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*CofZ05P4wDUGglV4Uwx7kA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*CofZ05P4wDUGglV4Uwx7kA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*CofZ05P4wDUGglV4Uwx7kA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*CofZ05P4wDUGglV4Uwx7kA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">The difference in performance isn’t just a calibration issue. The quality of the predictions is substantially better for the properly initialized XGBoost model, which can be seen here on this plot of best f1 score obtained by optimizing the decision threshold. See linked Jupyter notebook for code to generate this plot.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As you can see from the above log loss and f1_score plots (which are a function of the number of boosting iterations), not only does the properly initialized model converge much more quickly — the ultimate values of log loss and f1_score it converges to are substantially better. While there may not be a mathematical guarantee that the solution XGBoost converges on with this initialization will be better, we have seen it play out that way every time in practice.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Mistake 4: While building a model, resampling or reweighting to control output class statistics</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Another common scenario encountered when modeling on imbalanced data is that the relative balance of predictions output by the model for each class isn’t desirable. Often, data practitioners will resort to resampling or reweighting the training set to coax the model to predict more or less of the minority class.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Resampling or reweighting isn’t necessary to accomplish this and will only increase both the number of experiment iterations and the chances of making a mistake in your evaluation statistics or affect the calibration of your model.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">What to try instead</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Similar to what’s been suggested previously, <strong>sculpt your output class balance using a custom decision threshold </strong>applied to your model’s decision function.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is a simple and direct way to control the exact ratio of positives / negatives output by your model and is much safer and more computationally efficient than repeatedly retraining your model with different resampling or reweighting parameters.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In the experiment “Resampling or Reweighting to Control Output Statistics” in the <a href="https://github.com/PilCAki/imbalanced-dataset-common-errors/blob/main/Imbalanced%20Dataset%20Examples.ipynb" target="_self">linked notebook</a>, we perform the following experiment:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">Obtain a particular value of “recall” using resampling.</li><li class="ff3" style="font-size:22px;">Show that we can find a decision threshold using a model trained on the raw data that attains that same recall.</li><li class="ff3" style="font-size:22px;">Repeat for a variety of recall values attained through resampling and show that we can match it every time.</li><li class="ff3" style="font-size:22px;">Compare precision values.</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In this case, we find that the model trained on the resampled dataset is able to achieve equal recall in each case with a precision value that is equal to or exceeds that which is obtained through resampling.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*riyFzG0BZ-dB0WDuI9SK8w.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*riyFzG0BZ-dB0WDuI9SK8w.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*riyFzG0BZ-dB0WDuI9SK8w.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*riyFzG0BZ-dB0WDuI9SK8w.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*riyFzG0BZ-dB0WDuI9SK8w.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*riyFzG0BZ-dB0WDuI9SK8w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*riyFzG0BZ-dB0WDuI9SK8w.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*riyFzG0BZ-dB0WDuI9SK8w.png 640w, https://miro.medium.com/v2/resize:fit:720/1*riyFzG0BZ-dB0WDuI9SK8w.png 720w, https://miro.medium.com/v2/resize:fit:750/1*riyFzG0BZ-dB0WDuI9SK8w.png 750w, https://miro.medium.com/v2/resize:fit:786/1*riyFzG0BZ-dB0WDuI9SK8w.png 786w, https://miro.medium.com/v2/resize:fit:828/1*riyFzG0BZ-dB0WDuI9SK8w.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*riyFzG0BZ-dB0WDuI9SK8w.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*riyFzG0BZ-dB0WDuI9SK8w.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*riyFzG0BZ-dB0WDuI9SK8w.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Comparison of precision / recall tradeoffs achievable when using downsampling vs using the entire dataset. See linked Jupyter notebook for code to generate this table.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In large part, we’re able to not only match but beat the precision of the resampling strategy each time because we’re downsampling (the most common resampling strategy). Downsampling throws away data — and sometimes a lot of it if you’ve got a highly imbalanced dataset. You would expect a model trained on more data would perform better in general, which is what we’re seeing here.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You do not need to mutilate your dataset to get the recall you want! Just remember to use a tuned decision threshold.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Mistake 5: Tuning and evaluating model performance on resampled validation or test sets</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Typically, datasets are split into three groups:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ol><li class="ff3" style="font-size:22px;">A training set for training the model.</li><li class="ff3" style="font-size:22px;">A validation set to repeatedly validate the model’s performance on data not used in training.</li><li class="ff3" style="font-size:22px;">A test set to be used one time at the end to simulate the model’s performance in a production environment.</li></ol></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">When resampling, it is important to resample only the training set and not the validation or test sets. This means that one must first split the data into training, validation, and test sets, and then resample the training set.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">It is easy to accidentally resample the validation or test set by first resampling the entire dataset and then breaking it into training, validation, and test sets. That can be problematic for two reasons:</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><ul><li class="ff3" style="font-size:22px;">The validation and test sets are meant to represent the data that the model will encounter when making predictions in production. These sets should match what would be encountered in production as closely as possible. <strong>Resampling the validation and test sets generally makes the classification problem appear easier than it actually is </strong>and results in misleadingly optimistic evaluations of model performance.</li><li class="ff3" style="font-size:22px;">In addition, care must always be taken to avoid leakage in your evaluation setups. If not done carefully, <strong>upsampling and other types of resampling with replacement can result in validation and test sets that contain duplicates of samples from the training set.</strong> This too will result in misleadingly optimistic model evaluation and drastically increases the potential for overfitting.</li></ul></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Both of these errors can exaggerate model quality statistics to the extent that a model unfit for deployment may appear to have excellent accuracy. Often the impact of this kind of error is not discovered until the model has been consumed downstream, sometimes for months or more, especially if the only performance statistics being monitored are based on resampled datasets.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">What to try instead</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you do end up needing to resample for some reason, <strong>construct your validation and test sets before resampling</strong> — not after.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Keep clean separations between all dataset divides and <strong>be especially diligent regarding the test set </strong>— it’s the final gateway to testing viability of a model in production. This should be as close to production expectations as possible.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We illustrate the downside of validating on a resampled dataset compared to our best practices recommendation of doing no resampling in the experiment “Evaluating on resampled datasets” in the <a href="https://github.com/PilCAki/imbalanced-dataset-common-errors/blob/main/Imbalanced%20Dataset%20Examples.ipynb" target="_self">linked notebook</a>. In this experiment, we train a model and choose a decision threshold that maximizes f1 score on our validation set, and then apply it to our “production” dataset. We do this twice; once with a training set we resample before splitting out validation, and once with a training set in which we do no resampling.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Here is a table of results:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:84%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 620px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*pNWW3WPxhilNa6yNNPNsHA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*pNWW3WPxhilNa6yNNPNsHA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*pNWW3WPxhilNa6yNNPNsHA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*pNWW3WPxhilNa6yNNPNsHA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*pNWW3WPxhilNa6yNNPNsHA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*pNWW3WPxhilNa6yNNPNsHA.png 1100w, https://miro.medium.com/v2/resize:fit:1240/format:webp/1*pNWW3WPxhilNa6yNNPNsHA.png 1240w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 620px" srcset="https://miro.medium.com/v2/resize:fit:640/1*pNWW3WPxhilNa6yNNPNsHA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*pNWW3WPxhilNa6yNNPNsHA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*pNWW3WPxhilNa6yNNPNsHA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*pNWW3WPxhilNa6yNNPNsHA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*pNWW3WPxhilNa6yNNPNsHA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*pNWW3WPxhilNa6yNNPNsHA.png 1100w, https://miro.medium.com/v2/resize:fit:1240/1*pNWW3WPxhilNa6yNNPNsHA.png 1240w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:620/1*pNWW3WPxhilNa6yNNPNsHA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Results comparing resampled versus non-resampled validation sets to true model performance (“prod”). Note that the resampled validation set yields drastically overoptimistic performance estimates while the non-resampled validation set is right in line with “production” performance.</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The first thing to note is that the evaluation metrics on the resampled validation set look much better than those same metrics as computed on the non-resampled validation set. For example, the f1 score on the resampled validation set is 79% compared to 50% on the non-resampled validation set. This is the prime motivating factor behind making this mistake. These statistics look much better — but appearances can be deceiving. These are spurious results.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Recall that these models were selected to maximize the f1 score. We can see the “true” performance of the model reflected in the “prod_f1_score”. The “prod” dataset was split off before any data science was done and is reflective of the data the model would see after deployment.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Despite the fact that the model trained and evaluated on the resampled dataset appeared to achieve an f1 score of 79%, when evaluated on a representative test set we find that it’s substantially worse at 38%. The resampled validation set statistics were drastically overoptimistic. Imagine making a business decision on the basis of a statistic this misaligned with reality!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">On the other hand, the model trained on the untouched dataset was estimated to achieve a 50% f1 score based on validation, which it essentially achieved when evaluated on a representative test set (49%).</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Without resampling, not only was the estimated performance of the model using a validation set much closer to the reality we achieved in “prod”, but the model is also substantially better — an f1 score of 49% vs 38%.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">Use cases for resampling or reweighting data</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Although this article clearly discourages resampling imbalanced data, there may be certain instances where resampling or reweighting could be appropriate. Generally, there may be good reason to resample your data if you are encountering resource constraints (like time or memory) or if your optimizer is struggling.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">For example, if there is a massive amount of data that is too cumbersome to process, it may be acceptable to downsample the majority class to reduce the train time. This may result in a drop in performance because there is less data to learn from. But, if train time is a priority, a slight decrease in performance could be worth it. However, we’d still want to be sure we only downsample the training data, leaving the validation and test sets untouched. In addition, if calibration is important, we’d recommend reweighting the dataset to assess resampling’s effect on the model calibration.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">An example of where upsampling may be appropriate is when it is possible to create new examples of the minority class through data augmentation. Instead of upsampling through exactly duplicating data points, data augmentation is the process of creating new artificial data points from the minority class. A popular technique for doing this is called Synthetic Minority Oversampling Technique (SMOTE). If you’re operating in a regime of data scarcity and could benefit from some extra samples, sometimes data augmentation can be helpful. Data augmentation is not meant to fix class imbalance, but instead to fix the issue of data scarcity where there are not enough samples from the minority class to learn from. Again, we’d recommend that you counteract the augmentation’s effect on class balance with appropriate reweighting to ensure continued model calibration.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Reweighting also has its place. In particular, there are methods that may require a sample-specific weighting to reflect the noise in the target value. There may also be cost functions that are easiest to implement as reweighted versions of pre-existing cost functions. Reweighting can also be used to undo the miscalibration brought on by resampling.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Let’s summarize with a summary that is printable for your cork board:</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*qJy-5HD4YuA0_GuEUIcJBQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*qJy-5HD4YuA0_GuEUIcJBQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*qJy-5HD4YuA0_GuEUIcJBQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*qJy-5HD4YuA0_GuEUIcJBQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*qJy-5HD4YuA0_GuEUIcJBQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*qJy-5HD4YuA0_GuEUIcJBQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qJy-5HD4YuA0_GuEUIcJBQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*qJy-5HD4YuA0_GuEUIcJBQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*qJy-5HD4YuA0_GuEUIcJBQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*qJy-5HD4YuA0_GuEUIcJBQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*qJy-5HD4YuA0_GuEUIcJBQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*qJy-5HD4YuA0_GuEUIcJBQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*qJy-5HD4YuA0_GuEUIcJBQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*qJy-5HD4YuA0_GuEUIcJBQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*qJy-5HD4YuA0_GuEUIcJBQ.png"></picture></div><br></div></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>