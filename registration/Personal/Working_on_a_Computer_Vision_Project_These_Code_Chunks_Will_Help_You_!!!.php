<!DOCTYPE html>
                <html>
                <head>
                    <title>Working on a Computer Vision Project? These Code Chunks Will Help You !!!</title>
                <?php include_once 'Elemental/header.php'; ?><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><br><br><h5> This article is reformatted from originally published at <a href="https://pub.towardsai.net/working-on-a-computer-vision-project-these-code-chunks-will-help-you-45756bbe7e65"><strong>TDS(Towards Data Science)</strong></a></h5></br><h5> <a href="https://medium.com/@BH_Chinmay?source=post_page-----45756bbe7e65--------------------------------">Author : Chinmay Bhalerao</a> </h5></div></div></div></section><section data-bs-version="5.1" class="content4 cid-tt5SM2WLsM" id="content4-2" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
            <div class="container">
                <div class="row justify-content-center">
                    <div class="title col-md-12 col-lg-9">
                        <h3 class="mbr-section-title mbr-fonts-style mb-4 display-2">
                            <strong>Working on a Computer Vision Project? These Code Chunks Will Help You !!!</h3></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5 text-muted">An introduction to a few “used to” methods in a computer vision project</h4></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*K1RYveEPTCBgvf6LwOs7rA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*K1RYveEPTCBgvf6LwOs7rA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*K1RYveEPTCBgvf6LwOs7rA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*K1RYveEPTCBgvf6LwOs7rA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*K1RYveEPTCBgvf6LwOs7rA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*K1RYveEPTCBgvf6LwOs7rA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K1RYveEPTCBgvf6LwOs7rA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*K1RYveEPTCBgvf6LwOs7rA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*K1RYveEPTCBgvf6LwOs7rA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*K1RYveEPTCBgvf6LwOs7rA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*K1RYveEPTCBgvf6LwOs7rA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*K1RYveEPTCBgvf6LwOs7rA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*K1RYveEPTCBgvf6LwOs7rA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*K1RYveEPTCBgvf6LwOs7rA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*K1RYveEPTCBgvf6LwOs7rA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Computer vision projects [<a href="https://blogs.nvidia.com/blog/2019/10/23/drive-labs-panoptic-segmentation/" target="_self">Source</a>]</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">“VR and AR will eventually converge, and smart glasses will take over our digital interactions.”― <strong>Carlos López (Founder @ Oarsis)</strong></p></blockquote></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><span>T</span>he amazing thing about working in Computer vision and machine learning is that after every few years, somebody invents something crazy that makes you totally reconsider what's possible!!!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The World got a new eye & new way of thinking and tracking objects since the emergence of Computer vision algorithms. Starting from Region-Based Convolutional Neural Networks [RCNN] to YOLO V7, detectron-2, segformer, and classification architectures, computer vision changed drastically for higher efficiency of detection and higher latency with less requirement of time and computational expensiveness.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">A computer vision project is a combination of many things, from data collection to successful deployment. Understanding data and the right processing and training is the key to success. Below are a few code chunks with descriptions of their work that will ease your working on the project.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">1. Know your dataset’s instances</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">for the object detection or segmentation project, we annotate our dataset with the help of external annotation tools like <a href="https://www.makesense.ai/" target="_self">makesense.ai</a>, <a href="https://www.robots.ox.ac.uk/~vgg/software/via/via_demo.html" target="_self">VGG annotator</a>, <a href="https://github.com/heartexlabs/labelImg" target="_self">LableIMG</a>, etc.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*KdW_Y2JnHtQkZgKSk690YQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*KdW_Y2JnHtQkZgKSk690YQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*KdW_Y2JnHtQkZgKSk690YQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*KdW_Y2JnHtQkZgKSk690YQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*KdW_Y2JnHtQkZgKSk690YQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*KdW_Y2JnHtQkZgKSk690YQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KdW_Y2JnHtQkZgKSk690YQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*KdW_Y2JnHtQkZgKSk690YQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*KdW_Y2JnHtQkZgKSk690YQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*KdW_Y2JnHtQkZgKSk690YQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*KdW_Y2JnHtQkZgKSk690YQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*KdW_Y2JnHtQkZgKSk690YQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*KdW_Y2JnHtQkZgKSk690YQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*KdW_Y2JnHtQkZgKSk690YQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*KdW_Y2JnHtQkZgKSk690YQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Example of an imbalance dataset in object detection [Image <a href="https://www.semanticscholar.org/paper/Frame-Augmentation-for-Imbalanced-Object-Detection-Elasal-Swart/f183c02ef708ef6e7c49a3720947599d54014ccb" target="_self">Source</a>]</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">We know the exact number of images, but it's hard to know how many instances of each class we have. Knowing instances of the class will tell you if your dataset is imbalanced or not. It will have a deep impact on the learning model if your instances are not balanced. So after downloading annotated dataset and its annotation file, you can use the following chunk of code to see the class balance status.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><span>import</span> os<br/><span>#Give path of folder in which you stored images and annotations </span><br/>path = <span>r"Your dataset *folder* location"</span> <br/><span># Change the directory to path </span><br/>os.chdir(path)<br/>x=[]<br/><span># Spinning through all files </span><br/><span>for</span> file <span>in</span> os.listdir():<br/><span># Checking for text annotation file </span><br/>    <span>if</span> file.endswith(<span>".txt"</span>):<br/>        file_path = <span>f"<span>{path}</span>\{file}"</span><br/>        <span>with</span> <span>open</span>(file_path, <span>'r'</span>) <span>as</span> f:<br/>            <span>for</span> line <span>in</span> f:<br/>                a=line[<span>0</span>]<br/>                x.append(a)<br/><span>print</span>(x)<br/><span>#to count instances </span><br/><span>from</span> collections <span>import</span> Counter<br/>Counter(x)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*mjsIo27_AIG2rQVmuBsSBQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*mjsIo27_AIG2rQVmuBsSBQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*mjsIo27_AIG2rQVmuBsSBQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*mjsIo27_AIG2rQVmuBsSBQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*mjsIo27_AIG2rQVmuBsSBQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*mjsIo27_AIG2rQVmuBsSBQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mjsIo27_AIG2rQVmuBsSBQ.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*mjsIo27_AIG2rQVmuBsSBQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*mjsIo27_AIG2rQVmuBsSBQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*mjsIo27_AIG2rQVmuBsSBQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*mjsIo27_AIG2rQVmuBsSBQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*mjsIo27_AIG2rQVmuBsSBQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*mjsIo27_AIG2rQVmuBsSBQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*mjsIo27_AIG2rQVmuBsSBQ.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*mjsIo27_AIG2rQVmuBsSBQ.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image by Author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You can see, at last, the counter gives instance values for each class, and then on your model criteria, you can decide if the dataset needs further balancing or not.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">2. Preprocessing of images</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In our image dataset, other than class instances, we have many other objects/things. If we take it for the learning purpose of the model, then these other items can be classified as noises. There are many use cases that claim that removing these noises and then sending them to the model for training improves the performance of the model. So how do preprocess images? See the below code.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><span>#Writing a function to create mouse masking </span><br/><span>#We are using mouse click events here</span><br/><span>import</span> numpy <span>as</span> np<br/><span>import</span> cv2 <span>as</span> cv<br/>drawing = <span>False</span> <span># true if mouse is pressed</span><br/>mode = <span>True</span> <span># if True, draw rectangle. Press 'm' to toggle to curve</span><br/>ix,iy = -<span>1</span>,-<span>1</span><br/><span># mouse callback function</span><br/><span>def</span> <span>draw_circle</span>(<span>event,x,y,flags,param</span>):<br/>    <span>global</span> ix,iy,drawing,mode<br/>    <span>if</span> event == cv.EVENT_LBUTTONDOWN:<br/>        drawing = <span>True</span><br/>        ix,iy = x,y<br/>    <span>elif</span> event == cv.EVENT_MOUSEMOVE:<br/>        <span>if</span> drawing == <span>True</span>:<br/>            <span>if</span> mode == <span>True</span>:<br/>                cv.rectangle(img,(ix,iy),(x,y),(<span>255</span>,<span>255</span>,<span>255</span>),-<span>1</span>)<br/>                <span>#(255,255,255) represents white color but you can give any.</span><br/>                <span># -1 represents filled box and 1 represents hollow box </span><br/>            <span>else</span>:<br/>                cv.circle(img,(x,y),<span>5</span>,(<span>0</span>,<span>0</span>,<span>255</span>),-<span>1</span>)<br/>    <span>elif</span> event == cv.EVENT_LBUTTONUP:<br/>        drawing = <span>False</span><br/>        <span>if</span> mode == <span>True</span>:<br/>            cv.rectangle(img,(ix,iy),(x,y),(<span>255</span>,<span>255</span>,<span>255</span>),-<span>1</span>)<br/>        <span>else</span>:<br/>            cv.circle(img,(x,y),<span>5</span>,(<span>0</span>,<span>0</span>,<span>255</span>),-<span>1</span>)<br/>            <br/><span>#storing final output        </span><br/>            <br/>    cv2.imwrite(<span>"new_img.jpg"</span>,img)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><span>#Calling function and using it on input image </span><br/><span>import</span> cv2 <br/>img = cv2.imread(<span>r"Your image path"</span>,<span>1</span>)<br/><span>#resizing to fit on screen</span><br/>img = cv2.resize(img,(<span>1200</span>,<span>800</span>))<br/>cv.namedWindow(<span>'image'</span>)<br/>cv.setMouseCallback(<span>'image'</span>,draw_circle)<br/><span>while</span>(<span>1</span>):<br/>    cv.imshow(<span>'image'</span>,img)<br/>    k = cv.waitKey(<span>1</span>) &amp; <span>0xFF</span><br/>    <span>if</span> k == <span>ord</span>(<span>'m'</span>):<br/>        mode = <span>not</span> mode<br/>    <span>elif</span> k == <span>27</span>:<br/>        <span>break</span><br/>cv.destroyAllWindows()</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you run the above code, then you will have your training image in front of you, and your mouse will act as a mask maker. After clicking and hovering the mouse on an unnecessary object will direct create a mask on that object. I took white color for use case purposes, but you can take any according to your problem. You can train a separate object detection model for noise, and below that, you can attach this code. At first, the model will detect noise, and then this code will mask that bounding box with your desired color.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:81%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 600px" srcset="https://miro.medium.com/v2/resize:fit:640/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 1100w, https://miro.medium.com/v2/resize:fit:1200/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 1200w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 600px" srcset="https://miro.medium.com/v2/resize:fit:640/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 640w, https://miro.medium.com/v2/resize:fit:720/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 720w, https://miro.medium.com/v2/resize:fit:750/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 750w, https://miro.medium.com/v2/resize:fit:786/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 786w, https://miro.medium.com/v2/resize:fit:828/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 828w, https://miro.medium.com/v2/resize:fit:1100/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 1100w, https://miro.medium.com/v2/resize:fit:1200/1*RhSUIbk3Vrbn_kow0qF5Qw.gif 1200w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:600/1*RhSUIbk3Vrbn_kow0qF5Qw.gif"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Masking of noise objects [Image by Author]</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">There are many things you can do for image preprocessing, like cropping, making blur/contrast, etc. you can read my blog for more image preprocessing techniques.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://medium.com/nerd-for-tech/do-you-know-these-basic-image-processing-operations-2bac0e3363e8"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">Do you know these basic image processing operations?</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">Basics of Image Processing in Python</h3><p>medium.com</p></a></div></div></div></div></section><br><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">3. Data Augmentation</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">In every computer vision project, you want to augment the dataset to make it bigger to make the model’s work easier. There is much open-source software that does Augmentations for you, like <a href="https://app.roboflow.com/" target="_self">Roboflow</a>. But many times, there can be a problem with data security and confidentiality. So you can do your own dataset augmentation on your python editor. There is a library by TensorFlow known as “<a href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" target="_self">ImageDataGenerator</a>” which helps you to do this. See the below code.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><span># FOR COMPLETE FOLDER ANNOTATION</span><br/><span>#imports </span><br/><span>import</span> tensorflow<br/><span>import</span> keras<br/><span>import</span> numpy <span>as</span> np<br/><span>import</span> os<br/><span>from</span> PIL <span>import</span> Image<br/><span>from</span> skimage <span>import</span> io<br/>SIZE = <span>128</span><br/>dataset = []<br/>image_directory = <span>'Image folder address/'</span><br/><span>from</span> keras.preprocessing.image <span>import</span> ImageDataGenerator, array_to_img, img_to_array, load_img<br/><span># Gving required augmentations to image </span><br/><span>#ImageDataGenerator has many Augmentations, choose those who are good for your condition</span><br/>datagen = ImageDataGenerator(<br/>        rotation_range=<span>40</span>,<br/>        width_shift_range=<span>0.2</span>,<br/>        height_shift_range=<span>0.2</span>,<br/>        shear_range=<span>0.2</span>,<br/>        zoom_range=<span>0.2</span>,<br/>        horizontal_flip=<span>True</span>,<br/>        fill_mode=<span>'nearest'</span>)<br/><br/>my_images = os.listdir(image_directory)<br/><span>for</span> i, image_name <span>in</span> <span>enumerate</span>(my_images):<br/>    <span>if</span> (image_name.split(<span>'.'</span>)[<span>1</span>] == <span>'jpg'</span>):<br/>        image = io.imread(image_directory + image_name)<br/>        image = Image.fromarray(image,<span>'RGB'</span>)<br/>        image = image.resize((SIZE,SIZE))<br/>        dataset.append(np.array(image))  <br/>x = np.array(dataset)<br/>i = <span>0</span><br/><span>for</span> batch <span>in</span> datagen.flow(x, batch_size=<span>20</span>,<br/>                          save_to_dir=<span>'preview'</span>, save_prefix=<span>'Hard_Hat'</span>, save_format=<span>'jpeg'</span>):<br/>    i += <span>1</span><br/>    <span>if</span> i &gt; <span>200</span>:<br/>        <span>break</span><br/><br/> </span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><span>#FOR SINGLE IMAGE ANNOTATION</span><br/><br/><span>import</span> tensorflow<br/><span>import</span> keras<br/><span>from</span> keras.preprocessing.image <span>import</span> ImageDataGenerator, array_to_img, img_to_array, load_img<br/><span>#Adress of image</span><br/>img = load_img(<span>'Image address [should end with .jpg or .png]'</span>)  <br/><span>#Required augmentations </span><br/>datagen = ImageDataGenerator(<br/>        rotation_range=<span>40</span>,<br/>        width_shift_range=<span>0.2</span>,<br/>        height_shift_range=<span>0.2</span>,<br/>        shear_range=<span>0.2</span>,<br/>        zoom_range=<span>0.2</span>,<br/>        horizontal_flip=<span>True</span>,<br/>        fill_mode=<span>'nearest'</span>)<br/><br/>x = img_to_array(img) <br/>x = x.reshape((<span>1</span>,) + x.shape)  <br/><br/>i = <span>0</span><br/><span>for</span> batch <span>in</span> datagen.flow(x, batch_size=<span>1</span>,<br/>                          save_to_dir=<span>'preview/green_Aug'</span>, save_prefix=<span>'Hard_Hat_orange_Aug'</span>, save_format=<span>'jpeg'</span>):<br/>    i += <span>1</span><br/>    <span>if</span> i &gt; <span>20</span>:     <span>#20 is the output images that we will get. you can set any limit according to project</span><br/>        <span>break</span>  <br/></span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">The first chunk of code is for the folder of images. you can do mass augmentation from that. The second chunk is for single images. You can use any of the above according to your use case. The last “<strong>i</strong>” is the number of synthetic images you want to create. Choose an appropriate number and Augment it.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:96%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*9uOVOqcUlRTKg7QudEh1dA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*9uOVOqcUlRTKg7QudEh1dA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*9uOVOqcUlRTKg7QudEh1dA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*9uOVOqcUlRTKg7QudEh1dA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*9uOVOqcUlRTKg7QudEh1dA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*9uOVOqcUlRTKg7QudEh1dA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9uOVOqcUlRTKg7QudEh1dA.png 1400w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" srcset="https://miro.medium.com/v2/resize:fit:640/1*9uOVOqcUlRTKg7QudEh1dA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*9uOVOqcUlRTKg7QudEh1dA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*9uOVOqcUlRTKg7QudEh1dA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*9uOVOqcUlRTKg7QudEh1dA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*9uOVOqcUlRTKg7QudEh1dA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*9uOVOqcUlRTKg7QudEh1dA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*9uOVOqcUlRTKg7QudEh1dA.png 1400w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:700/1*9uOVOqcUlRTKg7QudEh1dA.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Augmented images by code [Image by author]</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">4. Dataset creation</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Many times, you require images from a webcam. but it's hard to click it and save it in the labeled folder for classification or object detection. It also involves a lot of manual tasks. below code is to click images for particular labels, and it directly will store them at the proper location.</p></div></div></div></section><section data-bs-version="5.1" class="content7 cid-ttbhFZC4Ql" id="content7-8" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
        <div class="container"><div class="row justify-content-center"><div class="col-12 col-md-9"><blockquote><p class="ff4">Mention your labels and mention how many images you want for each class. Then specify your path for storage. After every<strong> time.sleep(5)</strong>, it will click images until the creation of data.</p></blockquote></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><span># Importing modules </span><br/><span>import</span> cv2 <br/><span>import</span> uuid<br/><span>import</span> os<br/><span>import</span> time<br/><br/><span>#Classes that you want to use</span><br/>labels = [<span>'happyface'</span>, <span>'sadface'</span>, <span>'angryface'</span>, <span>'excitedface'</span>]<br/><span># How many images you want for each class</span><br/>number_imgs = <span>5</span><br/><span>#Image path </span><br/>IMAGES_PATH = os.path.join(<span>'Tensorflow'</span>, <span>'workspace'</span>, <span>'images'</span>, <span>'collectedimages'</span>)</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span><span>if</span> <span>not</span> <span>os</span>.<span>path</span>.exists(IMAGES_PATH):<br/>    <span>if</span> <span>os</span>.name == <span>'posix'</span>:<br/>        !mkdir -p {IMAGES_PATH}<br/>    <span>if</span> <span>os</span>.name == <span>'nt'</span>:<br/>         !mkdir {IMAGES_PATH}<br/><span>for</span> label <span>in</span> labels:<br/>    <span>path</span> = <span>os</span>.<span>path</span>.join(IMAGES_PATH, label)<br/>    <span>if</span> <span>not</span> <span>os</span>.<span>path</span>.exists(<span>path</span>):<br/>        !mkdir {<span>path</span>}</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="iframe"><pre><span># This will open your Webcam and start clicking images and save it in <span>.jpg</span> format<br/>for <span>label</span> in labels:<br/>    cap = cv2.<span>VideoCapture</span>(<span>0</span>)<br/>    <span>print</span>(<span>'Collecting images for {}'</span>.<span>format</span>(label))<br/>    time.<span>sleep</span>(<span>5</span>)<br/>    for imgnum in <span>range</span>(number_imgs):<br/>        <span>print</span>(<span>'Collecting image {}'</span>.<span>format</span>(imgnum))<br/>        ret, frame = cap.<span>read</span>()<br/>        imgname = os.path.<span>join</span>(IMAGES_PATH,label,label+<span>'.'</span>+<span>'{}.jpg'</span>.<span>format</span>(<span>str</span>(uuid.<span>uuid1</span>())))<br/>        cv2.<span>imwrite</span>(imgname, frame)<br/>        cv2.<span>imshow</span>(<span>'frame'</span>, frame)           <br/>        time.<span>sleep</span>(<span>2</span>)<br/>        if cv2.<span>waitKey</span>(<span>1</span>) &amp; <span>0</span>xFF == <span>ord</span>(<span>'q'</span>):         <br/>            break<br/>cap.<span>release</span>()<br/>cv2.<span>destroyAllWindows</span>()</span></pre></div><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">You will get the below result after running the code chunk. and images will get stored at the specified location.</p></div></div></div></section><section data-bs-version="5.1" class="image3 cid-tt612oXwA9" id="image3-5" style="padding-top:0px; padding-bottom:0px; background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-lg-9">
                <div class="image-wrapper"><div class="image_style" style="width:70%;"><picture><source sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 518px" srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*zRLdibDPNCZcmT4sa0lfBw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*zRLdibDPNCZcmT4sa0lfBw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*zRLdibDPNCZcmT4sa0lfBw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*zRLdibDPNCZcmT4sa0lfBw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*zRLdibDPNCZcmT4sa0lfBw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*zRLdibDPNCZcmT4sa0lfBw.png 1100w, https://miro.medium.com/v2/resize:fit:1036/format:webp/1*zRLdibDPNCZcmT4sa0lfBw.png 1036w" type="image/webp"/><source data-testid="og" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 518px" srcset="https://miro.medium.com/v2/resize:fit:640/1*zRLdibDPNCZcmT4sa0lfBw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*zRLdibDPNCZcmT4sa0lfBw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*zRLdibDPNCZcmT4sa0lfBw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*zRLdibDPNCZcmT4sa0lfBw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*zRLdibDPNCZcmT4sa0lfBw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*zRLdibDPNCZcmT4sa0lfBw.png 1100w, https://miro.medium.com/v2/resize:fit:1036/1*zRLdibDPNCZcmT4sa0lfBw.png 1036w"/><img alt="" loading="lazy" role="presentation" src="https://miro.medium.com/v2/resize:fit:518/1*zRLdibDPNCZcmT4sa0lfBw.png"></picture></div><p class="mbr-description mbr-fonts-style mt-2 align-center display-12 text-muted" style="font-size:12px;">Image by Author</p><br></div></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">5. Extracting areas from the image</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">This is the most useful thing not just to detect or segment objects but to extract their areas. We use many techniques like pixel measurement and others. But the thing is, you have to do calibration before extracting areas to match the original dimensions and their representations in the image and their ratios. So for calibration, people use inbuilt ratios and reference object schemes, but I tried a new way of calculating the calibration factor. You have to draw just a line to do the calibration. I mentioned how to do that in the below blog.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://medium.com/@BH_Chinmay/calibration-in-image-processing-c4c164870f21"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">Calibration in Image Processing</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">Many times in image processing and object detection problems, we have to measure the sizes of objects from images. In…</h3><p>medium.com</p></a></div></div></div></div></section><br><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
            <br>
                <hr class="hr5">
            <br>
            </div>
        </div>
    </div>
</section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">These are a few chunks that will help you to build and contribute to your project. There were many things I wanted to cover, but still, this is enough for this blog section.</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">If you have found this article insightful</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">If you found this article insightful, follow me on <a href="https://www.linkedin.com/in/chinmay-bhalerao-6b5284137/" target="_self">Linkedin</a> and <a href="https://medium.com/@BH_Chinmay" target="_self">medium</a>. you can also <a href="https://medium.com/@BH_Chinmay" target="_self">subscribe</a> to get notified when I publish articles. Let’s create a community! Thanks for your support!</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-5">If you want to support me :</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">As Your following and clapping is the most important thing, but you can also support me by buying coffee. <a href="https://www.buymeacoffee.com/chinmaybhalerao" target="_self">COFFEE</a><strong>.</strong></p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><h4 class="mbr-section-subtitle mbr-fonts-style mb-4 display-7">You can read my other blogs related to :</h4></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://medium.com/mlearning-ai/feature-selection-techniques-for-data-57f0eacd8fa8"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">Feature selection techniques for data</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">Heuristic and Evolutionary feature selection techniques</h3><p>medium.com</p></a></div></div></div></div></section><br><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://medium.com/geekculture/simultaneous-localization-and-mapping-slam-systems-44d4369fcb46"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">Simultaneous Localization And Mapping [SLAM] systems</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">Introduction to outperforming DROID-SLAM system</h3><p>medium.com</p></a></div></div></div></div></section><br><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://medium.com/genetic-algorithm-optimization-8299856949d3"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">Genetic Algorithm Optimization</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">A detailed explanation of the evolutionary and nature-inspired optimization algorithm</h3><p>pub.towardsai.net</p></a></div></div></div></div></section><br><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><div class="sketchy"><a href="https://medium.com/ant-colony-optimization-an-overview-4bf7cb909b80"><h2 style="color:blueviolet; font-family:Arial, Helvetica, sans-serif; font-size:25px;">Ant Colony Optimization: An overview</h2><h3 style="color:rgb(45, 34, 54); font-family:Arial, Helvetica, sans-serif; font-size:20px;">Population-based metaheuristic nature-inspired optimization algorithm</h3><p>pub.towardsai.net</p></a></div></div></div></div></section><br><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;">Signing off,</p></div></div></div></section><section data-bs-version="5.1" class="content5 cid-tt5UseJ9wk" id="content5-4" style="padding-top:0px; padding-bottom:0px;background-color: rgb(255, 255, 255);">
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-9"><p class="ff3" style="font-size:22px;"><strong>Chinmay Bhalerao</strong></p></div></div></div></section><?php include_once 'Elemental/footer.php'; ?>