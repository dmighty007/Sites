{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from itertools import chain\n",
    "from selenium import webdriver\n",
    "import undetected_chromedriver as uc\n",
    "from time import sleep\n",
    "from urllib.parse import urljoin\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import tqdm.auto as tqdm\n",
    "import contextlib\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from mediumscrapper import ScrapeWebsite \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "class FeedPage:\n",
    "    def __init__(self):\n",
    "        self.start_driver()\n",
    "\n",
    "        title, content, rt, link, img_link = [], [], [], [], []\n",
    "        for query in [\"Machine+Learning\", \"Deep+Learning\", \"Python\", \"Programming\", \"Neural+Network\", \"CNN\", \"RNN\", \"GNN\", \"drug+discovery\", \"AI\"]:\n",
    "            t, c , r, l, i = self.QueryMaker(query = query)\n",
    "            title.append(t)\n",
    "            content.append(c)\n",
    "            rt.append(r)\n",
    "            link.append(l)\n",
    "            img_link.append(i)\n",
    "        myfilter = lambda x : x[:25]\n",
    "        self.all_titles = list(chain.from_iterable(map(myfilter, title)))\n",
    "        self.all_contents = list(chain.from_iterable(map(myfilter, content)))\n",
    "        self.all_rt = list(chain.from_iterable(map(myfilter, rt)))\n",
    "        self.all_links = list(chain.from_iterable(map(myfilter, link)))\n",
    "        self.all_images = list(chain.from_iterable(map(myfilter, img_link)))\n",
    "        self.scrapSite()\n",
    "        self.makeHTML()\n",
    "        self.driver.close()\n",
    "\n",
    "\n",
    "    def start_driver(self):\n",
    "        options = Options()\n",
    "        #options.add_argument('--headless')\n",
    "        options.add_argument('--disable-gpu')\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument('--start-maximized')\n",
    "        self.driver = uc.Chrome(exec_file = \"/home/dibya/Dibyendu/Test/HTML/selenium/chromedriver/linux64/109.0.5414.74/chromedriver\",options = options)\n",
    "        \n",
    "    def GiveR(self, url):\n",
    "        r = requests.get(url, allow_redirects=False)\n",
    "        if r.status_code != 301:\n",
    "            self.driver.get(url)\n",
    "            screen_height = self.driver.execute_script(\"return window.screen.height;\")   # get the screen height of the web\n",
    "            timeout = time.time() + 60*0.5\n",
    "            scroll_pause_time = 0.5\n",
    "            i = 1\n",
    "            for _ in range(6):\n",
    "                while True:\n",
    "                    # scroll one screen height each time\n",
    "                    self.driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))  \n",
    "                    i += 1\n",
    "                    time.sleep(scroll_pause_time)\n",
    "\n",
    "                    # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n",
    "                    scroll_height = self.driver.execute_script(\"return document.body.scrollHeight;\")  \n",
    "                    # Break the loop when the height we need to scroll to is larger than the total scroll height\n",
    "                    if (screen_height) * i > scroll_height:\n",
    "                        break\n",
    "                r = self.driver.page_source\n",
    "                bts = BeautifulSoup(r, 'html.parser').find_all(\"button\")\n",
    "                for i in range(len(bts)):\n",
    "                    if bts[i].getText() == \"Show more\":\n",
    "                        selector = bts[i]['class'][0]\n",
    "                #btn = self.driver.find_elements(By.CLASS_NAME, selector)[0]\n",
    "                #self.driver.execute_script(\"arguments[0].click();\", WebDriverWait(self.driver, 30).until(EC.element_to_be_clickable(btn)))\n",
    "                self.driver.execute_script(\"arguments[0].click();\", WebDriverWait(self.driver, 30).until(EC.element_to_be_clickable((By.XPATH, \"//button[text()='Show more']\"))))\n",
    "            r = self.driver.page_source\n",
    "            return r\n",
    "\n",
    "    def QueryMaker(self, query):\n",
    "        r = self.GiveR(f\"https://medium.com/search?q={query}\")\n",
    "        soup = BeautifulSoup(r, 'html.parser')\n",
    "        articles = soup.find_all('article')\n",
    "        title_list, content_list, rt_list, link_list, img_list = [], [], [], [], []\n",
    "        for article in articles:\n",
    "            title, content, rt , link, img_link = self.getDetails(article)\n",
    "            title_list.append(title)\n",
    "            content_list.append(content)\n",
    "            rt_list.append(rt)\n",
    "            link_list.append(link)\n",
    "            img_list.append(img_link)\n",
    "        return title_list, content_list, rt_list, link_list, img_list\n",
    "\n",
    "    def getDetails(self, article):\n",
    "        all_a = article.find_all(\"a\")\n",
    "        title, content, rt, link, img_link = None, None, None, None, None  \n",
    "        for a in all_a:\n",
    "            with contextlib.suppress(Exception):\n",
    "                #print(a.text)\n",
    "                label = a.extract()['aria-label']\n",
    "                #print(label)\n",
    "                if label == \"Post Preview Title\":\n",
    "                    title = a.find(\"h2\").getText()\n",
    "                    content = a.find(\"p\").getText()\n",
    "                elif label == \"Post Preview Reading Time\":\n",
    "                    rt = a.getText()\n",
    "                elif label == \"Post Preview Image\":\n",
    "                    link = a.extract()['href']\n",
    "                image = a.find('img')\n",
    "                img_link = image.extract()['src']\n",
    "                \n",
    "        return title, content, rt, link, img_link\n",
    "\n",
    "    def formatDate(self, date):\n",
    "        return datetime.datetime.strptime(date,  '%b %d, %Y').strftime('%Y-%m-%d')\n",
    "    \n",
    "    def TagExtracter(self, Scrappable):\n",
    "        All_As = Scrappable.Soup.find_all('a', {'rel':\"noopener follow\"})\n",
    "        Checker = lambda x : 'tag' in x['href']\n",
    "        tag_links = np.array(All_As, dtype = object)[list(map(Checker, All_As))]\n",
    "        Tagger = lambda x : x.getText()\n",
    "        return np.unique(list(map(Tagger, tag_links)))\n",
    "\n",
    "    def formatTitle(self, title):\n",
    "        remove_chars = ['[', ']', '/', '`', '\"', \"'\", '…', '.', ',', '’', '‘', '\\n', '“', '”', ':', '：', '，', \"?\", \"!\"]\n",
    "        replace_with_space = [':']\n",
    "\n",
    "        for char in remove_chars:\n",
    "            title = title.replace(char, '')\n",
    "\n",
    "        for char in replace_with_space:\n",
    "            title = title.replace(char, ' ')\n",
    "\n",
    "        title = '_'.join(title.split())\n",
    "\n",
    "        return title\n",
    "    def transform_data(self, author, title, content, date, tag, image, dir = \"files\"):\n",
    "\n",
    "        # Replace single and double quotes\n",
    "        author = author.replace(\"'\", \"\").replace('\"', '').replace('’', '').replace('‘', '')\n",
    "        title = title.replace(\"'\", \"\").replace('\"', '').replace('’', '').replace('‘', '')\n",
    "        content = content.replace(\"'\", \"\").replace('\"', '').replace('’', '').replace('‘', '').replace('…', '...')[:200]\n",
    "        \n",
    "        # Replace punctuation\n",
    "        author = author.replace('\\n','').replace('”', '').replace('“', '').replace(':', '').replace('：', '').replace('，', '')\n",
    "        title = title.replace('\\n','').replace('”', '').replace('“', '').replace(':', '').replace('：', '').replace('，', '')\n",
    "        \n",
    "        # Format Title & Date\n",
    "        formated_title = self.formatTitle(title)\n",
    "        formatted_date = self.formatDate(date)\n",
    "        \n",
    "        # Join tag list into string\n",
    "        joined_tags = '_'.join(tag)\n",
    "        \n",
    "        # Return dictionary with transformed data\n",
    "        return {\n",
    "            \"title\": title,\n",
    "            \"content\": content,\n",
    "            \"author\": author,\n",
    "            \"image\": image.replace(\"112\", \"640\"),\n",
    "            \"tag\": joined_tags,\n",
    "            \"dt\": formatted_date,\n",
    "            \"file\": f\"{dir}/{formated_title}.php\"\n",
    "        }\n",
    "\n",
    "    def getOne(self, image, title, content, date, file, author, tag):\n",
    "        \n",
    "        return f\"\"\"<div class=\"item features-image сol-12 col-md-6 col-lg-4\" data-type=\"{tag}\">\n",
    "                        <div class=\"item-wrapper\">\n",
    "                            <div class=\"item-img\">\n",
    "                                <img src={image} alt=\"Image\" loading=\"lazy\" \n",
    "                                    title=\"\">\n",
    "                            </div>\n",
    "                            <div class=\"item-content\">\n",
    "                                <h5 class=\"text-muted\" style=\"font-size:15px; float:left;\">\n",
    "                                    <strong>{author}</strong>\n",
    "                                    <em>&nbsp;{date}</em>\n",
    "                                </h5>\n",
    "                                <br>\n",
    "                                <h6 class=\"item-subtitle mbr-fonts-style mt-1 display-7\"><strong>{title}</strong>\n",
    "                                </h6>\n",
    "                                <p class=\"ff3\">{content}...</p>\n",
    "                            </div>\n",
    "                            <div class=\"mbr-section-btn item-footer mt-2 text-center\">\n",
    "                                <a class=\"slide btn text-center\" id=\"button\" href=\"{file}\" >&nbsp;</a></div>\n",
    "                        </div>\n",
    "                    </div>\"\"\"\n",
    "\n",
    "\n",
    "    def GetDiv(self, detail_list ):\n",
    "        forYou_text = \"\"\"<section data-bs-version=\"5.1\" class=\"content2 cid-sFAOw5Fdod\" id=\"content2-e\" style=\"padding-top: 0px; padding-bottom: 0px;\">\n",
    "                <div class=\"container\">\n",
    "                <div class=\"mbr-section-head\">\n",
    "                <br><br>\n",
    "                    <h4 class=\"mbr-section-title mbr-fonts-style align-center mb-0 display-2\"><strong>Free Articles from\n",
    "                            Medium!</strong></h4>\n",
    "                    <h5 class=\"mbr-section-subtitle mbr-fonts-style align-center mb-0 mt-2 display-5\">Read the recent blog\n",
    "                        about ML, DL and Data Science from Towards Data Science.</h5>\n",
    "                </div><div class=\"row mt-4\">\"\"\"\n",
    "\n",
    "        for i in range(len(detail_list)):\n",
    "            #print(i)\n",
    "            #data = transform_data(all_authors[i], all_titles[i], all_contents[i], all_dates[i], all_tags[i], all_images[i], dir = \"Feed\")\n",
    "            with contextlib.suppress(Exception):\n",
    "                data = self.transform_data(self.all_authors[i], self.all_titles[i], self.all_contents[i], self.all_dates[i], self.all_tags[i], self.all_images[i], dir = \"Feed\")\n",
    "                title = data['title']\n",
    "                date = data['dt']\n",
    "                image = data['image']\n",
    "                author = data['author']\n",
    "                content = data['content']\n",
    "                file = data['file']\n",
    "                tag = data['tag']\n",
    "                #print(data)\n",
    "                forYou_text += self.getOne(title=title, date=date, image=image, author=author, content=content, tag = tag, file = file)\n",
    "        forYou_text += \"\"\"</div></div></section>\"\"\"\n",
    "        return forYou_text\n",
    "\n",
    "    def scrapSite(self):\n",
    "        Scrappable = ScrapeWebsite()\n",
    "        author_list = []\n",
    "        Address_list = []\n",
    "        tag_list = []\n",
    "        date_list = []\n",
    "        for i in tqdm.trange(len(self.all_links)):\n",
    "            with contextlib.suppress(Exception):\n",
    "                if self.all_links[i] != None:\n",
    "                    curl = f'https://medium.com{self.all_links[i]}'\n",
    "                    Scrappable.DoScrap(curl, save_dir=\"./Feed/\") \n",
    "                    Author, Address = Scrappable.GiveAuthor(Scrappable.Soup)\n",
    "                    Date = Scrappable.Soup.find('p', {'class':'pw-published-date'}).getText()\n",
    "                    tags = self.TagExtracter(Scrappable)\n",
    "                    tag_list.append(tags)\n",
    "                    date_list.append(Date)\n",
    "                    Address_list.append(Address)\n",
    "                    author_list.append(Author)\n",
    "                else:\n",
    "                    tag_list.append(None)\n",
    "                    date_list.append(None)\n",
    "                    Address_list.append(None)\n",
    "                    author_list.append(None)\n",
    "        self.all_authors = author_list\n",
    "        self.all_address = Address_list\n",
    "        self.all_dates = date_list\n",
    "        self.all_tags = tag_list\n",
    "    def makeHTML(self):\n",
    "        head = open(\"Elemental/header.html\").read()\n",
    "        foot = open(\"Elemental/footer.html\").read()\n",
    "        with open(\"Feed2.html\", \"w\") as f:\n",
    "            f.write(head)\n",
    "            f.write(self.GetDiv(self.all_address))\n",
    "            f.write(foot)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e04b9c2d8d4780b43ca0dbf7796487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: target frame detached\n  (failed to check if window was closed: disconnected: Unable to receive message from renderer)\n  (Session info: chrome=110.0.5481.100)\nStacktrace:\n#0 0x5629c3139d93 <unknown>\n#1 0x5629c2f0815d <unknown>\n#2 0x5629c2ef23aa <unknown>\n#3 0x5629c2ef0ee2 <unknown>\n#4 0x5629c2ef1682 <unknown>\n#5 0x5629c2efeb4f <unknown>\n#6 0x5629c2eff7a2 <unknown>\n#7 0x5629c2f0fdd1 <unknown>\n#8 0x5629c2f80787 <unknown>\n#9 0x5629c2f68353 <unknown>\n#10 0x5629c2f37e40 <unknown>\n#11 0x5629c2f39038 <unknown>\n#12 0x5629c318d8be <unknown>\n#13 0x5629c31918f0 <unknown>\n#14 0x5629c3171f90 <unknown>\n#15 0x5629c3192b7d <unknown>\n#16 0x5629c3163578 <unknown>\n#17 0x5629c31b7348 <unknown>\n#18 0x5629c31b74d6 <unknown>\n#19 0x5629c31d1341 <unknown>\n#20 0x7f4800af5bb5 <unknown>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_176099/3442084094.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeedPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_176099/1946220221.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_link\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscrapSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakeHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_176099/1946220221.py\u001b[0m in \u001b[0;36mscrapSite\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_links\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mcurl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'https://medium.com{self.all_links[i]}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mScrappable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDoScrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./Feed/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0mAuthor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAddress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScrappable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGiveAuthor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mScrappable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mDate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScrappable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'pw-published-date'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Soft/Fresh/Scraper/mediumscrapper.py\u001b[0m in \u001b[0;36mDoScrap\u001b[0;34m(self, url, save_dir)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGiveR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'article'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Soft/Fresh/Scraper/mediumscrapper.py\u001b[0m in \u001b[0;36mGiveR\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mscroll_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"return document.body.scrollHeight;\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;31m# Break the loop when the height we need to scroll to is larger than the total scroll height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mscroll_height\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Soft/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute_script\u001b[0;34m(self, script, *args)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW3C_EXECUTE_SCRIPT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"script\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"args\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconverted_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_async_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Soft/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Soft/anaconda3/lib/python3.9/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: target frame detached\n  (failed to check if window was closed: disconnected: Unable to receive message from renderer)\n  (Session info: chrome=110.0.5481.100)\nStacktrace:\n#0 0x5629c3139d93 <unknown>\n#1 0x5629c2f0815d <unknown>\n#2 0x5629c2ef23aa <unknown>\n#3 0x5629c2ef0ee2 <unknown>\n#4 0x5629c2ef1682 <unknown>\n#5 0x5629c2efeb4f <unknown>\n#6 0x5629c2eff7a2 <unknown>\n#7 0x5629c2f0fdd1 <unknown>\n#8 0x5629c2f80787 <unknown>\n#9 0x5629c2f68353 <unknown>\n#10 0x5629c2f37e40 <unknown>\n#11 0x5629c2f39038 <unknown>\n#12 0x5629c318d8be <unknown>\n#13 0x5629c31918f0 <unknown>\n#14 0x5629c3171f90 <unknown>\n#15 0x5629c3192b7d <unknown>\n#16 0x5629c3163578 <unknown>\n#17 0x5629c31b7348 <unknown>\n#18 0x5629c31b74d6 <unknown>\n#19 0x5629c31d1341 <unknown>\n#20 0x7f4800af5bb5 <unknown>\n"
     ]
    }
   ],
   "source": [
    "F = FeedPage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_176099/665942277.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscrapSite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "F.scrapSite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "links = np.load('links.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953a647c6a734a278584441c9d70159d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d13fa35701b3ccf10ec30731592d3f10e2e0dbd94b9263cf3db1223b8cdbfc1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
