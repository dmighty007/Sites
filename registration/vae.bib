@article{1f9c63e957adb671e52a8a4368dbab25faefc428,
title = {Variational embedding of protein folding simulations using gaussian mixture variational autoencoders},
year = {2021},
url = {https://www.semanticscholar.org/paper/1f9c63e957adb671e52a8a4368dbab25faefc428},
abstract = {Conformational sampling of biomolecules using molecular dynamics simulations often produces large amount of high dimensional data that makes it difficult to interpret using conventional analysis techniques. Dimensionality reduction methods are thus required to extract useful and relevant information. Here we devise a machine learning method, Gaussian mixture variational autoencoder (GMVAE) that can simultaneously perform dimensionality reduction and clustering of biomolecular conformations in an unsupervised way. We show that GMVAE can learn a reduced representation of the free energy landscape of protein folding with highly separated clusters that correspond to the metastable states during folding. Since GMVAE uses a mixture of Gaussians as the prior, it can directly acknowledge the multi-basin nature of protein folding free-energy landscape. To make the model end-to-end differentialble, we use a Gumbel-softmax distribution. We test the model on three long-timescale protein folding trajectories and show that GMVAE embedding resembles the folding funnel with folded states down the funnel and unfolded states outer in the funnel path. Additionally, we show that the latent space of GMVAE can be used for kinetic analysis and Markov state models built on this embedding produce folding and unfolding timescales that are in close agreement with other rigorous dynamical embeddings such as time independent component analysis (TICA).},
author = {Mahdi Ghorbani and Samarjeet Prasad and Jeffery B. Klauda and B. Brooks},
journal = {ArXiv},
volume = {abs/2108.12493},
pages = {null},
doi = {10.1063/5.0069708},
arxivid = {2108.12493},
}

@article{06b0a8c66ba5a4da7363116e7f4d65f1703d7e31,
title = {Deep learning the slow modes for rare events sampling},
year = {2021},
url = {https://www.semanticscholar.org/paper/06b0a8c66ba5a4da7363116e7f4d65f1703d7e31},
abstract = {Significance The use of enhanced sampling simulations is essential in the study of complex physical, chemical, and biological processes. We devise a procedure that, by combining machine learning and biased simulations, removes the bottlenecks that hinder convergence. This approach allows different types of challenging processes to be studied in a near-blind way, thus extending significantly the scope of atomistic simulations. The development of enhanced sampling methods has greatly extended the scope of atomistic simulations, allowing long-time phenomena to be studied with accessible computational resources. Many such methods rely on the identification of an appropriate set of collective variables. These are meant to describe the system’s modes that most slowly approach equilibrium under the action of the sampling algorithm. Once identified, the equilibration of these modes is accelerated by the enhanced sampling method of choice. An attractive way of determining the collective variables is to relate them to the eigenfunctions and eigenvalues of the transfer operator. Unfortunately, this requires knowing the long-term dynamics of the system beforehand, which is generally not available. However, we have recently shown that it is indeed possible to determine efficient collective variables starting from biased simulations. In this paper, we bring the power of machine learning and the efficiency of the recently developed on the fly probability-enhanced sampling method to bear on this approach. The result is a powerful and robust algorithm that, given an initial enhanced sampling simulation performed with trial collective variables or generalized ensembles, extracts transfer operator eigenfunctions using a neural network ansatz and then accelerates them to promote sampling of rare events. To illustrate the generality of this approach, we apply it to several systems, ranging from the conformational transition of a small molecule to the folding of a miniprotein and the study of materials crystallization.},
author = {L. Bonati and G. Piccini and M. Parrinello},
journal = {Proceedings of the National Academy of Sciences},
volume = {118},
pages = {null},
doi = {10.1073/pnas.2113533118},
pmid = {34706940},
arxivid = {2107.03943},
}

@article{e4140d67d59c61de86d2a9de31380e01a07ef85b,
title = {Past–future information bottleneck for sampling molecular reaction coordinate simultaneously with thermodynamics and kinetics},
year = {2019},
url = {https://www.semanticscholar.org/paper/e4140d67d59c61de86d2a9de31380e01a07ef85b},
abstract = {S2 TL;DR: The authors adapt the Predictive Information Bottleneck framework to sample biomolecular structure and dynamics through iterative rounds of biased simulations and deep learning.},
author = {Yihang Wang and João Marcelo Lamim Ribeiro and P. Tiwary},
journal = {Nature Communications},
volume = {10},
pages = {null},
doi = {10.1038/s41467-019-11405-4},
pmid = {31395868},
}

@article{8743308fda3677f254973521d2761936b71f54ab,
title = {Data-Driven Collective Variables for Enhanced Sampling.},
year = {2020},
url = {https://www.semanticscholar.org/paper/8743308fda3677f254973521d2761936b71f54ab},
abstract = {Designing an appropriate set of collective variables is crucial to the success of several enhanced sampling methods. Here we focus on how to obtain such variables from information limited to the metastable states. We characterize these states by a large set of descriptors and employ neural networks to compress this information in a lower-dimensional space, using Fisher's linear discriminant as an objective function to maximize the discriminative power of the network. We test this method on alanine dipeptide, using the nonlinearly separable data set composed by atomic distances. We then study an intermolecular aldol reaction characterized by a concerted mechanism. The resulting variables are able to promote sampling by drawing nonlinear paths in the physical space connecting the fluctuations between metastable basins. Lastly, we interpret the behavior of the neural network by studying its relation to the physical variables. Through the identification of its most relevant features, we are able to gain chemical insight into the process.},
author = {L. Bonati and Valerio Rizzi and M. Parrinello},
journal = {The journal of physical chemistry letters},
volume = {null},
pages = {
          2998-3004
        },
doi = {10.1021/acs.jpclett.0c00535},
pmid = {32239945},
arxivid = {2002.06562},
}

@article{b20bd30a1274ac83242c2cbd74f452857a5f86e4,
title = {Multiscale Reweighted Stochastic Embedding: Deep Learning of Collective Variables for Enhanced Sampling},
year = {2020},
url = {https://www.semanticscholar.org/paper/b20bd30a1274ac83242c2cbd74f452857a5f86e4},
abstract = {Machine learning methods provide a general framework for automatically finding and representing the essential characteristics of simulation data. This task is particularly crucial in enhanced sampling simulations. There we seek a few generalized degrees of freedom, referred to as collective variables (CVs), to represent and drive the sampling of the free energy landscape. In theory, these CVs should separate different metastable states and correspond to the slow degrees of freedom of the studied physical process. To this aim, we propose a new method that we call multiscale reweighted stochastic embedding (MRSE). Our work builds upon a parametric version of stochastic neighbor embedding. The technique automatically learns CVs that map a high-dimensional feature space to a low-dimensional latent space via a deep neural network. We introduce several new advancements to stochastic neighbor embedding methods that make MRSE especially suitable for enhanced sampling simulations: (1) weight-tempered random sampling as a landmark selection scheme to obtain training data sets that strike a balance between equilibrium representation and capturing important metastable states lying higher in free energy; (2) a multiscale representation of the high-dimensional feature space via a Gaussian mixture probability model; and (3) a reweighting procedure to account for training data from a biased probability distribution. We show that MRSE constructs low-dimensional CVs that can correctly characterize the different metastable states in three model systems: the Müller-Brown potential, alanine dipeptide, and alanine tetrapeptide.},
author = {J. Rydzewski and O. Valsson},
journal = {The Journal of Physical Chemistry. a},
volume = {125},
pages = {6286 - 6302},
doi = {10.1021/acs.jpca.1c02869},
pmid = {34213915},
arxivid = {2007.06377},
}

@article{55705bec7256bb2f3ceec805823de4e87bee87f1,
title = {Machine Learning for Molecular Dynamics on Long Timescales},
year = {2018},
url = {https://www.semanticscholar.org/paper/55705bec7256bb2f3ceec805823de4e87bee87f1},
abstract = {S2 TL;DR: The learning problems in long timescale MD are defined, successful approaches are presented, and some of the unsolved ML problems in this application field are outlined.},
author = {F. Noé},
journal = {ArXiv},
volume = {abs/1812.07669},
pages = {null},
doi = {10.1007/978-3-030-40245-7_16},
arxivid = {1812.07669},
}

@article{4d6e7890bbfbc80ab369d8910fcb72267551fb36,
title = {Collective variable discovery and enhanced sampling using autoencoders: Innovations in network architecture and error function design.},
year = {2018},
url = {https://www.semanticscholar.org/paper/4d6e7890bbfbc80ab369d8910fcb72267551fb36},
abstract = {Auto-associative neural networks ("autoencoders") present a powerful nonlinear dimensionality reduction technique to mine data-driven collective variables from molecular simulation trajectories. This technique furnishes explicit and differentiable expressions for the nonlinear collective variables, making it ideally suited for integration with enhanced sampling techniques for accelerated exploration of configurational space. In this work, we describe a number of sophistications of the neural network architectures to improve and generalize the process of interleaved collective variable discovery and enhanced sampling. We employ circular network nodes to accommodate periodicities in the collective variables, hierarchical network architectures to rank-order the collective variables, and generalized encoder-decoder architectures to support bespoke error functions for network training to incorporate prior knowledge. We demonstrate our approach in blind collective variable discovery and enhanced sampling of the configurational free energy landscapes of alanine dipeptide and Trp-cage using an open-source plugin developed for the OpenMM molecular simulation package.},
author = {Wei Chen and Aik Rui Tan and Andrew L. Ferguson},
journal = {The Journal of chemical physics},
volume = {149 7},
pages = {
          072312
        },
doi = {10.1063/1.5023804},
pmid = {30134681},
}

@article{a1b36c08f6f04550f1dc48d84bb74ad3a8e0aaa5,
title = {Learning Clustered Representation for Complex Free Energy Landscapes},
year = {2019},
url = {https://www.semanticscholar.org/paper/a1b36c08f6f04550f1dc48d84bb74ad3a8e0aaa5},
abstract = {In this paper we first analyzed the inductive bias underlying the data scattered across complex free energy landscapes (FEL), and exploited it to train deep neural networks which yield reduced and clustered representation for the FEL. Our parametric method, called Information Distilling of Metastability (IDM), is end-to-end differentiable thus scalable to ultra-large dataset. IDM is also a clustering algorithm and is able to cluster the samples in the meantime of reducing the dimensions. Besides, as an unsupervised learning method, IDM differs from many existing dimensionality reduction and clustering methods in that it neither requires a cherry-picked distance metric nor the ground-true number of clusters, and that it can be used to unroll and zoom-in the hierarchical FEL with respect to different timescales. Through multiple experiments, we show that IDM can achieve physically meaningful representations which partition the FEL into well-defined metastable states hence are amenable for downstream tasks such as mechanism analysis and kinetic modeling.},
author = {Jun Zhang and Yao-Kun Lei and X. Che and Zhen Zhang and Y. I. Yang and Y. Gao},
journal = {arXiv: Statistical Mechanics},
volume = {},
pages = {null},
arxivid = {1906.02852},
}

@article{d8d8e2c04ca47bd628bd2a499e03ad7cd29633da,
title = {Time-lagged autoencoders: Deep learning of slow collective variables for molecular kinetics},
year = {2017},
url = {https://www.semanticscholar.org/paper/d8d8e2c04ca47bd628bd2a499e03ad7cd29633da},
abstract = {Inspired by the success of deep learning techniques in the physical and chemical sciences, we apply a modification of an autoencoder type deep neural network to the task of dimension reduction of molecular dynamics data. We can show that our time-lagged autoencoder reliably finds low-dimensional embeddings for high-dimensional feature spaces which capture the slow dynamics of the underlying stochastic processes-beyond the capabilities of linear dimension reduction techniques.},
author = {C. Wehmeyer and F. Noé},
journal = {The Journal of chemical physics},
volume = {148 24},
pages = {
          241703
        },
doi = {10.1063/1.5011399},
pmid = {29960344},
arxivid = {1710.11239},
}

@article{fe3850f70016ae3a31767166fb996ed0f0325fd4,
title = {Capabilities and Limitations of Time-lagged Autoencoders for Slow Mode Discovery in Dynamical Systems},
year = {2019},
url = {https://www.semanticscholar.org/paper/fe3850f70016ae3a31767166fb996ed0f0325fd4},
abstract = {Time-lagged autoencoders (TAEs) have been proposed as a deep learning regression-based approach to the discovery of slow modes in dynamical systems. However, a rigorous analysis of nonlinear TAEs remains lacking. In this work, we discuss the capabilities and limitations of TAEs through both theoretical and numerical analyses. Theoretically, we derive bounds for nonlinear TAE performance in slow mode discovery and show that in general TAEs learn a mixture of slow and maximum variance modes. Numerically, we illustrate cases where TAEs can and cannot correctly identify the leading slowest mode in two example systems: a 2D "Washington beltway" potential and the alanine dipeptide molecule in explicit water. We also compare the TAE results with those obtained using state-free reversible VAMPnets (SRVs) as a variational-based neural network approach for slow modes discovery, and show that SRVs can correctly discover slow modes where TAEs fail.},
author = {Wei Chen and Hythem Sidky and Andrew L. Ferguson},
journal = {ArXiv},
volume = {abs/1906.00325},
pages = {null},
doi = {10.1063/1.5112048},
arxivid = {1906.00325},
}

@article{2e7163e31e9b32cec11005678bae9e1dbeb6d573,
title = {Nonlinear discovery of slow molecular modes using state-free reversible VAMPnets.},
year = {2019},
url = {https://www.semanticscholar.org/paper/2e7163e31e9b32cec11005678bae9e1dbeb6d573},
abstract = {The success of enhanced sampling molecular simulations that accelerate along collective variables (CVs) is predicated on the availability of variables coincident with the slow collective motions governing the long-time conformational dynamics of a system. It is challenging to intuit these slow CVs for all but the simplest molecular systems, and their data-driven discovery directly from molecular simulation trajectories has been a central focus of the molecular simulation community to both unveil the important physical mechanisms and drive enhanced sampling. In this work, we introduce state-free reversible VAMPnets (SRV) as a deep learning architecture that learns nonlinear CV approximants to the leading slow eigenfunctions of the spectral decomposition of the transfer operator that evolves equilibrium-scaled probability distributions through time. Orthogonality of the learned CVs is naturally imposed within network training without added regularization. The CVs are inherently explicit and differentiable functions of the input coordinates making them well-suited to use in enhanced sampling calculations. We demonstrate the utility of SRVs in capturing parsimonious nonlinear representations of complex system dynamics in applications to 1D and 2D toy systems where the true eigenfunctions are exactly calculable and to molecular dynamics simulations of alanine dipeptide and the WW domain protein.},
author = {Wei Chen and Hythem Sidky and Andrew L. Ferguson},
journal = {The Journal of chemical physics},
volume = {150 21},
pages = {
          214114
        },
doi = {10.1063/1.5092521},
pmid = {31176319},
}

@article{24726572ccb2e0daea9c7a7007a431da122e9f5d,
title = {Perspective: Identification of collective variables and metastable states of protein dynamics.},
year = {2018},
url = {https://www.semanticscholar.org/paper/24726572ccb2e0daea9c7a7007a431da122e9f5d},
abstract = {The statistical analysis of molecular dynamics simulations requires dimensionality reduction techniques, which yield a low-dimensional set of collective variables (CVs) {x i } = x that in some sense describe the essential dynamics of the system. Considering the distribution P( x ) of the CVs, the primal goal of a statistical analysis is to detect the characteristic features of P( x ), in particular, its maxima and their connection paths. This is because these features characterize the low-energy regions and the energy barriers of the corresponding free energy landscape ΔG( x ) = -k B T ln P( x ), and therefore amount to the metastable states and transition regions of the system. In this perspective, we outline a systematic strategy to identify CVs and metastable states, which subsequently can be employed to construct a Langevin or a Markov state model of the dynamics. In particular, we account for the still limited sampling typically achieved by molecular dynamics simulations, which in practice seriously limits the applicability of theories (e.g., assuming ergodicity) and black-box software tools (e.g., using redundant input coordinates). We show that it is essential to use internal (rather than Cartesian) input coordinates, employ dimensionality reduction methods that avoid rescaling errors (such as principal component analysis), and perform density based (rather than k-means-type) clustering. Finally, we briefly discuss a machine learning approach to dimensionality reduction, which highlights the essential internal coordinates of a system and may reveal hidden reaction mechanisms.},
author = {F. Sittel and G. Stock},
journal = {The Journal of chemical physics},
volume = {149 15},
pages = {
          150901
        },
doi = {10.1063/1.5049637},
pmid = {30342445},
}

@article{22bd75994b94a00cf2a9697a28a805e35da30b1f,
title = {Reweighted autoencoded variational Bayes for enhanced sampling (RAVE).},
year = {2018},
url = {https://www.semanticscholar.org/paper/22bd75994b94a00cf2a9697a28a805e35da30b1f},
abstract = {Here we propose the reweighted autoencoded variational Bayes for enhanced sampling (RAVE) method, a new iterative scheme that uses the deep learning framework of variational autoencoders to enhance sampling in molecular simulations. RAVE involves iterations between molecular simulations and deep learning in order to produce an increasingly accurate probability distribution along a low-dimensional latent space that captures the key features of the molecular simulation trajectory. Using the Kullback-Leibler divergence between this latent space distribution and the distribution of various trial reaction coordinates sampled from the molecular simulation, RAVE determines an optimum, yet nonetheless physically interpretable, reaction coordinate and optimum probability distribution. Both then directly serve as the biasing protocol for a new biased simulation, which is once again fed into the deep learning module with appropriate weights accounting for the bias, the procedure continuing until estimates of desirable thermodynamic observables are converged. Unlike recent methods using deep learning for enhanced sampling purposes, RAVE stands out in that (a) it naturally produces a physically interpretable reaction coordinate, (b) is independent of existing enhanced sampling protocols to enhance the fluctuations along the latent space identified via deep learning, and (c) it provides the ability to easily filter out spurious solutions learned by the deep learning procedure. The usefulness and reliability of RAVE is demonstrated by applying it to model potentials of increasing complexity, including computation of the binding free energy profile for a hydrophobic ligand-substrate system in explicit water with dissociation time of more than 3 min, in computer time at least twenty times less than that needed for umbrella sampling or metadynamics.},
author = {João Marcelo Lamim Ribeiro and P. Bravo and Yihang Wang and P. Tiwary},
journal = {The Journal of chemical physics},
volume = {149 7},
pages = {
          072301
        },
doi = {10.1063/1.5025487},
pmid = {30134694},
arxivid = {1802.03420},
}

@article{d5afe6f56fb0b48a2e890444b23daca676f0f8b4,
title = {Deep learning for variational multiscale molecular modeling.},
year = {2020},
url = {https://www.semanticscholar.org/paper/d5afe6f56fb0b48a2e890444b23daca676f0f8b4},
abstract = {Molecular simulations are widely applied in the study of chemical and bio-physical problems. However, the accessible timescales of atomistic simulations are limited, and extracting equilibrium properties of systems containing rare events remains challenging. Two distinct strategies are usually adopted in this regard: either sticking to the atomistic level and performing enhanced sampling or trading details for speed by leveraging coarse-grained models. Although both strategies are promising, either of them, if adopted individually, exhibits severe limitations. In this paper, we propose a machine-learning approach to ally both strategies so that simulations on different scales can benefit mutually from their crosstalks: Accurate coarse-grained (CG) models can be inferred from the fine-grained (FG) simulations through deep generative learning; in turn, FG simulations can be boosted by the guidance of CG models via deep reinforcement learning. Our method defines a variational and adaptive training objective, which allows end-to-end training of parametric molecular models using deep neural networks. Through multiple experiments, we show that our method is efficient and flexible and performs well on challenging chemical and bio-molecular systems.},
author = {Jun Zhang and Yao-Kun Lei and Y. I. Yang and Y. Gao},
journal = {The Journal of chemical physics},
volume = {153 17},
pages = {
          174115
        },
doi = {10.26434/chemrxiv.9640814.v4},
pmid = {33167648},
}

@article{5087c51a1b9cc71f37608c7d47f1d49ef19d756b,
title = {EncoderMap(II): Visualizing Important Molecular Motions with Improved Generation of Protein Conformations},
year = {2019},
url = {https://www.semanticscholar.org/paper/5087c51a1b9cc71f37608c7d47f1d49ef19d756b},
abstract = {Dimensionality reduction can be used to project high-dimensional molecular data into a simplified, low-dimensional map. One feature of our recently introduced dimensionality reduction technique EncoderMap, which relies on the combination of an autoencoder with multidimensional scaling, is its ability to do the reverse. It is able to generate conformations for any selected points in the low-dimensional map. This transfers the simplified, low-dimensional map back into the high-dimensional conformational space. Although the output is again high-dimensional, certain aspects of the simplification are preserved. The generated conformations only mirror the most dominant conformational differences that determine the positions of conformational states in the low-dimensional map. This allows to depict such differences and - in consequence - visualize molecular motions and gives a unique perspective on high-dimensional conformational data. In our previous work protein conformations described in backbone dihedral angle space were used as input for EncoderMap, and conformations were also generated in this space. For large proteins, however, the generation of conformations is inaccurate with this approach due to the local character of backbone dihedral angles. Here, we present an improved variant of EncoderMap which is able to generate large protein conformations that are accurate in short-range and long-range order. This is achieved by differentiable reconstruction of Cartesian coordinates from the generated dihedrals, which allows to add a contribution to the cost function that monitors the accuracy of all pairwise distances between the C α -atoms of the generated conformations. The improved capabilities to generate conformations of large, even multidomain, proteins are demonstrated for two examples: diubiquitin and a part of the Ssa1 Hsp70 yeast chaperone. We show that the improved variant of EncoderMap can nicely visualize motions of protein domains relative to each other but is also able to highlight important conformational changes within the individual domains.},
author = {Tobias Lemke and Andrej Berg and Alok Jain and C. Peter},
journal = {Journal of chemical information and modeling},
volume = {null},
pages = {null},
doi = {10.1021/acs.jcim.9b00675},
pmid = {31647645},
}

@article{3999faeea4b6fc58615245072ce010a0e6f641ea,
title = {Systematic control of collective variables learned from variational autoencoders.},
year = {2022},
url = {https://www.semanticscholar.org/paper/3999faeea4b6fc58615245072ce010a0e6f641ea},
abstract = {Variational autoencoders (VAEs) are rapidly gaining popularity within molecular simulation for discovering low-dimensional, or latent, representations, which are critical for both analyzing and accelerating simulations. However, it remains unclear how the information a VAE learns is connected to its probabilistic structure and, in turn, its loss function. Previous studies have focused on feature engineering, ad hoc modifications to loss functions, or adjustment of the prior to enforce desirable latent space properties. By applying effectively arbitrarily flexible priors via normalizing flows, we focus instead on how adjusting the structure of the decoding model impacts the learned latent coordinate. We systematically adjust the power and flexibility of the decoding distribution, observing that this has a significant impact on the structure of the latent space as measured by a suite of metrics developed in this work. By also varying weights on separate terms within each VAE loss function, we show that the level of detail encoded can be further tuned. This provides practical guidance for utilizing VAEs to extract varying resolutions of low-dimensional information from molecular dynamics and Monte Carlo simulations.},
author = {Jacob I. Monroe and V. K. Shen},
journal = {The Journal of chemical physics},
volume = {157 9},
pages = {
          094116
        },
doi = {10.1063/5.0105120},
pmid = {36075702},
}

@article{508e2861bd2927fb925967193db482e9e51b8121,
title = {Dynamical coring of Markov state models.},
year = {2019},
url = {https://www.semanticscholar.org/paper/508e2861bd2927fb925967193db482e9e51b8121},
abstract = {The accurate definition of suitable metastable conformational states is fundamental for the construction of a Markov state model describing biomolecular dynamics. Following the dimensionality reduction in a molecular dynamics trajectory, these microstates can be generated by a recently proposed density-based geometrical clustering algorithm [F. Sittel and G. Stock, J. Chem. Theory Comput. 12, 2426 (2016)], which by design cuts the resulting clusters at the energy barriers and allows for a data-based identification of all parameters. Nevertheless, projection artifacts due to the inevitable restriction to a low-dimensional space combined with insufficient sampling often leads to a misclassification of sampled points in the transition regions. This typically causes intrastate fluctuations to be mistaken as interstate transitions, which leads to artificially short life times of the metastable states. As a simple but effective remedy, dynamical coring requires that the trajectory spends a minimum time in the new state for the transition to be counted. Adopting molecular dynamics simulations of two well-established biomolecular systems (alanine dipeptide and villin headpiece), dynamical coring is shown to considerably improve the Markovianity of the resulting metastable states, which is demonstrated by Chapman-Kolmogorov tests and increased implied time scales of the Markov model. Providing high structural and temporal resolution, the combination of density-based clustering and dynamical coring is particularly suited to describe the complex structural dynamics of unfolded biomolecules.},
author = {Daniel Nagel and Anna Weber and Benjamin Lickert and G. Stock},
journal = {The Journal of chemical physics},
volume = {150 9},
pages = {
          094111
        },
doi = {10.1063/1.5081767},
pmid = {30849879},
}

@article{e8e246fbdec462fba08c2425c018bdf0bf5298ab,
title = {EncoderMap: Dimensionality Reduction and Generation of Molecule Conformations.},
year = {2019},
url = {https://www.semanticscholar.org/paper/e8e246fbdec462fba08c2425c018bdf0bf5298ab},
abstract = {Molecular simulation is one example where large amounts of high-dimensional (high-d) data are generated. To extract useful information, e.g., about relevant states and important conformational transitions, a form of dimensionality reduction is required. Dimensionality reduction algorithms differ in their ability to efficiently project large amounts of data to an informative low-dimensional (low-d) representation and the way the low and high-d representations are linked. We propose a dimensionality reduction algorithm called EncoderMap that is based on a neural network autoencoder in combination with a nonlinear distance metric. A key advantage of this method is that it establishes a functional link from the high-d to the low-d representation and vice versa. This allows us not only to efficiently project data points to the low-d representation but also to generate high-d representatives for any point in the low-d map. The potential of the algorithm is demonstrated for molecular simulation data of a small, highly flexible peptide as well as for folding simulations of the 20-residue Trp-cage protein. We demonstrate that the algorithm is able to efficiently project the ensemble of high-d structures to a low-d map where major states can be identified and important conformational transitions are revealed. We also show that molecular conformations can be generated for any point or any connecting line between points on the low-d map. This ability of inverse mapping from the low-d to the high-d representation is particularly relevant for the use in algorithms that enhance the exploration of conformational space or the sampling of transitions between conformational states.},
author = {Tobias Lemke and C. Peter},
journal = {Journal of chemical theory and computation},
volume = {15 2},
pages = {
          1209-1215
        },
doi = {10.1021/acs.jctc.8b00975},
pmid = {30632745},
}

@article{22ed924c0d91c12e28d36322ecc26bbf2394fb03,
title = {The role of conformational entropy in the determination of structural-kinetic relationships for helix-coil transitions},
year = {2017},
url = {https://www.semanticscholar.org/paper/22ed924c0d91c12e28d36322ecc26bbf2394fb03},
abstract = {Coarse-grained molecular simulation models can provide significant insight into the complex behavior of protein systems, but suffer from an inherently distorted description of dynamical properties. This limitation prevents these models from providing consistent structural interpretations for kinetic experiments. We recently demonstrated (Rudzinski, Bereau, bioRχiv, 2017, https://doi.org/10.1101/183053) that, for a heptapeptide of alanine residues, the structural and kinetic properties of a simulation model are linked in a rather simple way, given a certain level of physics present in the model. In this work, we extend these findings to a longer peptide, for which the representation of configuration space in terms of a full enumeration of sequences of helical/coil states along the peptide backbone is impractical. Similar to our previous work, we verify the structural-kinetic relationships by scanning the parameter space of a simple native-biased model and then employ a distinct transferable model to validate and generalize the conclusions. Our results further demonstrate the validity of the previous findings, while clarifying the role of conformational entropy in the determination of the structural-kinetic relationships. More specifically, while the kinetic properties of a particular class of models with varying energetic parameters but approximately fixed conformational entropy are determined by the average helical content, a shift in the kinetic observables occurs for models with a distinct representation of steric interactions. The conclusions suggest an approach for ensuring kinetic consistency of coarse-grained simulation models.},
author = {J. F. Rudzinski and T. Bereau},
journal = {bioRxiv},
volume = {null},
pages = {null},
doi = {10.1101/237875},
}

@article{f954c3e5262104a383fc64adcb57fb800d7ac221,
title = {Deep Representation Learning for Complex Free Energy Landscapes.},
year = {2019},
url = {https://www.semanticscholar.org/paper/f954c3e5262104a383fc64adcb57fb800d7ac221},
abstract = {In this letter, we analyzed the inductive bias underlying complex free energy landscapes (FEL), and exploited it to train deep neural networks which yield reduced and clustered representation for the FEL. Our parametric method, called Information Distilling of Metastability (IDM), is end-to-end differentiable thus scalable to ultra-large dataset. IDM is able to perform clustering in the meantime of reducing the dimensions. Besides, as an unsupervised learning method, IDM differs from many existing dimensionality reduction and clustering methods in that it neither requires a cherry-picked distance metric nor the ground-true number of clusters defined a priori, and that it can be used to unroll and zoom-in the hierarchical FEL with respect to different timescales. Through multiple experiments, we show that IDM can achieve physically meaningful representations which partition the FEL into well-defined metastable states hence are amenable for downstream tasks such as mechanism analysis and kinetic modeling.},
author = {Jun Zhang and Yao-Kun Lei and X. Che and Zhen Zhang and Y. I. Yang and Y. Gao},
journal = {The journal of physical chemistry letters},
volume = {null},
pages = {null},
doi = {10.1021/acs.jpclett.9b02012},
pmid = {31476868},
}

@article{3d50464ec004730c9bb79f461b1eccf124d42e6d,
title = {Toward Achieving Efficient and Accurate Ligand-Protein Unbinding with Deep Learning and Molecular Dynamics through RAVE.},
year = {2018},
url = {https://www.semanticscholar.org/paper/3d50464ec004730c9bb79f461b1eccf124d42e6d},
abstract = {In this work, we demonstrate how to leverage our recent iterative deep learning-all atom molecular dynamics (MD) technique "Reweighted autoencoded variational Bayes for enhanced sampling (RAVE)" (Ribeiro, Bravo, Wang, Tiwary, J. Chem. Phys. 2018, 149, 072301) for investigating ligand-protein unbinding mechanisms and calculating absolute binding free energies, Δ Gb, when plagued with difficult to sample rare events. In order to do so, we introduce a simple but powerful extension to RAVE that allows learning a reaction coordinate expressed as a piecewise function that is linear over all intervals. Such an approach allows us to retain the physical interpretation of a RAVE-derived reaction coordinate while making the method more applicable to a wider range of complex biophysical problems. As we will demonstrate, using as our test-case the slow dissociation of benzene from the L99A variant of lysozyme, the RAVE extension led to observing an unbinding event in 100% of the independent all-atom MD simulations, all within 3-50 ns for a process that takes on an average close to few hundred milliseconds, which reflects a 7 orders of magnitude acceleration relative to straightforward MD. Furthermore, we will show that without the use of time-dependent biasing, clear back-and-forth movement between metastable intermediates was achieved during the various simulations, demonstrating the caliber of the RAVE-derived piecewise reaction coordinate and bias potential, which together drive efficient and accurate sampling of the ligand-protein dissociation event. Last, we report the results for Δ Gb, which via very short MD simulations, can form a strict lower-bound that is ∼2-3 kcal/mol off from experiments. We believe that RAVE, together with its multidimensional extension that we introduce here, will be a useful tool for simulating the slow unbinding process of practical ligand-protein complexes in an automated manner with minimal use of human intuition.},
author = {João Marcelo Lamim Ribeiro and P. Tiwary},
journal = {Journal of chemical theory and computation},
volume = {15 1},
pages = {
          708-719
        },
doi = {10.1021/acs.jctc.8b00869},
pmid = {30525598},
}

@article{14fa614cc60fb42d3ff220ae129a26f58eb1be7a,
title = {Extensible and Scalable Adaptive Sampling on Supercomputers.},
year = {2019},
url = {https://www.semanticscholar.org/paper/14fa614cc60fb42d3ff220ae129a26f58eb1be7a},
abstract = {The accurate sampling of protein dynamics is an ongoing challenge despite the utilization of high-performance computer (HPC) systems. Utilizing only "brute force" molecular dynamics (MD) simulations requires an unacceptably long time to solution. Adaptive sampling methods allow a more effective sampling of protein dynamics than standard MD simulations. Depending on the restarting strategy, the speed up can be more than 1 order of magnitude. One challenge limiting the utilization of adaptive sampling by domain experts is the relatively high complexity of efficiently running adaptive sampling on HPC systems. We discuss how the ExTASY framework can set up new adaptive sampling strategies and reliably execute resulting workflows at scale on HPC platforms. Here, the folding dynamics of four proteins are predicted with no a priori information.},
author = {Eugen Hruska and Vivek Balasubramanian and Hyungro Lee and S. Jha and C. Clementi},
journal = {Journal of chemical theory and computation},
volume = {null},
pages = {null},
doi = {10.1021/acs.jctc.0c00991},
pmid = {33170696},
arxivid = {1907.06954},
}

@article{55c81b9b31c93af629c853df42fe83cf036d0ff4,
title = {Automatic mutual information noise omission (AMINO): generating order parameters for molecular systems},
year = {2019},
url = {https://www.semanticscholar.org/paper/55c81b9b31c93af629c853df42fe83cf036d0ff4},
abstract = {Molecular dynamics (MD) simulations generate valuable all-atom resolution trajectories of complex systems, but analyzing this high-dimensional data as well as reaching practical timescales even with powerful super-computers remain open problems. As such, many specialized sampling and reaction coordinate construction methods exist that alleviate these problems. However, these methods typically don’t work directly on all atomic coordinates, and still require previous knowledge of the important distinguishing features of the system, known as order parameters (OPs). Here we present AMINO, an automated method that generates such OPs by screening through a very large dictionary of OPs, such as all heavy atom contacts in a biomolecule. AMINO uses ideas from information theory and rate distortion theory. The OPs learnt from AMINO can then serve as an input for designing a reaction coordinate which can then be used in many enhanced sampling methods. Here we outline its key theoretical underpinnings, and apply it to systems of increasing complexity. Our applications include a problem of tremendous pharmaceutical and engineering relevance, namely, calculating the binding affinity of a protein-ligand system when all that is known is the structure of the bound system. Our calculations are performed in a human-free fashion, obtaining very accurate results compared to long unbiased MD simulations on the Anton supercomputer, but in orders of magnitude less computer time. We thus expect AMINO to be useful for the calculation of thermodynamics and kinetics in the study of diverse molecular systems.},
author = {P. Ravindra and Zachary Smith and P. Tiwary},
journal = {bioRxiv},
volume = {null},
pages = {null},
doi = {10.1101/745968},
}

@article{538d0f3f70c90dfd8d9f6e7bba3f50ea4058c34c,
title = {High-Resolution Markov State Models for the Dynamics of Trp-Cage Miniprotein Constructed over Slow Folding Modes Identified by State-Free Reversible VAMPnets.},
year = {2019},
url = {https://www.semanticscholar.org/paper/538d0f3f70c90dfd8d9f6e7bba3f50ea4058c34c},
abstract = {State-free reversible VAMPnets (SRVs) are a neural network-based framework capable of learning the leading eigenfunctions of the transfer operator of a dynamical system from trajectory data. In molecular dynamics simulations, these data-driven collective variables (CVs) capture the slowest modes of the dynamics and are useful for enhanced sampling and free energy estimation. In this work, we employ SRV coordinates as a feature set for Markov state model (MSM) construction. Compared to the current state of the art, MSMs constructed from SRV coordinates are more robust to the choice of input features, exhibit faster implied timescale convergence, and permit the use of shorter lagtimes to construct higher kinetic resolution models. We apply this methodology to study the folding kinetics and conformational landscape of the Trp-cage miniprotein. Folding and unfolding mean first passage times are in good agreement with prior literature, and a nine macrostate model is presented. The unfolded ensemble comprises a central kinetic hub with interconversions to several metastable unfolded conformations and which serves as the gateway to the folded ensemble. The folded ensemble comprises the native state, a partially unfolded intermediate "loop" state, and a previously unreported short-lived intermediate that we were able to resolve due to the high time-resolution of the SRV-MSM. We propose SRVs as an excellent candidate for integration into modern MSM construction pipelines.},
author = {Hythem Sidky and Wei Chen and Andrew L. Ferguson},
journal = {The journal of physical chemistry. B},
volume = {null},
pages = {null},
doi = {10.1021/acs.jpcb.9b05578},
pmid = {31453697},
arxivid = {1906.04890},
}

@article{33342505de83960be734548d911c0ae9543a467f,
title = {Investigating the Conformational Ensembles of Intrinsically Disordered Proteins with a Simple Physics-Based Model},
year = {2020},
url = {https://www.semanticscholar.org/paper/33342505de83960be734548d911c0ae9543a467f},
abstract = {Intrinsically disordered proteins (IDPs) play an important role in an array of biological processes but present a number of fundamental challenges for computational modeling. Recently, simple polymer models have re-gained popularity for interpreting the experimental characterization of IDPs. Homopolymer theory provides a strong foundation for understanding generic features of phenomena ranging from single-chain conformational dynamics to the properties of entangled polymer melts, but is difficult to extend to the copolymer context. This challenge is magnified for proteins due to the variety of competing interactions and large deviations in side-chain properties. In this work, we apply a simple physics-based coarse-grained model for describing largely disordered conformational ensembles of peptides, based on the premise that sampling sterically-forbidden conformations can compromise the faithful description of both static and dynamical properties. The Hamiltonian of the employed model can be easily adjusted to investigate the impact of distinct interactions and sequence specificity on the randomness of the resulting conformational ensemble. In particular, starting with a bead-spring-like model and then adding more detailed interactions one by one, we construct a hierarchical set of models and perform a detailed comparison of their properties. Our analysis clarifies the role of generic attractions, electrostatics and side-chain sterics, while providing a foundation for developing efficient models for IDPs that retain an accurate description of the hierarchy of conformational dynamics, which is nontrivially influenced by interactions with surrounding proteins and solvent molecules.},
author = {Yani Zhao and R. Cortes-Huerto and K. Kremer and J. F. Rudzinski},
journal = {The Journal of Physical Chemistry. B},
volume = {124},
pages = {4097 - 4113},
doi = {10.1101/2020.02.11.943969},
pmid = {32345021},
}

@article{d8a1e7f0fcdead153d06f7f376da42b7be8fa98f,
title = {Structural-kinetic-thermodynamic relationships identified from physics-based molecular simulation models.},
year = {2018},
url = {https://www.semanticscholar.org/paper/d8a1e7f0fcdead153d06f7f376da42b7be8fa98f},
abstract = {Coarse-grained molecular simulation models have provided immense, often general, insight into the complex behavior of condensed-phase systems but suffer from a lost connection to the true dynamical properties of the underlying system. In general, the physics that is built into a model shapes the free-energy landscape, restricting the attainable static and kinetic properties. In this work, we perform a detailed investigation into the property interrelationships resulting from these restrictions, for a representative system of the helix-coil transition. Inspired by high-throughput studies, we systematically vary force-field parameters and monitor their structural, kinetic, and thermodynamic properties. The focus of our investigation is a simple coarse-grained model, which accurately represents the underlying structural ensemble, i.e., effectively avoids sterically-forbidden configurations. As a result of this built-in physics, we observe a rather large restriction in the topology of the networks characterizing the simulation kinetics. When screening across force-field parameters, we find that structurally accurate models also best reproduce the kinetics, suggesting structural-kinetic relationships for these models. Additionally, an investigation into thermodynamic properties reveals a link between the cooperativity of the transition and the network topology at a single reference temperature.},
author = {J. F. Rudzinski and T. Bereau},
journal = {The Journal of chemical physics},
volume = {148 20},
pages = {
          204111
        },
doi = {10.1063/1.5025125},
pmid = {29865838},
}

@article{4275490b2442d0f4bfd56ec5f494e8c81543c0bb,
title = {Past–future information bottleneck framework for simultaneously sampling biomolecular reaction coordinate, thermodynamics and kinetics},
year = {2018},
url = {https://www.semanticscholar.org/paper/4275490b2442d0f4bfd56ec5f494e8c81543c0bb},
abstract = {The ability to rapidly learn from high-dimensional data to make reliable bets about the future outcomes is crucial in many contexts. This could be a fly avoiding predators, or the retina processing gigabytes of data almost instantaneously to guide complex human actions. In this work we draw parallels between such tasks, and the efficient sampling of complex biomolecules with hundreds of thousands of atoms. For this we use the Predictive Information Bottleneck (PIB) framework developed and used for the first two classes of problems, and re-formulate it for the sampling of biomolecular structure and dynamics, especially when plagued with rare events. Our method considers a given biomolecular trajectory expressed in terms of order parameters or basis functions, and uses a deep neural network to learn the minimally complex yet most predictive aspects of this trajectory, viz the PIB. This information is used to perform iterative rounds of biased simulations that enhance the sampling along the PIB to gradually improve its accuracy, directly obtaining associated thermodynamic and kinetic information. We demonstrate the method on two test-pieces, including benzene dissociation from the protein lysozyme, where we calculate the dissociation pathway and timescales slower than milliseconds. Finally, by performing an analysis of residues contributing to the PIB, we predict the critical mutations in the system which would be most impactful on the stability of the crucial but ephemeral transition state. We believe this work marks a big step forward in the use of predictive artificial intelligence ideas for the sampling of biomolecules.},
author = {Yihang Wang and João Marcelo Lamim Ribeiro and P. Tiwary},
journal = {bioRxiv},
volume = {null},
pages = {null},
doi = {10.1101/507822},
}

@article{6bb5eeb7728656d61987b98aceb9cc4579a6f705,
title = {A deep autoencoder framework for discovery of metastable ensembles in biomacromolecules.},
year = {2021},
url = {https://www.semanticscholar.org/paper/6bb5eeb7728656d61987b98aceb9cc4579a6f705},
abstract = {Biomacromolecules manifest dynamic conformational fluctuation and involve mutual interconversion among metastable states. A robust mapping of their conformational landscape often requires the low-dimensional projection of the conformational ensemble along optimized collective variables (CVs). However, the traditional choice for the CV is often limited by user-intuition and prior knowledge about the system, and this lacks a rigorous assessment of their optimality over other candidate CVs. To address this issue, we propose an approach in which we first choose the possible combinations of inter-residue Cα-distances within a given macromolecule as a set of input CVs. Subsequently, we derive a non-linear combination of latent space embedded CVs via auto-encoding the unbiased molecular dynamics simulation trajectories within the framework of the feed-forward neural network. We demonstrate the ability of the derived latent space variables in elucidating the conformational landscape in four hierarchically complex systems. The latent space CVs identify key metastable states of a bead-in-a-spring polymer. The combination of the adopted dimensional reduction technique with a Markov state model, built on the derived latent space, reveals multiple spatially and kinetically well-resolved metastable conformations for GB1 β-hairpin. A quantitative comparison based on the variational approach-based scoring of the auto-encoder-derived latent space CVs with the ones obtained via independent component analysis (principal component analysis or time-structured independent component analysis) confirms the optimality of the former. As a practical application, the auto-encoder-derived CVs were found to predict the reinforced folding of a Trp-cage mini-protein in aqueous osmolyte solution. Finally, the protocol was able to decipher the conformational heterogeneities involved in a complex metalloenzyme, namely, cytochrome P450.},
author = {Satyabrata Bandyopadhyay and J. Mondal},
journal = {The Journal of chemical physics},
volume = {155 11},
pages = {
          114106
        },
doi = {10.1063/5.0059965},
pmid = {34551528},
arxivid = {2106.00724},
}

@article{bd8c74f9c67ec07605eac970928782d5cb47b8b3,
title = {Learning Efficient, Collective Monte Carlo Moves with Variational Autoencoders.},
year = {2022},
url = {https://www.semanticscholar.org/paper/bd8c74f9c67ec07605eac970928782d5cb47b8b3},
abstract = {Discovering meaningful collective variables for enhancing sampling, via applied biasing potentials or tailored MC move sets, remains a major challenge within molecular simulation. While recent studies identifying collective variables with variational autoencoders (VAEs) have focused on the encoding and latent space discovered by a VAE, the impact of the decoding and its ability to act as a generative model remains unexplored. We demonstrate how VAEs may be used to learn (on-the-fly and with minimal human intervention) highly efficient, collective Monte Carlo moves that accelerate sampling along the learned collective variable. In contrast to many machine learning-based efforts to bias sampling and generate novel configurations, our methods result in exact sampling in the ensemble of interest and do not require reweighting. In fact, we show that the acceptance rates of our moves approach unity for a perfect VAE model. While this is never observed in practice, VAE-based Monte Carlo moves still enhance sampling of new configurations. We demonstrate, however, that the form of the encoding and decoding distributions, in particular the extent to which the decoder reflects the underlying physics, greatly impacts the performance of the trained VAE.},
author = {Jacob I. Monroe and V. K. Shen},
journal = {Journal of chemical theory and computation},
volume = {null},
pages = {null},
doi = {10.1021/acs.jctc.2c00110},
pmid = {35613327},
}

@article{5accc7bc13a4eab720f72eb99e2fb2a47e5a22eb,
title = {Structural-Kinetic-Thermodynamic Relationships for Peptide Secondary Structure Formation Identified from Transition Network Properties},
year = {2017},
url = {https://www.semanticscholar.org/paper/5accc7bc13a4eab720f72eb99e2fb2a47e5a22eb},
abstract = {Molecular simulation models have provided immense, often general, insight into the complex behavior of protein systems. Even for very detailed, e.g., atomistic, models, the generation of quantitatively accurate dynamical properties remains a formidable challenge. This lack of consistent dynamics largely hinders simulation models, especially coarse-grained models, from providing structural interpretations for kinetic experiments. In this work, we perform a detailed investigation into the kinetic properties generated by molecular simulation models for a representative system of the helix-coil transition. Inspired by high-throughput studies that aim to uncover structure-property relationships, we systematically vary force-field parameters and monitor their structural, kinetic, and thermodynamic properties. The focus of our investigation is a simple, nativebiased coarse-grained model, which accurately represents the underlying structural ensemble by employing near-atomistic steric and intramolecular backbone interactions. From each set of simulations, we construct a Markov state model to efficiently and systematically assess the system’s kinetic properties. We observe a rather large restriction in the topology of the resulting kinetic networks, apparently due to the detailed description of the peptide backbone. When screening across force-field parameters, we find that structurally-accurate models, with respect to a higher-resolution reference, also best reproduce the kinetics. This connection suggests structural-kinetic relationships for these models—accurate structural features guarantee consistent kinetics. A comparative study against distinct higher-resolution models highlights the generality of our conclusions. These remarkable relationships hinge upon the physics of the model, which shapes the free-energy landscape and restricts the attainable kinetic properties. While structural features determine the kinetics at a single temperature, the temperature dependence of the structure determines the thermodynamics, i.e., cooperativity, of the transition. Interestingly, a topological metric of the kinetic networks characterizing the degree of randomness of pathways traveling between the helix and coil states at a single reference temperature dictates the relative cooperativity of the resulting transition.},
author = {J. F. Rudzinski and T. Bereau},
journal = {bioRxiv},
volume = {null},
pages = {null},
doi = {10.1101/183053},
}

@article{c86006be8cd1c5ee6193ee31cf31d44449b9c082,
title = {Molecular enhanced sampling with autoencoders: On‐the‐fly collective variable discovery and accelerated free energy landscape exploration},
year = {2017},
url = {https://www.semanticscholar.org/paper/c86006be8cd1c5ee6193ee31cf31d44449b9c082},
abstract = {Macromolecular and biomolecular folding landscapes typically contain high free energy barriers that impede efficient sampling of configurational space by standard molecular dynamics simulation. Biased sampling can artificially drive the simulation along prespecified collective variables (CVs), but success depends critically on the availability of good CVs associated with the important collective dynamical motions. Nonlinear machine learning techniques can identify such CVs but typically do not furnish an explicit relationship with the atomic coordinates necessary to perform biased sampling. In this work, we employ auto‐associative artificial neural networks (“autoencoders”) to learn nonlinear CVs that are explicit and differentiable functions of the atomic coordinates. Our approach offers substantial speedups in exploration of configurational space, and is distinguished from existing approaches by its capacity to simultaneously discover and directly accelerate along data‐driven CVs. We demonstrate the approach in simulations of alanine dipeptide and Trp‐cage, and have developed an open‐source and freely available implementation within OpenMM. © 2018 Wiley Periodicals, Inc.},
author = {Wei Chen and Andrew L. Ferguson},
journal = {Journal of Computational Chemistry},
volume = {39},
pages = {2079 - 2102},
doi = {10.1002/jcc.25520},
pmid = {30368832},
arxivid = {1801.00203},
}

@article{88a277bbc18ad0eed29ea02bef0219b1c1a111ab,
title = {Variational encoding of complex dynamics.},
year = {2017},
url = {https://www.semanticscholar.org/paper/88a277bbc18ad0eed29ea02bef0219b1c1a111ab},
abstract = {Often the analysis of time-dependent chemical and biophysical systems produces high-dimensional time-series data for which it can be difficult to interpret which individual features are most salient. While recent work from our group and others has demonstrated the utility of time-lagged covariate models to study such systems, linearity assumptions can limit the compression of inherently nonlinear dynamics into just a few characteristic components. Recent work in the field of deep learning has led to the development of the variational autoencoder (VAE), which is able to compress complex datasets into simpler manifolds. We present the use of a time-lagged VAE, or variational dynamics encoder (VDE), to reduce complex, nonlinear processes to a single embedding with high fidelity to the underlying dynamics. We demonstrate how the VDE is able to capture nontrivial dynamics in a variety of examples, including Brownian dynamics and atomistic protein folding. Additionally, we demonstrate a method for analyzing the VDE model, inspired by saliency mapping, to determine what features are selected by the VDE model to describe dynamics. The VDE presents an important step in applying techniques from deep learning to more accurately model and interpret complex biophysics.},
author = {Carlos X. Hernández and H. Wayment-Steele and Mohammad M. Sultan and B. Husic and V. Pande},
journal = {Physical review. E},
volume = {97 6-1},
pages = {
          062412
        },
doi = {10.1103/PhysRevE.97.062412},
pmid = {30011547},
arxivid = {1711.08576},
}

@article{a43d083d9414c106f23b5ed0c40177a086b42799,
title = {Chasing Collective Variables using Autoencoders and biased trajectories},
year = {2021},
url = {https://www.semanticscholar.org/paper/a43d083d9414c106f23b5ed0c40177a086b42799},
abstract = {Free energy biasing methods have proven to be powerful tools to accelerate the simulation of important conformational changes of molecules by modifying the sampling measure. However, most of these methods rely on the prior knowledge of low-dimensional slow degrees of freedom, i.e., collective variables (CVs). Alternatively, such CVs can be identified using machine learning (ML) and dimensionality reduction algorithms. In this context, approaches where the CVs are learned in an iterative way using adaptive biasing have been proposed: at each iteration, the learned CV is used to perform free energy adaptive biasing to generate new data and learn a new CV. In this paper, we introduce a new iterative method involving CV learning with autoencoders: Free Energy Biasing and Iterative Learning with AutoEncoders (FEBILAE). Our method includes a reweighting scheme to ensure that the learning model optimizes the same loss at each iteration and achieves CV convergence. Using the alanine dipeptide system and the solvated chignolin mini-protein system as examples, we present results of our algorithm using the extended adaptive biasing force as the free energy adaptive biasing method.},
author = {Zineb Belkacemi and P. Gkeka and T. Lelièvre and G. Stoltz},
journal = {Journal of chemical theory and computation},
volume = {null},
pages = {null},
doi = {10.1021/acs.jctc.1c00415},
pmid = {34965117},
arxivid = {2104.11061},
}

@article{d3d51ccff69b92a784a2e234d39f1f2c950bf1e1,
title = {Machine learning approaches for analyzing and enhancing molecular dynamics simulations.},
year = {2019},
url = {https://www.semanticscholar.org/paper/d3d51ccff69b92a784a2e234d39f1f2c950bf1e1},
abstract = {S2 TL;DR: A summary of machine learning based ideas that are solving both of these limitations of molecular dynamics, with a focus on their key theoretical underpinnings and remaining challenges.},
author = {Yihang Wang and João Marcelo Lamim Ribeiro and P. Tiwary},
journal = {Current opinion in structural biology},
volume = {61},
pages = {
          139-145
        },
doi = {10.1016/j.sbi.2019.12.016},
pmid = {31972477},
arxivid = {1909.11748},
}

@article{4244b9b2515e37a20b254fa8f9ed7305f2f64d7e,
title = {Interpretable embeddings from molecular simulations using Gaussian mixture variational autoencoders},
year = {2019},
url = {https://www.semanticscholar.org/paper/4244b9b2515e37a20b254fa8f9ed7305f2f64d7e},
abstract = {Extracting insight from the enormous quantity of data generated from molecular simulations requires the identification of a small number of collective variables whose corresponding low-dimensional free-energy landscape retains the essential features of the underlying system. Data-driven techniques provide a systematic route to constructing this landscape, without the need for extensive a priori intuition into the relevant driving forces. In particular, autoencoders are powerful tools for dimensionality reduction, as they naturally force an information bottleneck and, thereby, a low-dimensional embedding of the essential features. While variational autoencoders ensure continuity of the embedding by assuming a unimodal Gaussian prior, this is at odds with the multi-basin free-energy landscapes that typically arise from the identification of meaningful collective variables. In this work, we incorporate this physical intuition into the prior by employing a Gaussian mixture variational autoencoder (GMVAE), which encourages the separation of metastable states within the embedding. The GMVAE performs dimensionality reduction and clustering within a single unified framework, and is capable of identifying the inherent dimensionality of the input data, in terms of the number of Gaussians required to categorize the data. We illustrate our approach on two toy models, alanine dipeptide, and a challenging disordered peptide ensemble, demonstrating the enhanced clustering effect of the GMVAE prior compared to standard VAEs. The resulting embeddings appear to be promising representations for constructing Markov state models, highlighting the transferability of the dimensionality reduction from static equilibrium properties to dynamics.},
author = {Yasemin Bozkurt Varolgunes and T. Bereau and J. F. Rudzinski},
journal = {Machine Learning: Science and Technology},
volume = {1},
pages = {null},
doi = {10.1088/2632-2153/ab80b7},
arxivid = {1912.12175},
}

@article{b77c306077e3f4b5bb6620fabee5cd8358df077d,
title = {Neural networks-based variationally enhanced sampling},
year = {2019},
url = {https://www.semanticscholar.org/paper/b77c306077e3f4b5bb6620fabee5cd8358df077d},
abstract = {Significance Atomistic-based simulations are one of the most widely used tools in contemporary science. However, in the presence of kinetic bottlenecks, their power is severely curtailed. In order to mitigate this problem, many enhanced sampling techniques have been proposed. Here, we show that by combining a variational approach with deep learning, much progress can be made in extending the scope of such simulations. Our development bridges the fields of enhanced sampling and machine learning and allows us to benefit from the rapidly growing advances in this area. Sampling complex free-energy surfaces is one of the main challenges of modern atomistic simulation methods. The presence of kinetic bottlenecks in such surfaces often renders a direct approach useless. A popular strategy is to identify a small number of key collective variables and to introduce a bias potential that is able to favor their fluctuations in order to accelerate sampling. Here, we propose to use machine-learning techniques in conjunction with the recent variationally enhanced sampling method [O. Valsson, M. Parrinello, Phys. Rev. Lett. 113, 090601 (2014)] in order to determine such potential. This is achieved by expressing the bias as a neural network. The parameters are determined in a variational learning scheme aimed at minimizing an appropriate functional. This required the development of a more efficient minimization technique. The expressivity of neural networks allows representing rapidly varying free-energy surfaces, removes boundary effects artifacts, and allows several collective variables to be handled.},
author = {L. Bonati and Yue-Yu Zhang and M. Parrinello},
journal = {Proceedings of the National Academy of Sciences},
volume = {116},
pages = {17641 - 17647},
doi = {10.1073/pnas.1907975116},
pmid = {31416918},
arxivid = {1904.01305},
}

@article{58912e2c2aaa77d1448d51e9d9460e06a5b924b9,
title = {VAMPnets for deep learning of molecular kinetics},
year = {2017},
url = {https://www.semanticscholar.org/paper/58912e2c2aaa77d1448d51e9d9460e06a5b924b9},
abstract = {S2 TL;DR: A deep learning framework that automates construction of Markov state models from MD simulation data is introduced that performs equally or better than state-of-the-art Markov modeling methods and provides easily interpretable few-state kinetic models.},
author = {Andreas Mardt and Luca Pasquali and Hao Wu and F. Noé},
journal = {Nature Communications},
volume = {9},
pages = {null},
doi = {10.1038/s41467-017-02388-1},
pmid = {29295994},
arxivid = {1710.06012},
}

@article{02355c3258110f390ecc7c36d460da5a1d113282,
title = {Machine learning force fields and coarse-grained variables in molecular dynamics: application to materials and biological systems.},
year = {2020},
url = {https://www.semanticscholar.org/paper/02355c3258110f390ecc7c36d460da5a1d113282},
abstract = {Machine learning encompasses a set of tools and algorithms which are now becoming popular in almost all scientific and technological fields. This is true for molecular dynamics as well, where machine learning offers promises of extracting valuable information from the enormous amounts of data generated by simulation of complex systems. We provide here a review of our current understanding of goals, benefits, and limitations of machine learning techniques for computational studies on atomistic systems, focusing on the construction of empirical force fields from ab-initio databases and the determination of reaction coordinates for free energy computation and enhanced sampling.},
author = {P. Gkeka and G. Stoltz and A. Barati Farimani and Zineb Belkacemi and M. Ceriotti and J. Chodera and A. Dinner and Andrew L. Ferguson and J. Maillet and H. Minoux and C. Peter and F. Pietrucci and A. Silveira and A. Tkatchenko and Z. Trstanova and Rafal P. Wiewiora and T. Lelièvre},
journal = {Journal of chemical theory and computation},
volume = {null},
pages = {null},
doi = {10.1021/acs.jctc.0c00355},
pmid = {32559068},
arxivid = {2004.06950},
}

@article{98243acffb45975b0fe73763b41316c520a7037a,
title = {Progress in deep Markov state modeling: Coarse graining and experimental data restraints.},
year = {2021},
url = {https://www.semanticscholar.org/paper/98243acffb45975b0fe73763b41316c520a7037a},
abstract = {Recent advances in deep learning frameworks have established valuable tools for analyzing the long-timescale behavior of complex systems, such as proteins. In particular, the inclusion of physical constraints, e.g., time-reversibility, was a crucial step to make the methods applicable to biophysical systems. Furthermore, we advance the method by incorporating experimental observables into the model estimation showing that biases in simulation data can be compensated for. We further develop a new neural network layer in order to build a hierarchical model allowing for different levels of details to be studied. Finally, we propose an attention mechanism, which highlights important residues for the classification into different states. We demonstrate the new methodology on an ultralong molecular dynamics simulation of the Villin headpiece miniprotein.},
author = {Andreas Mardt and Frank No'e},
journal = {The Journal of chemical physics},
volume = {155 21},
pages = {
          214106
        },
doi = {10.1063/5.0064668},
pmid = {34879670},
arxivid = {2108.01927},
}

@article{204cedd41db9db3623226e9dfce6d82aaa3f0f41,
title = {Machine learning for collective variable discovery and enhanced sampling in biomolecular simulation},
year = {2020},
url = {https://www.semanticscholar.org/paper/204cedd41db9db3623226e9dfce6d82aaa3f0f41},
abstract = {Classical molecular dynamics simulates the time evolution of molecular systems through the phase space spanned by the positions and velocities of the constituent atoms. Molecular-level thermodynamic, kinetic, and structural data extracted from the resulting trajectories provide valuable information for the understanding, engineering, and design of biological and molecular materials. The cost of simulating many-body atomic systems makes simulations of large molecules prohibitively expensive, and the high-dimensionality of the resulting trajectories presents a challenge for analysis. Driven by advances in algorithms, hardware, and data availability, there has been a flare of interest in recent years in the applications of machine learning – especially deep learning – to molecular simulation. These techniques have demonstrated great power and flexibility in both extracting mechanistic understanding of the important nonlinear collective variables governing the dynamics of a molecular system, and in furnishing good low-dimensional system representations with which to perform enhanced sampling or develop long-timescale dynamical models. It is the purpose of this article to introduce the key machine learning approaches, describe how they are married with statistical mechanical theory into domain-specific tools, and detail applications of these approaches in understanding and accelerating biomolecular simulation. GRAPHICAL ABSTRACT},
author = {Hythem Sidky and Wei Chen and Andrew L. Ferguson},
journal = {Molecular Physics},
volume = {118},
pages = {null},
doi = {10.1080/00268976.2020.1737742},
}

@article{b505075d5f3bb937d2d191dfc0fdfd956790ef94,
title = {Introduction to Markov state modeling with the PyEMMA software — v1.0},
year = {2018},
url = {https://www.semanticscholar.org/paper/b505075d5f3bb937d2d191dfc0fdfd956790ef94},
abstract = {This tutorial provides an introduction to the construction of Markov models of molec- ular kinetics from molecular dynamics trajectory data with the PyEMMA software. Using tutorial notebooks, we will guide the user through the basic functionality as well as the more common advanced mechanisms. Short exercises to self check the learning progress and a notebook on troubleshooting complete this basic introduction.},
author = {C. Wehmeyer and Martin K. Scherer and Tim Hempel and B. Husic and S. Olsson and F. Noé},
}
